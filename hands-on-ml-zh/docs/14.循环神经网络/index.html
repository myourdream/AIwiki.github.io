



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="AI Wiki 是一个编程竞赛知识整合站点，提供有趣又实用的编程竞赛知识以及其他有帮助的内容，帮助广大编程竞赛爱好者更快更深入地学习编程竞赛">
      
      
        <link rel="canonical" href="https://hai5g.cn/aiwiki/hands-on-ml-zh/docs/14.循环神经网络/">
      
      
        <meta name="author" content="AI Wiki Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>循环神经网络 - AI Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,400i,700|Fira+Mono">
        <style>body,input{font-family:"Fira Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Fira Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
      <link rel="manifest" href="../../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/ah@1.5.0/han.min.css">
    
      <link rel="stylesheet" href="../../../_static/css/extra.css?v=11">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              AI Wiki
            </span>
            <span class="md-header-nav__topic">
              循环神经网络
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="简介" class="md-tabs__link">
          简介
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../Coursera_ML_AndrewNg/" title="机器学习" class="md-tabs__link">
          机器学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../qa500/" title="深度学习500问" class="md-tabs__link">
          深度学习500问
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../lihang/" title="统计学习" class="md-tabs__link">
          统计学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../README.old/" title="Sklearn与TensorFlow" class="md-tabs__link md-tabs__link--active">
          Sklearn与TensorFlow
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    AI Wiki
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/AI学习路线/" title="AI学习路线1" class="md-nav__link">
      AI学习路线1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/ai-union-201904/" title="AI学习路线2" class="md-nav__link">
      AI学习路线2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v0.1/" title="AI 路线图v0.1" class="md-nav__link">
      AI 路线图v0.1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v0.2/" title="AI 路线图v0.2" class="md-nav__link">
      AI 路线图v0.2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v1.0/" title="ApacheCN 人工智能知识树" class="md-nav__link">
      ApacheCN 人工智能知识树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7" type="checkbox" id="nav-1-7">
    
    <label class="md-nav__link" for="nav-1-7">
      工具软件
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-7">
        工具软件
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/judgers/" title="评测工具" class="md-nav__link">
      评测工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/editors/" title="编辑工具" class="md-nav__link">
      编辑工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/wsl/" title="WSL (Windows 10)" class="md-nav__link">
      WSL (Windows 10)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/spj/" title="Special Judge" class="md-nav__link">
      Special Judge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7-5" type="checkbox" id="nav-1-7-5">
    
    <label class="md-nav__link" for="nav-1-7-5">
      Testlib
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-1-7-5">
        Testlib
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/" title="Testlib 简介" class="md-nav__link">
      Testlib 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/general/" title="通用" class="md-nav__link">
      通用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/generator/" title="Generator" class="md-nav__link">
      Generator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/validator/" title="Validator" class="md-nav__link">
      Validator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/interactor/" title="Interactor" class="md-nav__link">
      Interactor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/checker/" title="Checker" class="md-nav__link">
      Checker
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/docker-deploy/" title="Docker 部署" class="md-nav__link">
      Docker 部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/about/" title="关于本项目" class="md-nav__link">
      关于本项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/faq/" title="F.A.Q." class="md-nav__link">
      F.A.Q.
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      机器学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/SUMMARY/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/math/" title="数学基础" class="md-nav__link">
      数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week1/" title="week1" class="md-nav__link">
      week1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week2/" title="week2" class="md-nav__link">
      week2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week3/" title="week3" class="md-nav__link">
      week3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week4/" title="week4" class="md-nav__link">
      week4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week5/" title="week5" class="md-nav__link">
      week5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week6/" title="week6" class="md-nav__link">
      week6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week7/" title="week7" class="md-nav__link">
      week7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week8/" title="week8" class="md-nav__link">
      week8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week9/" title="week9" class="md-nav__link">
      week9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../Coursera_ML_AndrewNg/markdown/week10/" title="week10" class="md-nav__link">
      week10
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度学习500问
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        深度学习500问
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/content/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch01_math/ch01_math/" title="第一章_数学基础" class="md-nav__link">
      第一章_数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch02_机器学习基础/第二章_机器学习基础/" title="第二章_机器学习基础" class="md-nav__link">
      第二章_机器学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch03_深度学习基础/第三章_深度学习基础/" title="第三章_深度学习基础" class="md-nav__link">
      第三章_深度学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch04_经典网络/第四章_经典网络/" title="第四章_经典网络" class="md-nav__link">
      第四章_经典网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch05_卷积神经网络(CNN)/第五章 卷积神经网络（CNN）/" title="第五章 卷积神经网络（CNN）" class="md-nav__link">
      第五章 卷积神经网络（CNN）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch06_循环神经网络(RNN)/第六章_循环神经网络(RNN)/" title="第六章_循环神经网络(RNN)" class="md-nav__link">
      第六章_循环神经网络(RNN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch07_生成对抗网络(GAN)/ch7/" title="第七章_生成对抗网络(GAN)" class="md-nav__link">
      第七章_生成对抗网络(GAN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch08_目标检测/第八章_目标检测/" title="第八章_目标检测" class="md-nav__link">
      第八章_目标检测
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch09_图像分割/第九章_图像分割/" title="第九章_图像分割" class="md-nav__link">
      第九章_图像分割
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch10_强化学习/第十章_强化学习/" title="第十章_强化学习" class="md-nav__link">
      第十章_强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch11_迁移学习/第十一章_迁移学习/" title="第十一章_迁移学习" class="md-nav__link">
      第十一章_迁移学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch12_网络搭建及训练/第十二章_网络搭建及训练/" title="第十二章_网络搭建及训练" class="md-nav__link">
      第十二章_网络搭建及训练
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch13_优化算法/第十三章_优化算法/" title="第十三章_优化算法" class="md-nav__link">
      第十三章_优化算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch14_超参数调整/第十四章_超参数调整/" title="第十四章_超参数调整" class="md-nav__link">
      第十四章_超参数调整
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch15_GPU和框架选型/第十五章_异构运算、GPU及框架选型/" title="第十五章_异构运算、GPU及框架选型" class="md-nav__link">
      第十五章_异构运算、GPU及框架选型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch16_自然语言处理(NLP)/第十六章_NLP/" title="第十六章_NLP" class="md-nav__link">
      第十六章_NLP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch17_模型压缩、加速及移动端部署/第十七章_模型压缩、加速及移动端部署/" title="第十七章_模型压缩、加速及移动端部署" class="md-nav__link">
      第十七章_模型压缩、加速及移动端部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型、离线及实时计算/第十八章_后端架构选型、离线及实时计算/" title="第十八章_后端架构选型、离线及实时计算" class="md-nav__link">
      第十八章_后端架构选型、离线及实时计算
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型及应用场景/第十八章_后端架构选型及应用场景/" title="第十八章_后端架构选型及应用场景" class="md-nav__link">
      第十八章_后端架构选型及应用场景
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      统计学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        统计学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH01/" title="统计学习及监督学习概论" class="md-nav__link">
      统计学习及监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH02/" title="感知机" class="md-nav__link">
      感知机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH03/" title="K近邻法" class="md-nav__link">
      K近邻法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH04/" title="朴素贝叶斯法" class="md-nav__link">
      朴素贝叶斯法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH05/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH06/" title="逻辑斯蒂回归与最大熵模型" class="md-nav__link">
      逻辑斯蒂回归与最大熵模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH07/" title="支持向量机" class="md-nav__link">
      支持向量机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH08/" title="提升方法" class="md-nav__link">
      提升方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH09/" title="EM算法及其推广" class="md-nav__link">
      EM算法及其推广
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH10/" title="隐马尔可夫模型" class="md-nav__link">
      隐马尔可夫模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH11/" title="条件随机场" class="md-nav__link">
      条件随机场
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH12/" title="监督学习方法总结" class="md-nav__link">
      监督学习方法总结
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH13/" title="无监督学习概论" class="md-nav__link">
      无监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH14/" title="聚类方法" class="md-nav__link">
      聚类方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH22/" title="无监督学习方法总结" class="md-nav__link">
      无监督学习方法总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Sklearn与TensorFlow
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Sklearn与TensorFlow
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../README.old/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../0.前言/" title="前言" class="md-nav__link">
      前言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1.机器学习概览/" title="机器学习概览" class="md-nav__link">
      机器学习概览
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2.一个完整的机器学习项目/" title="一个完整的机器学习项目" class="md-nav__link">
      一个完整的机器学习项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.分类/" title="分类" class="md-nav__link">
      分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../4.训练模型/" title="训练模型" class="md-nav__link">
      训练模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../5.支持向量机/" title="支持向量机" class="md-nav__link">
      支持向量机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../6.决策树/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../7.集成学习和随机森林/" title="集成学习和随机森林" class="md-nav__link">
      集成学习和随机森林
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../9.启动并运行_TensorFlow/" title="启动并运行_TensorFlow" class="md-nav__link">
      启动并运行_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../10.人工神经网络介绍/" title="人工神经网络介绍" class="md-nav__link">
      人工神经网络介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../11.训练深层神经网络/" title="训练深层神经网络" class="md-nav__link">
      训练深层神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../12.设备和服务器上的分布式_TensorFlow/" title="设备和服务器上的分布式_TensorFlow" class="md-nav__link">
      设备和服务器上的分布式_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../13.卷积神经网络/" title="卷积神经网络" class="md-nav__link">
      卷积神经网络
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        循环神经网络
      </label>
    
    <a href="./" title="循环神经网络" class="md-nav__link md-nav__link--active">
      循环神经网络
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="循环神经元" class="md-nav__link">
    循环神经元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="记忆单元" class="md-nav__link">
    记忆单元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="输入和输出序列" class="md-nav__link">
    输入和输出序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-rnn" title="TensorFlow 中的基本 RNN" class="md-nav__link">
    TensorFlow 中的基本 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" title="时间上的静态展开" class="md-nav__link">
    时间上的静态展开
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="时间上的动态展开" class="md-nav__link">
    时间上的动态展开
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="处理变长输入序列" class="md-nav__link">
    处理变长输入序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" title="处理变长输出序列" class="md-nav__link">
    处理变长输出序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn" title="训练 RNN" class="md-nav__link">
    训练 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" title="训练序列分类器" class="md-nav__link">
    训练序列分类器
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" title="为预测时间序列而训练" class="md-nav__link">
    为预测时间序列而训练
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_1" title="生成 RNN" class="md-nav__link">
    生成 RNN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn_2" title="深度 RNN" class="md-nav__link">
    深度 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-rnn" title="在多个 GPU 上分布式部署深度 RNN 网络" class="md-nav__link">
    在多个 GPU 上分布式部署深度 RNN 网络
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dropout" title="Dropout 的应用" class="md-nav__link">
    Dropout 的应用
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" title="长时训练的困难" class="md-nav__link">
    长时训练的困难
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="LSTM 单元" class="md-nav__link">
    LSTM 单元
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" title="窥孔连接" class="md-nav__link">
    窥孔连接
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gru" title="GRU 单元" class="md-nav__link">
    GRU 单元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" title="自然语言处理" class="md-nav__link">
    自然语言处理
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_14" title="单词嵌入" class="md-nav__link">
    单词嵌入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="用于机器翻译的编解码器网络" class="md-nav__link">
    用于机器翻译的编解码器网络
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" title="练习" class="md-nav__link">
    练习
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../15.自编码器/" title="自编码器" class="md-nav__link">
      自编码器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../16.强化学习/" title="强化学习" class="md-nav__link">
      强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../B.机器学习项目清单/" title="B.机器学习项目清单" class="md-nav__link">
      B.机器学习项目清单
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../C.SVM_对偶问题/" title="C.SVM_对偶问题" class="md-nav__link">
      C.SVM_对偶问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../D.自动微分/" title="D.自动微分" class="md-nav__link">
      D.自动微分
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="循环神经元" class="md-nav__link">
    循环神经元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="记忆单元" class="md-nav__link">
    记忆单元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="输入和输出序列" class="md-nav__link">
    输入和输出序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-rnn" title="TensorFlow 中的基本 RNN" class="md-nav__link">
    TensorFlow 中的基本 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" title="时间上的静态展开" class="md-nav__link">
    时间上的静态展开
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="时间上的动态展开" class="md-nav__link">
    时间上的动态展开
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="处理变长输入序列" class="md-nav__link">
    处理变长输入序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" title="处理变长输出序列" class="md-nav__link">
    处理变长输出序列
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn" title="训练 RNN" class="md-nav__link">
    训练 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" title="训练序列分类器" class="md-nav__link">
    训练序列分类器
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" title="为预测时间序列而训练" class="md-nav__link">
    为预测时间序列而训练
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_1" title="生成 RNN" class="md-nav__link">
    生成 RNN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn_2" title="深度 RNN" class="md-nav__link">
    深度 RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-rnn" title="在多个 GPU 上分布式部署深度 RNN 网络" class="md-nav__link">
    在多个 GPU 上分布式部署深度 RNN 网络
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dropout" title="Dropout 的应用" class="md-nav__link">
    Dropout 的应用
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" title="长时训练的困难" class="md-nav__link">
    长时训练的困难
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="LSTM 单元" class="md-nav__link">
    LSTM 单元
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" title="窥孔连接" class="md-nav__link">
    窥孔连接
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gru" title="GRU 单元" class="md-nav__link">
    GRU 单元
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" title="自然语言处理" class="md-nav__link">
    自然语言处理
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_14" title="单词嵌入" class="md-nav__link">
    单词嵌入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="用于机器翻译的编解码器网络" class="md-nav__link">
    用于机器翻译的编解码器网络
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" title="练习" class="md-nav__link">
    练习
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/myourdream/aiwiki/blob/master/docs/hands-on-ml-zh/docs/14.循环神经网络.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="_1">十四、循环神经网络<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<blockquote>
<p>译者：<a href="https://github.com/wangxupeng">@akonwang</a>、<a href="https://github.com/alexcheen">@alexcheen</a>、<a href="https://github.com/wizardforcel">@飞龙</a></p>
<p>校对者：<a href="https://github.com/wizardforcel">@飞龙</a></p>
</blockquote>
<p>击球手击出垒球，你会开始预测球的轨迹并立即开始奔跑。你追踪着它，不断调整你的移动步伐，最终在观众的一片雷鸣声中抓到它。无论是在听完朋友的话语还是早餐时预测咖啡的味道，你时刻在做的事就是在预测未来。在本章中，我们将讨论循环神经网络 -- 一类预测未来的网络（当然，是到目前为止）。它们可以分析时间序列数据，诸如股票价格，并告诉你什么时候买入和卖出。在自动驾驶系统中，他们可以预测行车轨迹，避免发生交通意外。更一般地说，它们可在任意长度的序列上工作，而不是截止目前我们讨论的只能在固定长度的输入上工作的网络。举个例子，它们可以把语句，文件，以及语音范本作为输入，使得它们在诸如自动翻译，语音到文本或者情感分析（例如，读取电影评论并提取评论者关于该电影的感觉）的自然语言处理系统中极为有用。</p>
<p>更近一步，循环神经网络的预测能力使得它们具备令人惊讶的创造力。你同样可以要求它们去预测一段旋律的下几个音符，然后随机选取这些音符的其中之一并演奏它。然后要求网络给出接下来最可能的音符，演奏它，如此周而复始。在你知道它之前，你的神经网络将创作一首诸如由谷歌 Magenta 工程所创造的《The one》的歌曲。类似的，循环神经网络可以生成语句，图像标注以及更多。目前结果还不能准确得到莎士比亚或者莫扎特的作品，但谁知道几年后他们能生成什么呢？</p>
<p>在本章中，我们将看到循环神经网络背后的基本概念，他们所面临的主要问题（换句话说，在第11章中讨论的消失／爆炸的梯度），以及广泛用于反抗这些问题的方法：LSTM 和 GRU cell（单元）。如同以往，沿着这个方式，我们将展示如何用 TensorFlow 实现循环神经网络。最终我们将看看及其翻译系统的架构。</p>
<h2 id="_2">循环神经元<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>到目前为止，我们主要关注的是前馈神经网络，其中激活仅从输入层到输出层的一个方向流动（附录 E 中的几个网络除外）。 循环神经网络看起来非常像一个前馈神经网络，除了它也有连接指向后方。 让我们看一下最简单的 RNN，它由一个神经元接收输入，产生一个输出，并将输出发送回自己，如图 14-1（左）所示。 在每个时间步<code>t</code>（也称为一个帧），这个循环神经元接收输入 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 以及它自己的前一时间步长 <img alt="y^{(t-1)}" src="../../images/tex-9d51d9238bb54c1c9448b87d61b7503e.gif" /> 的输出。 我们可以用时间轴来表示这个微小的网络，如图 14-1（右）所示。 这被称为随着时间的推移展开网络。</p>
<p><img alt="" src="../../images/chapter_14/14-1.png" /></p>
<p>你可以轻松创建一个循环神经元层。 在每个时间步t，每个神经元都接收输入向量 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 和前一个时间步 <img alt="y^{(t-1)}" src="../../images/tex-9d51d9238bb54c1c9448b87d61b7503e.gif" /> 的输出向量，如图 14-2 所示。 请注意，输入和输出都是向量（当只有一个神经元时，输出是一个标量）。</p>
<p><img alt="" src="../../images/chapter_14/14-2.png" /></p>
<p>每个循环神经元有两组权重：一组用于输入 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" />，另一组用于前一时间步长 <img alt="y^{(t-1)}" src="../../images/tex-9d51d9238bb54c1c9448b87d61b7503e.gif" /> 的输出。 我们称这些权重向量为 <img alt="w_x" src="../../images/tex-4a5d1969fe1ef947082a32d547c247d7.gif" /> 和 <img alt="w_y" src="../../images/tex-e939f0323d8d49a8482b30a5284c8374.gif" />。如公式 14-1 所示（<code>b</code>是偏差项，<code>φ(·)</code>是激活函数，例如 ReLU），可以计算单个循环神经元的输出。</p>
<p><img alt="" src="../../images/chapter_14/e-14-1.png" /></p>
<p>就像前馈神经网络一样，我们可以使用上一个公式的向量化形式，对整个小批量计算整个层的输出（见公式 14-2）。</p>
<p><img alt="" src="../../images/chapter_14/e-14-2.png" /></p>
<ul>
<li><img alt="Y^{(t)}" src="../../images/tex-626343cb96bdf9ee8429b7d5d8f4607a.gif" /> 是 <img alt="m \times n_{neurons}" src="../../images/tex-5034ed18fa4c81ee7bc176f0a4cbab80.gif" /> 矩阵，包含在最小批次中每个实例在时间步<code>t</code>处的层输出（<code>m</code>是小批次中的实例数，<img alt="n_{neurons}" src="../../images/tex-e57673e94f4eeddd53be04f2167db8d2.gif" /> 是神经元数）。</li>
<li><img alt="X^{(t)}" src="../../images/tex-56662b2579440b8c9f02e9c09b8b021d.gif" /> 是 <img alt="m \times n_{inputs}" src="../../images/tex-3550fe5e2cae185a9af7235e7f7fb05d.gif" /> 矩阵，包含所有实例的输入的 （<img alt="n_{inputs}" src="../../images/tex-53e90522ca559971bb2d9d6009b82a44.gif" /> 是输入特征的数量）。</li>
<li><img alt="W_x" src="../../images/tex-6984549d7be7b4c4021c370c9411cef3.gif" /> 是 <img alt="n_{inputs} \times n_{neurons}" src="../../images/tex-7d4bb14b3b5f5073d69bb75df6665017.gif" /> 矩阵，包含当前时间步的输入的连接权重的。</li>
<li><img alt="W_y" src="../../images/tex-a1c5ef84a61f97159520c00e49a728a0.gif" /> 是 <img alt="n_{neurons} \times n_{neurons}" src="../../images/tex-66696a3ef544ca4201af088feb0b911b.gif" /> 矩阵，包含上一个时间步的输出的连接权重。</li>
<li>权重矩阵 <img alt="W_x" src="../../images/tex-6984549d7be7b4c4021c370c9411cef3.gif" /> 和 <img alt="W_y" src="../../images/tex-a1c5ef84a61f97159520c00e49a728a0.gif" /> 通常连接成单个权重矩阵<code>W</code>，形状为 <img alt="(n_{inputs}+n_{neurons}) \times n_{neurons}" src="../../images/tex-92c270042098f9151bcc3e90407cf028.gif" />（见公式 14-2 的第二行）</li>
<li><code>b</code>是大小为 <img alt="n_{neurons}" src="../../images/tex-e57673e94f4eeddd53be04f2167db8d2.gif" /> 的向量，包含每个神经元的偏置项。</li>
</ul>
<p>注意，<img alt="Y^{(t)}" src="../../images/tex-626343cb96bdf9ee8429b7d5d8f4607a.gif" /> 是 <img alt="X^{(t)}" src="../../images/tex-56662b2579440b8c9f02e9c09b8b021d.gif" /> 和 <img alt="Y^{(t-1)}" src="../../images/tex-224150d7a099d199fc7bbb324fee9d18.gif" /> 的函数，它是 <img alt="X^{(t-1)}" src="../../images/tex-f9a82354ca58947238d9ae8ae8cf1ec6.gif" /> 和 <img alt="Y^{(t-2)}" src="../../images/tex-fb0f62e49ab81bcdf5d79d2bf9542446.gif" /> 的函数，它是 <img alt="X^{(t-2)}" src="../../images/tex-c4f2bbec4ec0a31260b87fef04ffb9fc.gif" /> 和 <img alt="Y^{(t-3)}" src="../../images/tex-4f717d5e747701b3301e39c21191ae17.gif" /> 的函数，等等。 这使得 <img alt="Y^{(t)}" src="../../images/tex-626343cb96bdf9ee8429b7d5d8f4607a.gif" /> 是从时间<code>t = 0</code>开始的所有输入（即 <img alt="X^{(0)}" src="../../images/tex-091a36c336b9f86ac488b9e8ac0e0ffa.gif" />，<img alt="X^{(1)}" src="../../images/tex-588e5b81fdcbbd6dd55e2195663fab41.gif" />，...，<img alt="X^{(t)}" src="../../images/tex-56662b2579440b8c9f02e9c09b8b021d.gif" />）的函数。 在第一个时间步，<code>t = 0</code>，没有以前的输出，所以它们通常被假定为全零。</p>
<h2 id="_3">记忆单元<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>由于时间<code>t</code>的循环神经元的输出，是由所有先前时间步骤计算出来的的函数，你可以说它有一种记忆形式。一个神经网络的一部分，跨越时间步长保留一些状态，称为存储单元（或简称为单元）。单个循环神经元或循环神经元层是非常基本的单元，但本章后面我们将介绍一些更为复杂和强大的单元类型。</p>
<p>一般情况下，时间步<code>t</code>处的单元状态，记为 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" />（<code>h</code>代表“隐藏”），是该时间步的某些输入和前一时间步的状态的函数：<img alt="h^{(t)} = f(h^{(t-1)}, x^{(t)})" src="../../images/tex-07be34d7c17f39052675948cb5b75838.gif" />。 其在时间步<code>t</code>处的输出，表示为 <img alt="y^{(t)}" src="../../images/tex-cc685401bcf131ce4e9f980be319daac.gif" />，也和前一状态和当前输入的函数有关。 在我们已经讨论过的基本单元的情况下，输出等于单元状态，但是在更复杂的单元中并不总是如此，如图 14-3 所示。</p>
<p><img alt="" src="../../images/chapter_14/14-3.png" /></p>
<h2 id="_4">输入和输出序列<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../../images/chapter_14/14-4.png" /></p>
<p>RNN 可以同时进行一系列输入并产生一系列输出（见图 14-4，左上角的网络）。 例如，这种类型的网络对于预测时间序列（如股票价格）非常有用：你在过去的<code>N</code>天内给出价格，并且它必须输出向未来一天移动的价格（即从<code>N - 1</code>天前到明天）。</p>
<p>或者，你可以向网络输入一系列输入，并忽略除最后一个之外的所有输出（请参阅右上角的网络）。 换句话说，这是一个向量网络的序列。 例如，你可以向网络提供与电影评论相对应的单词序列，并且网络将输出情感评分（例如，从<code>-1 [恨]</code>到<code>+1 [爱]</code>）。</p>
<p>相反，你可以在第一个时间步中为网络提供一个输入（而在其他所有时间步中为零），然后让它输出一个序列（请参阅左下角的网络）。 这是一个向量到序列的网络。 例如，输入可以是图像，输出可以是该图像的标题。</p>
<p>最后，你可以有一个序列到向量网络，称为编码器，后面跟着一个称为解码器的向量到序列网络（参见右下角的网络）。 例如，这可以用于将句子从一种语言翻译成另一种语言。 你会用一种语言给网络喂一个句子，编码器会把这个句子转换成单一的向量表示，然后解码器将这个向量解码成另一种语言的句子。 这种称为编码器 - 解码器的两步模型，比用单个序列到序列的 RNN（如左上方所示的那个）快速地进行翻译要好得多，因为句子的最后一个单词可以 影响翻译的第一句话，所以你需要等到听完整个句子才能翻译。</p>
<h2 id="tensorflow-rnn">TensorFlow 中的基本 RNN<a class="headerlink" href="#tensorflow-rnn" title="Permanent link">&para;</a></h2>
<p>首先，我们来实现一个非常简单的 RNN 模型，而不使用任何 TensorFlow 的 RNN 操作，以更好地理解发生了什么。 我们将使用 tanh 激活函数创建由 5 个循环神经元的循环层组成的 RNN（如图 14-2 所示的 RNN）。 我们将假设 RNN 只运行两个时间步，每个时间步输入大小为 3 的向量。 下面的代码构建了这个 RNN，展开了两个时间步骤：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">Wy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">Y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">Wx</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Y0</span><span class="p">,</span> <span class="n">Wy</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Wx</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>这个网络看起来很像一个双层前馈神经网络，有一些改动：首先，两个层共享相同的权重和偏差项，其次，我们在每一层都有输入，并从每个层获得输出。 为了运行模型，我们需要在两个时间步中都有输入，如下所示：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>    <span class="c1"># Mini-batch: instance 0,instance 1,instance 2,instance 3</span>
    <span class="n">X0_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>  <span class="c1"># t = 0</span>
    <span class="n">X1_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>  <span class="c1"># t = 1</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">Y0_val</span><span class="p">,</span> <span class="n">Y1_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">Y0</span><span class="p">,</span> <span class="n">Y1</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X0</span><span class="p">:</span> <span class="n">X0_batch</span><span class="p">,</span> <span class="n">X1</span><span class="p">:</span> <span class="n">X1_batch</span><span class="p">})</span>
</pre></div>
</td></tr></table>

<p>这个小批量包含四个实例，每个实例都有一个由两个输入组成的输入序列。 最后，<code>Y0_val</code>和<code>Y1_val</code>在所有神经元和小批量中的所有实例的两个时间步中包含网络的输出：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">Y0_val</span><span class="p">)</span> <span class="c1"># output at t = 0</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.2964572</span> <span class="mf">0.82874775</span> <span class="o">-</span><span class="mf">0.34216955</span> <span class="o">-</span><span class="mf">0.75720584</span> <span class="mf">0.19011548</span><span class="p">]</span> <span class="c1"># instance 0</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.12842922</span> <span class="mf">0.99981797</span> <span class="mf">0.84704727</span> <span class="o">-</span><span class="mf">0.99570125</span> <span class="mf">0.38665548</span><span class="p">]</span> <span class="c1"># instance 1</span>
<span class="p">[</span> <span class="mf">0.04731077</span> <span class="mf">0.99999976</span> <span class="mf">0.99330056</span> <span class="o">-</span><span class="mf">0.999933</span> <span class="mf">0.55339795</span><span class="p">]</span> <span class="c1"># instance 2</span>
<span class="p">[</span> <span class="mf">0.70323634</span> <span class="mf">0.99309105</span> <span class="mf">0.99909431</span> <span class="o">-</span><span class="mf">0.85363263</span> <span class="mf">0.7472108</span> <span class="p">]]</span> <span class="c1"># instance 3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">Y1_val</span><span class="p">)</span> <span class="c1"># output at t = 1</span>
<span class="p">[[</span> <span class="mf">0.51955646</span> <span class="mi">1</span>\<span class="o">.</span> <span class="mf">0.99999022</span> <span class="o">-</span><span class="mf">0.99984968</span> <span class="o">-</span><span class="mf">0.24616946</span><span class="p">]</span> <span class="c1"># instance 0</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.70553327</span> <span class="o">-</span><span class="mf">0.11918639</span> <span class="mf">0.48885304</span> <span class="mf">0.08917919</span> <span class="o">-</span><span class="mf">0.26579669</span><span class="p">]</span> <span class="c1"># instance 1</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.32477224</span> <span class="mf">0.99996376</span> <span class="mf">0.99933046</span> <span class="o">-</span><span class="mf">0.99711186</span> <span class="mf">0.10981458</span><span class="p">]</span> <span class="c1"># instance 2</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.43738723</span> <span class="mf">0.91517633</span> <span class="mf">0.97817528</span> <span class="o">-</span><span class="mf">0.91763324</span> <span class="mf">0.11047263</span><span class="p">]]</span> <span class="c1"># instance 3</span>
</pre></div>
</td></tr></table>

<p>这并不难，但是当然如果你想能够运行 100 多个时间步骤的 RNN，这个图形将会非常大。 现在让我们看看如何使用 TensorFlow 的 RNN 操作创建相同的模型。</p>
<p>完整代码</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">X0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
    <span class="n">X1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
    <span class="n">Wx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">Wy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">Y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">Wx</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">Y1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Y0</span><span class="p">,</span> <span class="n">Wy</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Wx</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

    <span class="c1"># Mini-batch: instance 0,instance 1,instance 2,instance 3</span>
    <span class="n">X0_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>  <span class="c1"># t = 0</span>
    <span class="n">X1_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>  <span class="c1"># t = 1</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="n">Y0_val</span><span class="p">,</span> <span class="n">Y1_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">Y0</span><span class="p">,</span> <span class="n">Y1</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X0</span><span class="p">:</span> <span class="n">X0_batch</span><span class="p">,</span> <span class="n">X1</span><span class="p">:</span> <span class="n">X1_batch</span><span class="p">})</span>

    <span class="k">print</span><span class="p">(</span><span class="n">Y0_val</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">Y1_val</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h2 id="_5">时间上的静态展开<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<p><code>static_rnn()</code>函数通过链接单元来创建一个展开的 RNN 网络。 下面的代码创建了与上一个完全相同的模型：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">X0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>

<span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">output_seqs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">static_rnn</span><span class="p">(</span><span class="n">basic_cell</span><span class="p">,</span> <span class="p">[</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">],</span>
                                                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y0</span><span class="p">,</span> <span class="n">Y1</span> <span class="o">=</span> <span class="n">output_seqs</span>
</pre></div>
</td></tr></table>

<p>首先，我们像以前一样创建输入占位符。 然后，我们创建一个<code>BasicRNNCell</code>，你可以将其视为一个工厂，创建单元的副本以构建展开的 RNN（每个时间步一个）。 然后我们调用<code>static_rnn()</code>，向它提供单元工厂和输入张量，并告诉它输入的数据类型（用来创建初始状态矩阵，默认情况下是全零）。 <code>static_rnn()</code>函数为每个输入调用单元工厂的<code>__call __()</code>函数，创建单元的两个副本（每个单元包含 5 个循环神经元的循环层），并具有共享的权重和偏置项，像前面一样。<code>static_rnn()</code>函数返回两个对象。 第一个是包含每个时间步的输出张量的 Python 列表。 第二个是包含网络最终状态的张量。 当你使用基本的单元时，最后的状态就等于最后的输出。</p>
<p>如果有 50 个时间步长，则不得不定义 50 个输入占位符和 50 个输出张量。而且，在执行时，你将不得不为 50 个占位符中的每个占位符输入数据并且还要操纵 50 个输出。我们来简化一下。下面的代码再次构建相同的 RNN，但是这次它需要一个形状为<code>[None，n_steps，n_inputs]</code>的单个输入占位符，其中第一个维度是最小批量大小。然后提取每个时间步的输入序列列表。 <code>X_seqs</code>是形状为<code>n_steps</code>的 Python 列表，包含形状为<code>[None，n_inputs]</code>的张量，其中第一个维度同样是最小批量大小。为此，我们首先使用<code>transpose()</code>函数交换前两个维度，以便时间步骤现在是第一维度。然后，我们使 <code>unstack()</code>函数沿第一维（即每个时间步的一个张量）提取张量的 Python 列表。接下来的两行和以前一样。最后，我们使用<code>stack()</code>函数将所有输出张量合并成一个张量，然后我们交换前两个维度得到最终输出张量，形状为<code>[None, n_steps，n_neurons]</code>（第一个维度是小批量大小）。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">X_seqs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>

<span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">output_seqs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">static_rnn</span><span class="p">(</span><span class="n">basic_cell</span><span class="p">,</span> <span class="n">X_seqs</span><span class="p">,</span>
                                                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">output_seqs</span><span class="p">),</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</td></tr></table>

<p>现在我们可以通过给它提供一个包含所有小批量序列的张量来运行网络：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="c1"># t = 0      t = 1 </span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="c1"># instance 1</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="c1"># instance 2</span>
        <span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="c1"># instance 3</span>
        <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="c1"># instance 4</span>
    <span class="p">])</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">outputs_val</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">})</span>
</pre></div>
</td></tr></table>

<p>我们得到所有实例，所有时间步长和所有神经元的单一<code>outputs_val</code>张量：</p>
<p><img alt="" src="../../images/chapter_14/o-14-1.png" /></p>
<p>但是，这种方法仍然会建立一个每个时间步包含一个单元的图。 如果有 50 个时间步，这个图看起来会非常难看。 这有点像写一个程序而没有使用循环（例如，<code>Y0 = f(0,X0)</code>；<code>Y1 = f(Y0,X1)</code>；<code>Y2 = f(Y1,X2)</code>；...；<code>Y50 = f(Y49,X50)</code>）。 如果使用大图，在反向传播期间（特别是在 GPU 内存有限的情况下），你甚至可能会发生内存不足（OOM）错误，因为它必须在正向传递期间存储所有张量值，以便可以使用它们在反向传播期间计算梯度。</p>
<p>幸运的是，有一个更好的解决方案：<code>dynamic_rnn()</code>函数。</p>
<h2 id="_6">时间上的动态展开<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<p><code>dynamic_rnn()</code>函数使用<code>while_loop()</code>操作，在单元上运行适当的次数，如果要在反向传播期间将 GPU内 存交换到 CPU 内存，可以设置<code>swap_memory = True</code>，以避免内存不足错误。 方便的是，它还可以在每个时间步（形状为<code>[None, n_steps, n_inputs]</code>）接受所有输入的单个张量，并且在每个时间步（形状<code>[None, n_steps, n_neurons]</code>）上输出所有输出的单个张量。 没有必要堆叠，拆散或转置。 以下代码使用<code>dynamic_rnn()</code>函数创建与之前相同的 RNN。 这太好了！</p>
<p>完整代码</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">n_steps</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">5</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>

    <span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">basic_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>  <span class="c1"># instance 1</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>  <span class="c1"># instance 2</span>
        <span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>  <span class="c1"># instance 3</span>
        <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>  <span class="c1"># instance 4</span>
    <span class="p">])</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="n">outputs_val</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">})</span>

    <span class="k">print</span><span class="p">(</span><span class="n">outputs_val</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>在反向传播期间，<code>while_loop()</code>操作会执行相应的步骤：在正向传递期间存储每次迭代的张量值，以便在反向传递期间使用它们来计算梯度。</p>
<h2 id="_7">处理变长输入序列<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<p>到目前为止，我们只使用固定大小的输入序列（全部正好两个步长）。 如果输入序列具有可变长度（例如，像句子）呢？ 在这种情况下，你应该在调用<code>dynamic_rnn()</code>（或<code>static_rnn()</code>）函数时设置<code>sequence_length</code>参数；它必须是一维张量，表示每个实例的输入序列的长度。 例如：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">reset_graph</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">seq_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">])</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">basic_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                    <span class="n">sequence_length</span><span class="o">=</span><span class="n">seq_length</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>例如，假设第二个输入序列只包含一个输入而不是两个输入。 为了适应输入张量<code>X</code>，必须填充零向量（因为输入张量的第二维是最长序列的大小，即 2）</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="c1"># step 0     step 1</span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="c1"># instance 1</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="c1"># instance 2 (padded with zero vectors)</span>
        <span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="c1"># instance 3</span>
        <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="c1"># instance 4</span>
    <span class="p">])</span>
<span class="n">seq_length_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</td></tr></table>

<p>当然，你现在需要为两个占位符<code>X</code>和<code>seq_length</code>提供值：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">outputs_val</span><span class="p">,</span> <span class="n">states_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="p">[</span><span class="n">outputs</span><span class="p">,</span> <span class="n">states</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">:</span> <span class="n">seq_length_batch</span><span class="p">})</span>
</pre></div>
</td></tr></table>

<p>现在，RNN 输出序列长度的每个时间步都会输出零向量（查看第二个时间步的第二个输出）：</p>
<p><img alt="" src="../../images/chapter_14/o-14-2.png" /></p>
<p>此外，状态张量包含每个单元的最终状态（不包括零向量）：</p>
<p><img alt="" src="../../images/chapter_14/o-14-3.png" /></p>
<h2 id="_8">处理变长输出序列<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<p>如果输出序列长度不一样呢？ 如果事先知道每个序列的长度（例如，如果知道长度与输入序列的长度相同），那么可以按照上面所述设置<code>sequence_length</code>参数。 不幸的是，通常这是不可能的：例如，翻译后的句子的长度通常与输入句子的长度不同。 在这种情况下，最常见的解决方案是定义一个称为序列结束标记（EOS 标记）的特殊输出。 任何在 EOS 后面的输出应该被忽略（我们将在本章稍后讨论）。</p>
<p>好，现在你知道如何建立一个 RNN 网络（或者更准确地说是一个随着时间的推移而展开的 RNN 网络）。 但是你怎么训练呢？</p>
<h2 id="rnn">训练 RNN<a class="headerlink" href="#rnn" title="Permanent link">&para;</a></h2>
<p>为了训练一个 RNN，诀窍是在时间上展开（就像我们刚刚做的那样），然后简单地使用常规反向传播（见图 14-5）。 这个策略被称为时间上的反向传播（BPTT）。</p>
<p><img alt="" src="../../images/chapter_14/14-5.png" /></p>
<p>就像在正常的反向传播中一样，展开的网络（用虚线箭头表示）有第一个正向传递。然后使用损失函数评估输出序列 <img alt="" src="../../images/chapter_14/o-14-4.png" />（其中 <img alt="t_{min}" src="../../images/tex-e703e1ba18d3838a4834b8529afbddff.gif" /> 和 <img alt="t_{max}" src="../../images/tex-afdc190074a7e451cec25ee2fde23fa2.gif" /> 是第一个和最后一个输出时间步长，不计算忽略的输出），并且该损失函数的梯度通过展开的网络向后传播（实线箭头）；最后使用在 BPTT 期间计算的梯度来更新模型参数。 请注意，梯度在损失函数所使用的所有输出中反向流动，而不仅仅通过最终输出（例如，在图 14-5 中，损失函数使用网络的最后三个输出 <img alt="Y^{(2)}" src="../../images/tex-a0b673959034f5d7721eda22ec8f8a59.gif" />，<img alt="Y^{(3)}" src="../../images/tex-a9fd2d0f4eafa552b514c6a68092a08c.gif" /> 和 <img alt="Y^{(4)}" src="../../images/tex-966fcc27b1359fe6160829661f0657cc.gif" />，所以梯度流经这三个输出，但不通过 <img alt="Y^{(0)}" src="../../images/tex-347b979a3eaaf423a7c376ba475f1313.gif" /> 和 <img alt="Y^{(1)}" src="../../images/tex-44e3acde9f1b11682289b6069b6f2a1f.gif" />）。 而且，由于在每个时间步骤使用相同的参数<code>W</code>和<code>b</code>，所以反向传播将做正确的事情并且总结所有时间步骤。</p>
<h2 id="_9">训练序列分类器<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<p>我们训练一个 RNN 来分类 MNIST 图像。 卷积神经网络将更适合于图像分类（见第 13 章），但这是一个你已经熟悉的简单例子。 我们将把每个图像视为 28 行 28 像素的序列（因为每个MNIST图像是<code>28×28</code>像素）。 我们将使用 150 个循环神经元的单元，再加上一个全连接层，其中包含连接到上一个时间步的输出的 10 个神经元（每个类一个），然后是一个 softmax 层（见图 14-6）。</p>
<p><img alt="" src="../../images/chapter_14/14-6.png" /></p>
<p>建模阶段非常简单， 它和我们在第 10 章中建立的 MNIST 分类器几乎是一样的，只是展开的 RNN 替换了隐层。 注意，全连接层连接到状态张量，其仅包含 RNN 的最终状态（即，第 28 个输出）。 另请注意，<code>y</code>是目标类的占位符。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">])</span>

<span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">basic_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
<span class="n">xentropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                                                          <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">xentropy</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">in_top_k</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>现在让我们加载 MNIST 数据，并按照网络的预期方式将测试数据重塑为<code>[batch_size, n_steps, n_inputs]</code>。 我们之后会关注训练数据的重塑。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;/tmp/data/&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span>
</pre></div>
</td></tr></table>

<p>现在我们准备训练 RNN 了。 执行阶段与第 10 章中 MNIST 分类器的执行阶段完全相同，不同之处在于我们在将每个训练的批量提供给网络之前要重新调整。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">150</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">))</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">training_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_batch</span><span class="p">})</span>
        <span class="n">acc_train</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_batch</span><span class="p">})</span>
        <span class="n">acc_test</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_test</span><span class="p">})</span>
        <span class="k">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="s2">&quot;Train accuracy:&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Test accuracy:&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>输出应该是这样的：</p>
<p><img alt="" src="../../images/chapter_14/o-14-5.png" /></p>
<p>我们获得了超过 98% 的准确性 - 不错！ 另外，通过调整超参数，使用 He 初始化初始化 RNN 权重，更长时间训练或添加一些正则化（例如，droupout），你肯定会获得更好的结果。</p>
<p>你可以通过将其构造代码包装在一个变量作用域内（例如，使用<code>variable_scope("rnn", initializer = variance_scaling_initializer())</code>来使用 He 初始化）来为 RNN 指定初始化器。</p>
<h2 id="_10">为预测时间序列而训练<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<p>现在让我们来看看如何处理时间序列，如股价，气温，脑电波模式等等。 在本节中，我们将训练一个 RNN 来预测生成的时间序列中的下一个值。 每个训练实例是从时间序列中随机选取的 20 个连续值的序列，目标序列与输入序列相同，除了向后移动一个时间步（参见图14-7）。</p>
<p><img alt="" src="../../images/chapter_14/14-7.png" /></p>
<p>首先，我们来创建一个 RNN。 它将包含 100 个循环神经元，并且我们将在 20 个时间步骤上展开它，因为每个训练实例将是 20 个输入那么长。 每个输入将仅包含一个特征（在该时间的值）。 目标也是 20 个输入的序列，每个输入包含一个值。 代码与之前几乎相同：</p>
<p><img alt="" src="../../images/chapter_14/o-14-6.png" /></p>
<p>一般来说，你将不只有一个输入功能。 例如，如果你试图预测股票价格，则你可能在每个时间步骤都会有许多其他输入功能，例如竞争股票的价格，分析师的评级或可能帮助系统进行预测的任何其他功能。</p>
<p>在每个时间步，我们现在有一个大小为 100 的输出向量。但是我们实际需要的是每个时间步的单个输出值。 最简单的解决方法是将单元包装在<code>OutputProjectionWrapper</code>中。 单元包装器就像一个普通的单元，代理每个方法调用一个底层单元，但是它也增加了一些功能。<code>Out putProjectionWrapper</code>在每个输出之上添加一个完全连接的线性神经元层（即没有任何激活函数）（但不影响单元状态）。 所有这些完全连接的层共享相同（可训练）的权重和偏差项。 结果 RNN 如图 14-8 所示。</p>
<p><img alt="" src="../../images/chapter_14/14-8.png" /></p>
<p>包装单元是相当容易的。 让我们通过将<code>BasicRNNCell</code>包装到<code>OutputProjectionWrapper</code>中来调整前面的代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">cell</span> <span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">OutputProjectionWrapper</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
    <span class="n">output_size</span><span class="o">=</span><span class="n">n_outputs</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>到现在为止还挺好。 现在我们需要定义损失函数。 我们将使用均方误差（MSE），就像我们在之前的回归任务中所做的那样。 接下来，我们将像往常一样创建一个 Adam 优化器，训练操作和变量初始化操作：</p>
<h3 id="rnn_1">生成 RNN<a class="headerlink" href="#rnn_1" title="Permanent link">&para;</a></h3>
<p>到现在为止，我们已经训练了一个能够预测未来时刻样本值的模型，正如前文所述，可以用模型来生成新的序列。</p>
<p>为模型提供 长度为<code>n_steps</code>的种子序列, 比如全零序列，然后通过模型预测下一时刻的值；把该预测值添加到种子序列的末尾，用最后面 长度为<code>n_steps</code>的序列做为新的种子序列，做下一次预测，以此类推生成预测序列。</p>
<p>如图 14-11 所示，这个过程产生的序列会跟原始时间序列相似。</p>
<p><img alt="Figure 14-11" src="../../images/chapter_14/14-11.PNG" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_steps</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="o">-</span><span class="n">n_steps</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">X_batch</span><span class="p">}</span>
    <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<p>如果你试图把约翰·列侬的唱片塞给一个 RNN 模型，看它能不能生成下一张《想象》专辑。</p>
<blockquote>
<p>注</p>
<p>约翰·列侬 有一张专辑《Imagine》（1971），这里取其双关的意思</p>
</blockquote>
<p>也许你需要一个更强大的 RNN 网络，它有更多的神经元，层数也更多。下面来探究一下深度 RNN。</p>
<h2 id="rnn_2">深度 RNN<a class="headerlink" href="#rnn_2" title="Permanent link">&para;</a></h2>
<p>一个朴素的想法就是把一层层神经元堆叠起来，正如图 14-12 所示的那样，它呈现了一种深度 RNN。</p>
<p><img alt="Figure 14-12" src="../../images/chapter_14/14-12.PNG" /></p>
<p>为了用 TensorFlow 实现深度 RNN，可先创建一些神经单元，然后堆叠进<code>MultiRNNCell</code>。</p>
<p>以下代码中创建了 3 个相同的神经单元（当然也可以用不同类别的、包含不同不同数量神经元的单元）</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">basic_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">multi_layer_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">basic_cell</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_layers</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">multi_layer_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这些代码就完成了这部分堆叠工作。<code>status</code>变量包含了每层的一个张量，这个张量就代表了该层神经单元的最终状态（维度为<code>[batch_size, n_neurons]</code>）。</p>
<p>如果在创建<code>MultiRNNCell</code>时设置了<code>state_is_tuple=False</code>，那么<code>status</code>变量就变成了单个张量，它包含了每一层的状态，其在列的方向上进行了聚合，维度为<code>[batch_size, n_layers*n_neurons]</code>。</p>
<p>注意在 TensorFlow 版本 0.11.0 之前，<code>status</code>是单个张量是默认设置。</p>
<h2 id="gpu-rnn">在多个 GPU 上分布式部署深度 RNN 网络<a class="headerlink" href="#gpu-rnn" title="Permanent link">&para;</a></h2>
<h2 id="dropout">Dropout 的应用<a class="headerlink" href="#dropout" title="Permanent link">&para;</a></h2>
<p>对于深层深度 RNN，在训练集上很容易过拟合。Dropout 是防止过拟合的常用技术。</p>
<p>可以简单的在 RNN 层之前或之后添加一层 Dropout 层，但如果需要在 RNN 层之间应用 Dropout 技术就需要<code>DropoutWrapper</code>。</p>
<p>下面的代码中，每一层的 RNN 的输入前都应用了 Dropout，Dropout 的概率为 50%。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">cell_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">input_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
<span class="n">multi_layer_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">cell_drop</span><span class="p">]</span><span class="o">*</span><span class="n">n_layers</span><span class="p">)</span>
<span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">multi_layer_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>同时也可以通过设置<code>output_keep_prob</code>来在输出应用 Dropout 技术。</p>
<p>然而在以上代码中存在的主要问题是，Dropout 不管是在训练还是测试时都起作用了，而我们想要的仅仅是在训练时应用 Dropout。</p>
<p>很不幸的是<code>DropoutWrapper</code>不支持<code>is_training</code>这样一个设置选项。因此必须自己写 Dropout 包装类，或者创建两个计算图，一个用来训练，一个用来测试。后则可通过如下面代码这样实现。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">is_training</span>  <span class="o">=</span> <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">])</span>
<span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="k">if</span> <span class="n">is_training</span><span class="p">:</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">input_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
<span class="n">multi_layer_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">cell</span><span class="p">]</span><span class="o">*</span><span class="n">n_layers</span><span class="p">)</span>
<span class="n">rnn_outpus</span><span class="p">,</span> <span class="n">status</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">multi_layer_cell</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># bulid the rest of the graph</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">is_training</span><span class="p">:</span>
        <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
            <span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># train the model</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;/tmp/my_model.ckpt&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;/tmp/my_model.ckpt&quot;</span><span class="p">)</span>
        <span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># use the model</span>
</pre></div>
</td></tr></table>

<p>通过以上的方法就能够训练各种 RNN 网络了。然而对于长序列的 RNN 训练还言之过早，事情会变得有一些困难。</p>
<p>那么我们来探讨一下究竟这是为什么和怎么应对呢？</p>
<h2 id="_11">长时训练的困难<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<p>在训练长序列的 RNN 模型时，那么就需要把 RNN 在时间维度上展开成很深的神经网络。正如任何深度神经网络一样，其面临着梯度消失/爆炸的问题，使训练无法终止或收敛。</p>
<p>很多之前讨论过的缓解这种问题的技巧都可以应用在深度展开的 RNN 网络：好的参数初始化方式，非饱和的激活函数（如 ReLU），批量规范化（Batch Normalization）， 梯度截断（Gradient Clipping），更快的优化器。</p>
<p>即便如此， RNN 在处理适中的长序列（如 100 输入序列）也在训练时表现的很慢。</p>
<p>最简单和常见的方法解决训练时长问题就是在训练阶段仅仅展开限定时间步长的 RNN 网络，一种称为截断时间反向传播的算法。</p>
<p>在 TensorFlow 中通过截断输入序列来简单实现这种功能。例如在时间序列预测问题上可以在训练时减小<code>n_steps</code>来实现截断。理所当然这种方法会限制模型在长期模式的学习能力。一种变通方案时确保缩短的序列中包含旧数据和新数据，从而使模型获得两者信息（如序列同时包含最近五个月的数据，最近五周的和最近五天的数据）。</p>
<p>问题时如何确保从去年的细分类中获取的数据有效性呢？这期间短暂但重要的事件对后世的影响，甚至时数年后这种影响是否一定要考虑在内呢（如选举结果）？这种方案有其先天的不足之处。</p>
<p>在长的时间训练过程中，第二个要面临的问题时第一个输入的记忆会在长时间运行的 RNN 网络中逐渐淡去。确实，通过变换的方式，数据穿流在 RNN 网络之中，每个时间步长后都有一些信息被抛弃掉了。那么在一定时间后，第一个输入实际上会在 RNN 的状态中消失于无形。</p>
<p>比如说，你想要分析长篇幅的影评的情感类别，影评以<code>"I love this movie"</code>开篇，并辅以各种改善影片的一些建议。试想一下，如果 RNN 网络逐渐忘记了开头的几个词，RNN 网络的判断完全有可能会对影评断章取义。</p>
<p>为了解决其中的问题，各种能够携带长时记忆的神经单元的变体被提出。这些变体是有效的，往往基本形式的神经单元就不怎么被使用了。</p>
<p>首先了解一下最流行的一种长时记忆神经单元：长短时记忆神经单元 LSTM。</p>
<h2 id="lstm">LSTM 单元<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h2>
<p>长短时记忆单元在 1997 年<a href="https://goo.gl/j39AGv">由 S.H. 和 J.S. 首次提出</a> [3]，并在接下来的几年内经过 <a href="https://goo.gl/6BHh81">A.G，H.S</a> [4]，<a href="https://goo.gl/SZ9kzB">W.Z</a> [5] 等数位研究人员的改进逐渐形成。如果把 LSTM 单元看作一个黑盒，从外围看它和基本形式的记忆单元很相似，但 LSTM 单元会比基本单元性能更好，收敛更快，能够感知数据的长时依赖。TensorFlow 中通过<code>BasicLSTMCell</code>实现 LSTM 单元。</p>
<blockquote>
<p>[3]: "Long Short-Term Memory," S.Hochreiter and J.Schmidhuber(1997)</p>
<p>[4]: "Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling," H.Sak et al.(2014)</p>
<p>[5]: "Recurrent Neural Network Regularization," W.Zaremba et al.(2015)</p>
</blockquote>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>LSTM 单元的工作机制是什么呢？在图 14-13 中展示了基本 LSTM 单元的结构。</p>
<p><img alt="Figure 14-13" src="../../images/chapter_14/14-13.PNG" /></p>
<p>不观察 LSTM 单元内部，除了一些不同外跟常规 RNN 单元极其相似。这些不同包括 LSTM 单元状态分为两个向量：<img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" /> 和 <img alt="c^{(t)}" src="../../images/tex-d995862557c7577156d8598bbd676ff7.gif" />（<code>c</code>代表 cell）。可以简单认为 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" /> 是短期记忆状态，<img alt="c^{(t)}" src="../../images/tex-d995862557c7577156d8598bbd676ff7.gif" /> 是长期记忆状态。</p>
<p>好，我们来打开盒子。LSTM 单元的核心思想是其能够学习从长期状态中存储什么，忘记什么，读取什么。长期状态 <img alt="c^{(t-1)}" src="../../images/tex-a61d3a5d3cda282b36fe4a3fe7e657c1.gif" /> 从左向右在网络中传播，依次经过遗忘门（forget gate）时丢弃一些记忆，之后加法操作增加一些记忆（从输入门中选择一些记忆）。输出 <img alt="c^{(t)}" src="../../images/tex-d995862557c7577156d8598bbd676ff7.gif" /> 不经任何转换直接输出。每个单位时间步长后，都有一些记忆被抛弃，新的记忆被添加进来。另一方面，长时状态经过 tanh 激活函数通过输出门得到短时记忆 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" />，同时它也是这一时刻的单元输出结果 <img alt="y^{(t)}" src="../../images/tex-cc685401bcf131ce4e9f980be319daac.gif" />。接下来讨论一下新的记忆时如何产生的，门的功能是如何实现的。</p>
<p>首先，当前的输入向量 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 和前一时刻的短时状态 <img alt="h^{(t-1)}" src="../../images/tex-c94af4bec72c7e4e9e8f713c23232809.gif" /> 作为输入传给四个全连接层，这四个全连接层有不同的目的：</p>
<ul>
<li>其中主要的全连接层输出 <img alt="g^{(t)}" src="../../images/tex-ededcb90b8071069a783dea14b4aad14.gif" />，它的常规任务就是解析当前的输入 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 和前一时刻的短时状态 <img alt="h^{(t-1)}" src="../../images/tex-c94af4bec72c7e4e9e8f713c23232809.gif" />。在基本形式的 RNN 单元中，就与这种形式一样，直接输出了 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" />  和 <img alt="y^{(t)}" src="../../images/tex-cc685401bcf131ce4e9f980be319daac.gif" />。与之不同的是 LSTM 单元会将一部分 <img alt="g^{(t)}" src="../../images/tex-ededcb90b8071069a783dea14b4aad14.gif" /> 存储在长时状态中。</li>
<li>其它三个全连接层被称为门控制器（gate controller）。其采用 Logistic 作为激活函数，输出范围在 0 到 1 之间。正如在结构图中所示，这三个层的输出提供给了逐元素乘法操作，当输入为 0 时门关闭，输出为 1 时门打开。分别为：    <ul>
<li>遗忘门（forget gat）由 <img alt="f^{(t)}" src="../../images/tex-62f824d21d48162194f6ab54c819b0cc.gif" /> 控制，来决定哪些长期记忆需要被擦除；</li>
<li>输入门（input gate） 由 <img alt="i^{(t)}" src="../../images/tex-94eb8618287f30c0e8acb55826546dd1.gif" /> 控制，它的作用是处理哪部分 <img alt="g^{(t)}" src="../../images/tex-ededcb90b8071069a783dea14b4aad14.gif" /> 应该被添加到长时状态中，也就是为什么被称为<strong>部分存储</strong>。</li>
<li>输出门（output gate）由 <img alt="o^{(t)}" src="../../images/tex-8c4d6f1775020db40e7f11387a98b5ab.gif" /> 控制，在这一时刻的输出 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" /> 和 <img alt="y^{(t)}" src="../../images/tex-cc685401bcf131ce4e9f980be319daac.gif" /> 就是由输出门控制的，从长时状态中读取的记忆。</li>
</ul>
</li>
</ul>
<p>简要来说，LSTM 单元能够学习到识别重要输入（输入门作用），存储进长时状态，并保存必要的时间（遗忘门功能），并学会提取当前输出所需要的记忆。</p>
<p>这也解释了 LSTM 单元能够在提取长时序列，长文本，录音等数据中的长期模式的惊人成功的原因。</p>
<p>公式 14-3 总结了如何计算单元的长时状态，短时状态，和单个输入情形时每单位步长的输出（小批量的方程形式与单输入的形式相似）。</p>
<p><img alt="Equation 14-3" src="../../images/chapter_14/14-3E.PNG" /></p>
<ul>
<li><img alt="W_{xi}" src="../../images/tex-d5f696a5a6696de34b0622a8f14b4516.gif" />，<img alt="W_{xf}" src="../../images/tex-d038d062c32d4dc01937728b95d25e0e.gif" />，<img alt="W_{xo}" src="../../images/tex-6ffd6603299e89df0513e4d1b9d67637.gif" />，<img alt="W_{xg}" src="../../images/tex-9e957014b85eb320bc79506f6fc8c80b.gif" /> 是四个全连接层关于输入向量 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 的权重。</li>
<li><img alt="W_{hi}" src="../../images/tex-f60ef6008ce0d9eac12ac8a81cb64981.gif" />，<img alt="W_{hf}" src="../../images/tex-07d3e0eb59fb1b95dc15ecc6cb36a65c.gif" />，<img alt="W_{ho}" src="../../images/tex-c0b288b67c4f03e4fa7d866233a1c91c.gif" />，<img alt="W_{hg}" src="../../images/tex-47a1cfce155783c735e46b38d6513419.gif" /> 是四个全连接层关于上一时刻的短时状态 <img alt="h^{(t-1)}" src="../../images/tex-c94af4bec72c7e4e9e8f713c23232809.gif" /> 的权重。</li>
<li><img alt="b_i" src="../../images/tex-fe3e01a305f27284ff5115f4c5ea0fa4.gif" />，<img alt="b_f" src="../../images/tex-8b9664471b48978a8d67e67efdbf131d.gif" />，<img alt="b_o" src="../../images/tex-cd5404d7725e8dc13bb35de8c3a6fdf2.gif" />，<img alt="b_g" src="../../images/tex-56ac14615d54896bf04d40cde6bc37f7.gif" /> 是全连接层的四个偏置项，需要注意的是 TensorFlow 将其初始化为全 1 向量，而非全 0，为了阻止网络初始训练状态下，各个门关闭从而忘记所有记忆。</li>
</ul>
<h3 id="_12">窥孔连接<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h3>
<p>基本形式的 LSTM 单元中，门的控制仅有当前的输入 <img alt="x^{(t)}" src="../../images/tex-df9ed87e836e463cd086106035aef441.gif" /> 和前一时刻的短时状态 <img alt="h^{(t-1)}" src="../../images/tex-c94af4bec72c7e4e9e8f713c23232809.gif" />。不妨让各个控制门窥视一下长时状态，获取一些上下文信息不失为一种尝试。<a href="https://goo.gl/ch8xz3">该想法</a>由 F.G.he J.S. 在 2000 年提出。他们提出的 LSTM 的变体拥有叫做窥孔连接的额外连接：把前一时刻的长时状态 <img alt="c^{(t-1)}" src="../../images/tex-a61d3a5d3cda282b36fe4a3fe7e657c1.gif" /> 加入遗忘门和输入门控制的输入，当前时刻的长时状态加入输出门的控制输入。</p>
<p>TensorFLow 中由<code>LSTMCell</code>实现以上变体 LSTM，并设置<code>use_peepholes=True</code>。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">use_peepholes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>在众多 LSTM 变体中，一个特别流行的变体就是 GRU 单元。</p>
<h2 id="gru">GRU 单元<a class="headerlink" href="#gru" title="Permanent link">&para;</a></h2>
<p><img alt="Figure 14-14" src="../../images/chapter_14/14-14.PNG" /></p>
<p>门控循环单元（图 14-14）在 2014 年的 <a href="http://goo.gl/ZnAEOZ">K.Cho et al. 的论文</a>中提出，并且此文也引入了前文所述的编解码网络。</p>
<p>门控循环单元是 LSTM 单元的简化版本，能实现同样的性能，这也说明了为什么它能越来越流行。简化主要在一下几个方面：</p>
<ul>
<li>长时状态和短时状态合并为一个向量 <img alt="h^{(t)}" src="../../images/tex-7ddb4d2d45df22e2e98e6cc504f84787.gif" />。</li>
<li>用同一个门控制遗忘门和输入门。如果门控制输入 1，输入门打开，遗忘门关闭，反之亦然。也就是说，如果当有新的记忆需要存储，那么就必须实现在其对应位置事先擦除该处记忆。这也构成了 LSTM 本身的常见变体。</li>
<li>GRU 单元取消了输出门，单元的全部状态就是该时刻的单元输出。与此同时，增加了一个控制门 <img alt="r^{(t)}" src="../../images/tex-fd4cd5a78b3b4c8a13ed0184d6ca84b7.gif" /> 来控制哪部分前一时间步的状态在该时刻的单元内呈现。</li>
</ul>
<p><img alt="Equation 14-4" src="../../images/chapter_14/14-4E.PNG" /></p>
<p>公式 14-4 总结了如何计算单个输入情形时每单位步的单元的状态。</p>
<p>在 TensoFlow 中创建 GRU 单元很简单：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">gru_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">n_units</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>LSTM 或 GRU 单元是近年来 RNN 成功背后的主要原因之一，特别是在自然语言处理（NLP）中的应用。</p>
<h2 id="_13">自然语言处理<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<p>现在，大多数最先进的 NLP 应用（如机器翻译，自动摘要，解析，情感分析等），现在（至少一部分）都基于 RNN。 在最后一节中，我们将快速了解机器翻译模型的概况。 TensorFlow 的很厉害的 <a href="https://goo.gl/edArdi">Word2Vec</a> 和 <a href="https://goo.gl/L82gvS">Seq2Seq</a> 教程非常好地介绍了这个主题，所以你一定要阅读一下。</p>
<h3 id="_14">单词嵌入<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<p>在我们开始之前，我们需要选择一个词的表示形式。 一种选择可以是，使用单热向量表示每个词。 假设你的词汇表包含 5 万个单词，那么第<code>n</code>个单词将被表示为 50,000 维的向量，除了第<code>n</code>个位置为 1 之外，其它全部为 0。 然而，对于如此庞大的词汇表，这种稀疏表示根本就不会有效。 理想情况下，你希望相似的单词具有相似的表示形式，这使得模型可以轻松地将所学的关于单词的只是，推广到所有相似单词。 例如，如果模型被告知<code>"I drink milk"</code>是一个有效的句子，并且如果它知道<code>"milk"</code>接近于<code>"water"</code>，而不同于<code>"shoes"</code>，那么它会知道<code>"I drink water"</code> 也许是一个有效的句子，而<code>"I drink shoes"</code>可能不是。 但你如何提出这样一个有意义的表示呢？</p>
<p>最常见的解决方案是，用一个相当小且密集的向量（例如 150 维）表示词汇表中的每个单词，称为嵌入，并让神经网络在训练过程中，为每个单词学习一个良好的嵌入。 在训练开始时，嵌入只是随机选择的，但在训练过程中，反向传播会自动更新嵌入，来帮助神经网络执行任务。 通常这意味着，相似的词会逐渐彼此靠近，甚至最终以一种相当有意义的方式组织起来。 例如，嵌入可能最终沿着各种轴分布，它们代表性别，单数/复数，形容词/名词。 结果可能真的很神奇。</p>
<p>在TensorFlow中，首先需要创建一个变量来表示词汇表中每个词的嵌入（随机初始化）：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<p>现在假设你打算将句子<code>"I drink milk"</code>提供给你的神经网络。 你应该首先对句子进行预处理并将其分解成已知单词的列表。 例如，你可以删除不必要的字符，用预定义的标记词（如<code>"[UNK]"</code>）替换未知单词，用<code>"[NUM]"</code>替换数字值，用<code>"[URL]"</code>替换 URL 等。 一旦你有了一个已知单词列表，你可以在字典中查找每个单词的整数标识符（从 0 到 49999），例如<code>[72，3335，288]</code>。 此时，你已准备好使用占位符将这些单词标识符提供给 TensorFlow，并应用<code>embedding_lookup()</code>函数来获取相应的嵌入：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">train_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">])</span>  <span class="c1"># from ids...</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">train_inputs</span><span class="p">)</span>  <span class="c1"># ...to embeddings</span>
</pre></div>
</td></tr></table>

<p>一旦你的模型习得了良好的词嵌入，它们实际上可以在任何 NLP 应用中高效复用：毕竟，<code>"milk"</code>依然接近于<code>"water"</code>，而且不管你的应用是什么，它都不同于<code>"shoes"</code>。 实际上，你可能需要下载预训练的单词嵌入，而不是训练自己的单词嵌入。 就像复用预训练层（参见第 11 章）一样，你可以选择冻结预训练嵌入（例如，使用<code>trainable=False</code>创建嵌入变量），或者让反向传播为你的应用调整它们。 第一种选择将加速训练，但第二种选择可能会产生稍高的性能。</p>
<blockquote>
<p>提示</p>
<p>对于表示可能拥有大量不同值的类别属性，嵌入也很有用，特别是当值之间存在复杂的相似性的时候。 例如，考虑职业，爱好，菜品，物种，品牌等。</p>
</blockquote>
<p>你现在拥有了实现机器翻译系统所需的几乎所有的工具。 现在我们来看看它吧。</p>
<h3 id="_15">用于机器翻译的编解码器网络<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h3>
<p>让我们来看看简单的机器翻译模型，它将英语句子翻译成法语（参见图 14-15）。</p>
<p><img alt="" src="../../images/chapter_14/14-15.jpg" /></p>
<p>图 14-15：简单的机器翻译模型</p>
<p>英语句子被送进编码器，解码器输出法语翻译。 请注意，法语翻译也被用作解码器的输入，但后退了一步。 换句话说，解码器的输入是它应该在前一步输出的字（不管它实际输出的是什么）。 对于第一个单词，提供了表示句子开始的标记（<code>"&lt;go&gt;"</code>）。 解码器预期以序列末尾标记（EOS）结束句子（<code>"&lt;eos&gt;"</code>）。</p>
<p>请注意，英语句子在送入编码器之前会反转。 例如，<code>"I drink milk"</code>与<code>"milk drink I"</code>相反。这确保了英语句子的开头将会最后送到编码器，这很有用，因为这通常是解码器需要翻译的第一个东西。</p>
<p>每个单词最初由简单整数标识符表示（例如，单词<code>"milk"</code>为 288）。 接下来，嵌入查找返回词的嵌入（如前所述，这是一个密集的，相当低维的向量）。 这些词的嵌入是实际送到编码器和解码器的内容。</p>
<p>在每个步骤中，解码器输出输出词汇表（即法语）中每个词的得分，然后 Softmax 层将这些得分转换为概率。 例如，在第一步中，单词<code>"Je"</code>有 20% 的概率，<code>"Tu"</code>有 1% 的概率，以此类推。 概率最高的词会输出。 这非常类似于常规分类任务，因此你可以使用<code>softmax_cross_entropy_with_logits()</code>函数来训练模型。</p>
<p>请注意，在推断期间（训练之后），你不再将目标句子送入解码器。 相反，只需向解码器提供它在上一步输出的单词，如图 14-16 所示（这将需要嵌入查找，它未在图中显示）。</p>
<p>图 14-16：在推断期间，将之前的输出单词提供为输入</p>
<p>好的，现在你有了大方向。 但是，如果你阅读 TensorFlow 的序列教程，并查看<code>rnn/translate/seq2seq_model.py</code>中的代码（在 TensorFlow 模型中），你会注意到一些重要的区别：</p>
<ul>
<li>
<p>首先，到目前为止，我们已经假定所有输入序列（编码器和解码器的）具有恒定的长度。但显然句子长度可能会有所不同。有几种方法可以处理它 - 例如，使用<code>static_rnn()</code>或<code>dynamic_rnn()</code>函数的<code>sequence_length</code>参数，来指定每个句子的长度（如前所述）。然而，教程中使用了另一种方法（大概是出于性能原因）：句子分到长度相似的桶中（例如，句子的单词 1 到 6 分到一个桶，单词 7 到 12 分到另一个桶，等等），并且使用特殊的填充标记（例如<code>"&lt;pad&gt;"</code>）来填充较短的句子。例如，<code>"I drink milk"</code>变成<code>"&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; milk drink I"</code>，翻译成<code>"Je bois du lait &lt;eos&gt; &lt;pad&gt;"</code>。当然，我们希望忽略任何 EOS 标记之后的输出。为此，本教程的实现使用<code>target_weights</code>向量。例如，对于目标句子<code>"Je bois du lait &lt;eos&gt; &lt;pad&gt;"</code>，权重将设置为<code>[1.0,1.0,1.0,1.0,1.0,0.0]</code>（注意权重 0.0 对应目标句子中的填充标记）。简单地将损失乘以目标权重，将消除对应 EOS 标记之后的单词的损失。</p>
</li>
<li>
<p>其次，当输出词汇表很大时（就是这里的情况），输出每个可能的单词的概率将会非常慢。 如果目标词汇表包含 50,000 个法语单词，则解码器将输出 50,000 维向量，然后在这样的大向量上计算 softmax 函数，计算量将非常大。 为了避免这种情况，一种解决方案是让解码器输出更小的向量，例如 1,000 维向量，然后使用采样技术来估计损失，而不必对目标词汇表中的每个单词计算它。 这种采样 Softmax 技术是由 SébastienJean 等人在 2015 年提出的。在 TensorFlow 中，你可以使用<code>sampled_softmax_loss()</code>函数。</p>
</li>
<li>
<p>第三，教程的实现使用了一种注意力机制，让解码器能够窥视输入序列。 注意力增强的 RNN 不在本书的讨论范围之内，但如果你有兴趣，可以关注机器翻译，机器阅读和图像说明的相关论文。</p>
</li>
<li>
<p>最后，本教程的实现使用了<code>tf.nn.legacy_seq2seq</code>模块，该模块提供了轻松构建各种编解码器模型的工具。 例如，<code>embedding_rnn_seq2seq()</code>函数会创建一个简单的编解码器模型，它会自动为你处理单词嵌入，就像图 14-15 中所示的一样。 此代码可能会很快更新，来使用新的<code>tf.nn.seq2seq</code>模块。</p>
</li>
</ul>
<p>你现在拥有了，了解所有 seq2seq 教程的实现所需的全部工具。 将它们取出，并训练你自己的英法翻译器吧！</p>
<h2 id="_16">练习<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<ol>
<li>你能想象 seq2seq RNN 的几个应用吗？ seq2vec 的 RNN 呢？vex2seq 的 RNN 呢？</li>
<li>为什么人们使用编解码器 RNN 而不是简单的 seq2seq RNN 来自动翻译？</li>
<li>如何将卷积神经网络与 RNN 结合，来对视频进行分类？</li>
<li>使用<code>dynamic_rnn()</code>而不是<code>static_rnn()</code>构建 RNN 有什么好处？</li>
<li>你如何处理长度可变的输入序列？ 那么长度可变输出序列呢？</li>
<li>在多个 GPU 上分配深层 RNN 的训练和执行的常见方式是什么？</li>
<li>Hochreiter 和 Schmidhuber 在其关于 LSTM 的文章中使用了嵌入式 Reber 语法。 它们是产生字符串，如<code>"BPBTSXXVPSEPE"</code>的人造语法。查看 Jenny Orr 对此主题的<a href="https://goo.gl/7CkNRn">不错的介绍</a>。 选择一个特定的嵌入式 Reber 语法（例如 Jenny Orr 页面上显示的语法），然后训练一个 RNN 来确定字符串是否遵循该语法。 你首先需要编写一个函数，该函数能够生成训练批量，包含大约 50% 遵循语法的字符串，以及 50% 不遵循的字符串。</li>
<li>解决“How much did it rain? II”（下雨下了多久 II）<a href="https://goo.gl/0DS5Xe">Kaggle 比赛</a>。 这是一个时间序列预测任务：它为你提供极化雷达值的快照，并要求预测每小时降水量。 Luis Andre Dutra e Silva 的<a href="https://goo.gl/fTA90W">采访</a>对他在比赛中获得第二名的技术，提供了一些有趣的见解。 特别是，他使用了由两个 LSTM 层组成的 RNN。</li>
<li>通过 TensorFlow 的 <a href="https://goo.gl/edArdi">Word2Vec</a> 教程来创建单词嵌入，然后通过 <a href="https://goo.gl/L82gvS">Seq2Seq</a> 教程来训练英法翻译系统。</li>
</ol>
<p>附录 A 提供了这些练习的答案。</p>
                
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://hai5g.cn/aiwiki/hands-on-ml-zh/docs/14.循环神经网络/";
      this.page.identifier =
        "/hands-on-ml-zh/docs/14.循环神经网络/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//AI-Wiki.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../13.卷积神经网络/" title="卷积神经网络" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                卷积神经网络
              </span>
            </div>
          </a>
        
        
          <a href="../15.自编码器/" title="自编码器" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                自编码器
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 AI Wiki Team
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.39abc4af.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdn.jsdelivr.net/gh/ethantw/Han@3.3.0/dist/han.min.js"></script>
      
        <script src="../../../_static/js/extra.js?v=10"></script>
      
        <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>