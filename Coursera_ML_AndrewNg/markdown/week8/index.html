



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="AI Wiki 是一个编程竞赛知识整合站点，提供有趣又实用的编程竞赛知识以及其他有帮助的内容，帮助广大编程竞赛爱好者更快更深入地学习编程竞赛">
      
      
        <link rel="canonical" href="https://hai5g.cn/aiwiki/Coursera_ML_AndrewNg/markdown/week8/">
      
      
        <meta name="author" content="AI Wiki Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>week8 - AI Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,400i,700|Fira+Mono">
        <style>body,input{font-family:"Fira Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Fira Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
      <link rel="manifest" href="../../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/ah@1.5.0/han.min.css">
    
      <link rel="stylesheet" href="../../../_static/css/extra.css?v=11">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#8" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              AI Wiki
            </span>
            <span class="md-header-nav__topic">
              week8
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="简介" class="md-tabs__link">
          简介
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../" title="机器学习" class="md-tabs__link md-tabs__link--active">
          机器学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../qa500/" title="深度学习500问" class="md-tabs__link">
          深度学习500问
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../lihang/" title="统计学习" class="md-tabs__link">
          统计学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../hands-on-ml-zh/README.old/" title="Sklearn与TensorFlow" class="md-tabs__link">
          Sklearn与TensorFlow
        </a>
      
    </li>
  

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    AI Wiki
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/AI学习路线/" title="AI学习路线1" class="md-nav__link">
      AI学习路线1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/ai-union-201904/" title="AI学习路线2" class="md-nav__link">
      AI学习路线2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v0.1/" title="AI 路线图v0.1" class="md-nav__link">
      AI 路线图v0.1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v0.2/" title="AI 路线图v0.2" class="md-nav__link">
      AI 路线图v0.2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/ai-roadmap/v1.0/" title="ApacheCN 人工智能知识树" class="md-nav__link">
      ApacheCN 人工智能知识树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7" type="checkbox" id="nav-1-7">
    
    <label class="md-nav__link" for="nav-1-7">
      工具软件
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-7">
        工具软件
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/judgers/" title="评测工具" class="md-nav__link">
      评测工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/editors/" title="编辑工具" class="md-nav__link">
      编辑工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/wsl/" title="WSL (Windows 10)" class="md-nav__link">
      WSL (Windows 10)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/spj/" title="Special Judge" class="md-nav__link">
      Special Judge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7-5" type="checkbox" id="nav-1-7-5">
    
    <label class="md-nav__link" for="nav-1-7-5">
      Testlib
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-1-7-5">
        Testlib
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/" title="Testlib 简介" class="md-nav__link">
      Testlib 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/general/" title="通用" class="md-nav__link">
      通用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/generator/" title="Generator" class="md-nav__link">
      Generator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/validator/" title="Validator" class="md-nav__link">
      Validator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/interactor/" title="Interactor" class="md-nav__link">
      Interactor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/checker/" title="Checker" class="md-nav__link">
      Checker
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/docker-deploy/" title="Docker 部署" class="md-nav__link">
      Docker 部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/about/" title="关于本项目" class="md-nav__link">
      关于本项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/faq/" title="F.A.Q." class="md-nav__link">
      F.A.Q.
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      机器学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../SUMMARY/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../math/" title="数学基础" class="md-nav__link">
      数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week1/" title="week1" class="md-nav__link">
      week1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week2/" title="week2" class="md-nav__link">
      week2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week3/" title="week3" class="md-nav__link">
      week3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week4/" title="week4" class="md-nav__link">
      week4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week5/" title="week5" class="md-nav__link">
      week5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week6/" title="week6" class="md-nav__link">
      week6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week7/" title="week7" class="md-nav__link">
      week7
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        week8
      </label>
    
    <a href="./" title="week8" class="md-nav__link md-nav__link--active">
      week8
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#131" title="13.1 无监督学习：简介" class="md-nav__link">
    13.1 无监督学习：简介
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-k-" title="13.2 K-均值算法" class="md-nav__link">
    13.2 K-均值算法
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133" title="13.3 优化目标" class="md-nav__link">
    13.3 优化目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134" title="13.4 随机初始化" class="md-nav__link">
    13.4 随机初始化
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135" title="13.5 选择聚类数" class="md-nav__link">
    13.5 选择聚类数
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimensionality-reduction" title="十四、降维(Dimensionality Reduction)" class="md-nav__link">
    十四、降维(Dimensionality Reduction)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" title="14.1 动机一：数据压缩" class="md-nav__link">
    14.1 动机一：数据压缩
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" title="14.2 动机二：数据可视化" class="md-nav__link">
    14.2 动机二：数据可视化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" title="14.3 主成分分析问题" class="md-nav__link">
    14.3 主成分分析问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" title="14.4 主成分分析算法" class="md-nav__link">
    14.4 主成分分析算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" title="14.5 选择主成分的数量" class="md-nav__link">
    14.5 选择主成分的数量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" title="14.6 重建的压缩表示" class="md-nav__link">
    14.6 重建的压缩表示
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#147" title="14.7 主成分分析法的应用建议" class="md-nav__link">
    14.7 主成分分析法的应用建议
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week9/" title="week9" class="md-nav__link">
      week9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week10/" title="week10" class="md-nav__link">
      week10
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度学习500问
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        深度学习500问
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/content/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch01_math/ch01_math/" title="第一章_数学基础" class="md-nav__link">
      第一章_数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch02_机器学习基础/第二章_机器学习基础/" title="第二章_机器学习基础" class="md-nav__link">
      第二章_机器学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch03_深度学习基础/第三章_深度学习基础/" title="第三章_深度学习基础" class="md-nav__link">
      第三章_深度学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch04_经典网络/第四章_经典网络/" title="第四章_经典网络" class="md-nav__link">
      第四章_经典网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch05_卷积神经网络(CNN)/第五章 卷积神经网络（CNN）/" title="第五章 卷积神经网络（CNN）" class="md-nav__link">
      第五章 卷积神经网络（CNN）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch06_循环神经网络(RNN)/第六章_循环神经网络(RNN)/" title="第六章_循环神经网络(RNN)" class="md-nav__link">
      第六章_循环神经网络(RNN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch07_生成对抗网络(GAN)/ch7/" title="第七章_生成对抗网络(GAN)" class="md-nav__link">
      第七章_生成对抗网络(GAN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch08_目标检测/第八章_目标检测/" title="第八章_目标检测" class="md-nav__link">
      第八章_目标检测
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch09_图像分割/第九章_图像分割/" title="第九章_图像分割" class="md-nav__link">
      第九章_图像分割
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch10_强化学习/第十章_强化学习/" title="第十章_强化学习" class="md-nav__link">
      第十章_强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch11_迁移学习/第十一章_迁移学习/" title="第十一章_迁移学习" class="md-nav__link">
      第十一章_迁移学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch12_网络搭建及训练/第十二章_网络搭建及训练/" title="第十二章_网络搭建及训练" class="md-nav__link">
      第十二章_网络搭建及训练
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch13_优化算法/第十三章_优化算法/" title="第十三章_优化算法" class="md-nav__link">
      第十三章_优化算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch14_超参数调整/第十四章_超参数调整/" title="第十四章_超参数调整" class="md-nav__link">
      第十四章_超参数调整
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch15_GPU和框架选型/第十五章_异构运算、GPU及框架选型/" title="第十五章_异构运算、GPU及框架选型" class="md-nav__link">
      第十五章_异构运算、GPU及框架选型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch16_自然语言处理(NLP)/第十六章_NLP/" title="第十六章_NLP" class="md-nav__link">
      第十六章_NLP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch17_模型压缩、加速及移动端部署/第十七章_模型压缩、加速及移动端部署/" title="第十七章_模型压缩、加速及移动端部署" class="md-nav__link">
      第十七章_模型压缩、加速及移动端部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型、离线及实时计算/第十八章_后端架构选型、离线及实时计算/" title="第十八章_后端架构选型、离线及实时计算" class="md-nav__link">
      第十八章_后端架构选型、离线及实时计算
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型及应用场景/第十八章_后端架构选型及应用场景/" title="第十八章_后端架构选型及应用场景" class="md-nav__link">
      第十八章_后端架构选型及应用场景
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      统计学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        统计学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH01/" title="统计学习及监督学习概论" class="md-nav__link">
      统计学习及监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH02/" title="感知机" class="md-nav__link">
      感知机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH03/" title="K近邻法" class="md-nav__link">
      K近邻法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH04/" title="朴素贝叶斯法" class="md-nav__link">
      朴素贝叶斯法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH05/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH06/" title="逻辑斯蒂回归与最大熵模型" class="md-nav__link">
      逻辑斯蒂回归与最大熵模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH07/" title="支持向量机" class="md-nav__link">
      支持向量机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH08/" title="提升方法" class="md-nav__link">
      提升方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH09/" title="EM算法及其推广" class="md-nav__link">
      EM算法及其推广
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH10/" title="隐马尔可夫模型" class="md-nav__link">
      隐马尔可夫模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH11/" title="条件随机场" class="md-nav__link">
      条件随机场
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH12/" title="监督学习方法总结" class="md-nav__link">
      监督学习方法总结
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH13/" title="无监督学习概论" class="md-nav__link">
      无监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH14/" title="聚类方法" class="md-nav__link">
      聚类方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../lihang/CH22/" title="无监督学习方法总结" class="md-nav__link">
      无监督学习方法总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Sklearn与TensorFlow
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Sklearn与TensorFlow
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/README.old/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/0.前言/" title="前言" class="md-nav__link">
      前言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/1.机器学习概览/" title="机器学习概览" class="md-nav__link">
      机器学习概览
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/2.一个完整的机器学习项目/" title="一个完整的机器学习项目" class="md-nav__link">
      一个完整的机器学习项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/3.分类/" title="分类" class="md-nav__link">
      分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/4.训练模型/" title="训练模型" class="md-nav__link">
      训练模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/5.支持向量机/" title="支持向量机" class="md-nav__link">
      支持向量机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/6.决策树/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/7.集成学习和随机森林/" title="集成学习和随机森林" class="md-nav__link">
      集成学习和随机森林
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/9.启动并运行_TensorFlow/" title="启动并运行_TensorFlow" class="md-nav__link">
      启动并运行_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/10.人工神经网络介绍/" title="人工神经网络介绍" class="md-nav__link">
      人工神经网络介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/11.训练深层神经网络/" title="训练深层神经网络" class="md-nav__link">
      训练深层神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/12.设备和服务器上的分布式_TensorFlow/" title="设备和服务器上的分布式_TensorFlow" class="md-nav__link">
      设备和服务器上的分布式_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/13.卷积神经网络/" title="卷积神经网络" class="md-nav__link">
      卷积神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/14.循环神经网络/" title="循环神经网络" class="md-nav__link">
      循环神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/15.自编码器/" title="自编码器" class="md-nav__link">
      自编码器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/16.强化学习/" title="强化学习" class="md-nav__link">
      强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/B.机器学习项目清单/" title="机器学习项目清单" class="md-nav__link">
      机器学习项目清单
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/C.SVM_对偶问题/" title="SVM_对偶问题" class="md-nav__link">
      SVM_对偶问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../hands-on-ml-zh/docs/D.自动微分/" title="自动微分" class="md-nav__link">
      自动微分
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../about/" title="关于" class="md-nav__link">
      关于
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#131" title="13.1 无监督学习：简介" class="md-nav__link">
    13.1 无监督学习：简介
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-k-" title="13.2 K-均值算法" class="md-nav__link">
    13.2 K-均值算法
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133" title="13.3 优化目标" class="md-nav__link">
    13.3 优化目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134" title="13.4 随机初始化" class="md-nav__link">
    13.4 随机初始化
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135" title="13.5 选择聚类数" class="md-nav__link">
    13.5 选择聚类数
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimensionality-reduction" title="十四、降维(Dimensionality Reduction)" class="md-nav__link">
    十四、降维(Dimensionality Reduction)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141" title="14.1 动机一：数据压缩" class="md-nav__link">
    14.1 动机一：数据压缩
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142" title="14.2 动机二：数据可视化" class="md-nav__link">
    14.2 动机二：数据可视化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143" title="14.3 主成分分析问题" class="md-nav__link">
    14.3 主成分分析问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144" title="14.4 主成分分析算法" class="md-nav__link">
    14.4 主成分分析算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145" title="14.5 选择主成分的数量" class="md-nav__link">
    14.5 选择主成分的数量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146" title="14.6 重建的压缩表示" class="md-nav__link">
    14.6 重建的压缩表示
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#147" title="14.7 主成分分析法的应用建议" class="md-nav__link">
    14.7 主成分分析法的应用建议
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/myourdream/aiwiki/blob/master/docs/Coursera_ML_AndrewNg/markdown/week8.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="8">第8周<a class="headerlink" href="#8" title="Permanent link">&para;</a></h1>
<p>[TOC]
十三、聚类(Clustering)</p>
<hr />
<h3 id="131">13.1 无监督学习：简介<a class="headerlink" href="#131" title="Permanent link">&para;</a></h3>
<p>参考视频: 13 - 1 - Unsupervised Learning_ Introduction (3 min).mkv</p>
<p>在这个视频中，我将开始介绍聚类算法。这将是一个激动人心的时刻，因为这是我们学习的第一个非监督学习算法。我们将要让计算机学习无标签数据，而不是此前的标签数据。</p>
<p>那么，什么是非监督学习呢？在课程的一开始，我曾简单的介绍过非监督学习，然而，我们还是有必要将其与监督学习做一下比较。</p>
<p>在一个典型的监督学习中，我们有一个有标签的训练集，我们的目标是找到能够区分正样本和负样本的决策边界，在这里的监督学习中，我们有一系列标签，我们需要据此拟合一个假设函数。与此不同的是，在非监督学习中，我们的数据没有附带任何标签，我们拿到的数据就是这样的：</p>
<p><img alt="" src="../../images/6709f5ca3cd2240d4e95dcc3d3e808d5.png" /></p>
<p>在这里我们有一系列点，却没有标签。因此，我们的训练集可以写成只有<span><span class="MathJax_Preview">x^{(1)}</span><script type="math/tex">x^{(1)}</script></span>,<span><span class="MathJax_Preview">x^{(2)}</span><script type="math/tex">x^{(2)}</script></span>…..一直到<span><span class="MathJax_Preview">x^{(m)}</span><script type="math/tex">x^{(m)}</script></span>。我们没有任何标签<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>。因此，图上画的这些点没有标签信息。也就是说，在非监督学习中，我们需要将一系列无标签的训练数据，输入到一个算法中，然后我们告诉这个算法，快去为我们找找这个数据的内在结构给定数据。我们可能需要某种算法帮助我们寻找一种结构。图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到我圈出的这些点集的算法，就被称为聚类算法。</p>
<p><img alt="" src="../../images/6709f5ca3cd2240d4e95dcc3d3e808d5.png" /></p>
<p>这将是我们介绍的第一个非监督学习算法。当然，此后我们还将提到其他类型的非监督学习算法，它们可以为我们找到其他类型的结构或者其他的一些模式，而不只是簇。</p>
<p>我们将先介绍聚类算法。此后，我们将陆续介绍其他算法。那么聚类算法一般用来做什么呢？</p>
<p><img alt="" src="../../images/ff180f091e9bad9ac185248721437526.png" /></p>
<p>在这门课程的早些时候，我曾经列举过一些应用：比如市场分割。也许你在数据库中存储了许多客户的信息，而你希望将他们分成不同的客户群，这样你可以对不同类型的客户分别销售产品或者分别提供更适合的服务。社交网络分析：事实上有许多研究人员正在研究这样一些内容，他们关注一群人，关注社交网络，例如<strong>Facebook</strong>，<strong>Google+</strong>，或者是其他的一些信息，比如说：你经常跟哪些人联系，而这些人又经常给哪些人发邮件，由此找到关系密切的人群。因此，这可能需要另一个聚类算法，你希望用它发现社交网络中关系密切的朋友。我有一个朋友正在研究这个问题，他希望使用聚类算法来更好的组织计算机集群，或者更好的管理数据中心。因为如果你知道数据中心中，那些计算机经常协作工作。那么，你可以重新分配资源，重新布局网络。由此优化数据中心，优化数据通信。</p>
<p>最后，我实际上还在研究如何利用聚类算法了解星系的形成。然后用这个知识，了解一些天文学上的细节问题。好的，这就是聚类算法。这将是我们介绍的第一个非监督学习算法。在下一个视频中，我们将开始介绍一个具体的聚类算法。</p>
<h3 id="132-k-">13.2 K-均值算法<a class="headerlink" href="#132-k-" title="Permanent link">&para;</a></h3>
<p>参考视频: 13 - 2 - K-Means Algorithm (13 min).mkv</p>
<p><strong>K-均值</strong>是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。</p>
<p><strong>K-均值</strong>是一个迭代算法，假设我们想要将数据聚类成n个组，其方法为:</p>
<p>首先选择<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个随机的点，称为<strong>聚类中心</strong>（<strong>cluster centroids</strong>）；</p>
<p>对于数据集中的每一个数据，按照距离<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</p>
<p>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。</p>
<p>重复步骤2-4直至中心点不再变化。</p>
<p>下面是一个聚类示例：</p>
<p><img alt="" src="../../images/ff1db77ec2e83b592bbe1c4153586120.jpg" /></p>
<p>迭代 1 次</p>
<p><img alt="" src="../../images/acdb3ac44f1fe61ff3b5a77d5a4895a1.jpg" /></p>
<p>迭代 3 次</p>
<p><img alt="" src="../../images/fe6dd7acf1a1eddcd09da362ecdf976f.jpg" /></p>
<p>迭代 10 次</p>
<p>用<span><span class="MathJax_Preview">μ^1</span><script type="math/tex">μ^1</script></span>,<span><span class="MathJax_Preview">μ^2</span><script type="math/tex">μ^2</script></span>,...,<span><span class="MathJax_Preview">μ^k</span><script type="math/tex">μ^k</script></span> 来表示聚类中心，用<span><span class="MathJax_Preview">c^{(1)}</span><script type="math/tex">c^{(1)}</script></span>,<span><span class="MathJax_Preview">c^{(2)}</span><script type="math/tex">c^{(2)}</script></span>,...,<span><span class="MathJax_Preview">c^{(m)}</span><script type="math/tex">c^{(m)}</script></span>来存储与第<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>个实例数据最近的聚类中心的索引，<strong>K-均值</strong>算法的伪代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Repeat {

for i = 1 to m

c(i) := index (form 1 to K) of cluster centroid closest to x(i)

for k = 1 to K

μk := average (mean) of points assigned to cluster k

}
</pre></div>
</td></tr></table>

<p>算法分为两个步骤，第一个<strong>for</strong>循环是赋值步骤，即：对于每一个样例<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>，计算其应该属于的类。第二个<strong>for</strong>循环是聚类中心的移动，即：对于每一个类<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>，重新计算该类的质心。</p>
<p><strong>K-均值</strong>算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用<strong>K-均值</strong>算法将数据分为三类，用于帮助确定将要生产的T-恤衫的三种尺寸。</p>
<p><img alt="" src="../../images/fed50a4e482cf3aae38afeb368141a97.png" /></p>
<h3 id="133">13.3 优化目标<a class="headerlink" href="#133" title="Permanent link">&para;</a></h3>
<p>参考视频: 13 - 3 - Optimization Objective (7 min).mkv</p>
<p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此
K-均值的代价函数（又称<strong>畸变函数</strong> <strong>Distortion function</strong>）为：</p>
<div>
<div class="MathJax_Preview">J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)}}\right\| ^{2}</div>
<script type="math/tex; mode=display">J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)}}\right\| ^{2}</script>
</div>
<p>其中<span><span class="MathJax_Preview">{{\mu }_{{{c}^{(i)}}}}</span><script type="math/tex">{{\mu }_{{{c}^{(i)}}}}</script></span>代表与<span><span class="MathJax_Preview">{{x}^{(i)}}</span><script type="math/tex">{{x}^{(i)}}</script></span>最近的聚类中心点。
我们的的优化目标便是找出使得代价函数最小的 <span><span class="MathJax_Preview">c^{(1)}</span><script type="math/tex">c^{(1)}</script></span>,<span><span class="MathJax_Preview">c^{(2)}</span><script type="math/tex">c^{(2)}</script></span>,...,<span><span class="MathJax_Preview">c^{(m)}</span><script type="math/tex">c^{(m)}</script></span>和<span><span class="MathJax_Preview">μ^1</span><script type="math/tex">μ^1</script></span>,<span><span class="MathJax_Preview">μ^2</span><script type="math/tex">μ^2</script></span>,...,<span><span class="MathJax_Preview">μ^k</span><script type="math/tex">μ^k</script></span>：
<img alt="" src="../../images/8605f0826623078a156d30a7782dfc3c.png" /></p>
<p>回顾刚才给出的:
<strong>K-均值</strong>迭代算法，我们知道，第一个循环是用于减小<span><span class="MathJax_Preview">c^{(i)}</span><script type="math/tex">c^{(i)}</script></span>引起的代价，而第二个循环则是用于减小<span><span class="MathJax_Preview">{{\mu }_{i}}</span><script type="math/tex">{{\mu }_{i}}</script></span>引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p>
<h3 id="134">13.4 随机初始化<a class="headerlink" href="#134" title="Permanent link">&para;</a></h3>
<p>参考视频: 13 - 4 - Random Initialization (8 min).mkv</p>
<p>在运行K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p>
<ol>
<li>
<p>我们应该选择<span><span class="MathJax_Preview">K&lt;m</span><script type="math/tex">K<m</script></span>，即聚类中心点的个数要小于所有训练集实例的数量</p>
</li>
<li>
<p>随机选择<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个训练实例，然后令<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个聚类中心分别与这<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个训练实例相等</p>
</li>
</ol>
<p><strong>K-均值</strong>的一个问题在于，它有可能会停留在一个局部最小值处，而这取决于初始化的情况。</p>
<p><img alt="" src="../../images/d4d2c3edbdd8915f4e9d254d2a47d9c7.png" /></p>
<p>为了解决这个问题，我们通常需要多次运行<strong>K-均值</strong>算法，每一次都重新进行随机初始化，最后再比较多次运行<strong>K-均值</strong>的结果，选择代价函数最小的结果。这种方法在<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>较小的时候（2--10）还是可行的，但是如果<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>较大，这么做也可能不会有明显地改善。</p>
<h3 id="135">13.5 选择聚类数<a class="headerlink" href="#135" title="Permanent link">&para;</a></h3>
<p>参考视频: 13 - 5 - Choosing the Number of Clusters (8 min).mkv</p>
<p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用<strong>K-均值</strong>算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。</p>
<p>当人们在讨论，选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。关于“肘部法则”，我们所需要做的是改变<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>值，也就是聚类类别数目的总数。我们用一个聚类来运行<strong>K均值</strong>聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后计算成本函数或者计算畸变函数<span><span class="MathJax_Preview">J</span><script type="math/tex">J</script></span>。<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>代表聚类数字。</p>
<p><img alt="" src="../../images/f3ddc6d751cab7aba7a6f8f44794e975.png" /></p>
<p>我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。好像人的手臂，如果你伸出你的胳膊，那么这就是你的肩关节、肘关节、手。这就是“肘部法则”。你会发现这种模式，它的畸变值会迅速下降，从1到2，从2到3之后，你会在3的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用3个聚类来进行聚类是正确的，这是因为那个点是曲线的肘点，畸变值下降得很快，<span><span class="MathJax_Preview">K=3</span><script type="math/tex">K=3</script></span>之后就下降得很慢，那么我们就选<span><span class="MathJax_Preview">K=3</span><script type="math/tex">K=3</script></span>。当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p>
<p>例如，我们的 T-恤制造例子中，我们要将用户按照身材聚类，我们可以分成3个尺寸:<span><span class="MathJax_Preview">S,M,L</span><script type="math/tex">S,M,L</script></span>，也可以分成5个尺寸<span><span class="MathJax_Preview">XS,S,M,L,XL</span><script type="math/tex">XS,S,M,L,XL</script></span>，这样的选择是建立在回答“聚类后我们制造的T-恤是否能较好地适合我们的客户”这个问题的基础上作出的。</p>
<p><strong>聚类参考资料：</strong></p>
<p>1.相似度/距离计算方法总结</p>
<p>(1). 闵可夫斯基距离<strong>Minkowski</strong>/（其中欧式距离：<span><span class="MathJax_Preview">p=2</span><script type="math/tex">p=2</script></span>) </p>
<p><span><span class="MathJax_Preview">dist(X,Y)={{\left( {{\sum\limits_{i=1}^{n}{\left| {{x}_{i}}-{{y}_{i}} \right|}}^{p}} \right)}^{\frac{1}{p}}}</span><script type="math/tex">dist(X,Y)={{\left( {{\sum\limits_{i=1}^{n}{\left| {{x}_{i}}-{{y}_{i}} \right|}}^{p}} \right)}^{\frac{1}{p}}}</script></span></p>
<p>(2). 杰卡德相似系数(<strong>Jaccard</strong>)：</p>
<p><span><span class="MathJax_Preview">J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}</span><script type="math/tex">J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}</script></span></p>
<p>(3). 余弦相似度(<strong>cosine similarity</strong>)：</p>
<p><span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>维向量<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>和<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>的夹角记做<span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>，根据余弦定理，其余弦值为：</p>
<p><span><span class="MathJax_Preview">cos (\theta )=\frac{{{x}^{T}}y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{{{x}_{i}}{{y}_{i}}}}{\sqrt{\sum\limits_{i=1}^{n}{{{x}_{i}}^{2}}}\sqrt{\sum\limits_{i=1}^{n}{{{y}_{i}}^{2}}}}</span><script type="math/tex">cos (\theta )=\frac{{{x}^{T}}y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{{{x}_{i}}{{y}_{i}}}}{\sqrt{\sum\limits_{i=1}^{n}{{{x}_{i}}^{2}}}\sqrt{\sum\limits_{i=1}^{n}{{{y}_{i}}^{2}}}}</script></span>
(4). Pearson皮尔逊相关系数：
<span><span class="MathJax_Preview">{{\rho }_{XY}}=\frac{\operatorname{cov}(X,Y)}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{E[(X-{{\mu }_{X}})(Y-{{\mu }_{Y}})]}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{\sum\limits_{i=1}^{n}{(x-{{\mu }_{X}})(y-{{\mu }_{Y}})}}{\sqrt{\sum\limits_{i=1}^{n}{{{(x-{{\mu }_{X}})}^{2}}}}\sqrt{\sum\limits_{i=1}^{n}{{{(y-{{\mu }_{Y}})}^{2}}}}}</span><script type="math/tex">{{\rho }_{XY}}=\frac{\operatorname{cov}(X,Y)}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{E[(X-{{\mu }_{X}})(Y-{{\mu }_{Y}})]}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{\sum\limits_{i=1}^{n}{(x-{{\mu }_{X}})(y-{{\mu }_{Y}})}}{\sqrt{\sum\limits_{i=1}^{n}{{{(x-{{\mu }_{X}})}^{2}}}}\sqrt{\sum\limits_{i=1}^{n}{{{(y-{{\mu }_{Y}})}^{2}}}}}</script></span></p>
<p>Pearson相关系数即将<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>、<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>坐标向量各自平移到原点后的夹角余弦。</p>
<p>2.聚类的衡量指标</p>
<p>(1). 均一性：<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span></p>
<p>类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个 聚簇中正确分类的样本数占该聚簇总样本数的比例和)</p>
<p>(2). 完整性：<span><span class="MathJax_Preview">r</span><script type="math/tex">r</script></span></p>
<p>类似于召回率，同类别样本被归类到相同簇中，则满足完整性;每个聚簇中正确分类的样本数占该 
类型的总样本数比例的和</p>
<p>(3). <strong>V-measure</strong>:</p>
<p>均一性和完整性的加权平均 </p>
<p><span><span class="MathJax_Preview">V = \frac{(1+\beta^2)*pr}{\beta^2*p+r}</span><script type="math/tex">V = \frac{(1+\beta^2)*pr}{\beta^2*p+r}</script></span></p>
<p>(4). 轮廓系数</p>
<p>样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>的轮廓系数：<span><span class="MathJax_Preview">s(i)</span><script type="math/tex">s(i)</script></span></p>
<p>簇内不相似度:计算样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>到同簇其它样本的平均距离为<span><span class="MathJax_Preview">a(i)</span><script type="math/tex">a(i)</script></span>，应尽可能小。</p>
<p>簇间不相似度:计算样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>到其它簇<span><span class="MathJax_Preview">C_j</span><script type="math/tex">C_j</script></span>的所有样本的平均距离<span><span class="MathJax_Preview">b_{ij}</span><script type="math/tex">b_{ij}</script></span>，应尽可能大。</p>
<p>轮廓系数：<span><span class="MathJax_Preview">s(i)</span><script type="math/tex">s(i)</script></span>值越接近1表示样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>聚类越合理，越接近-1，表示样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>应该分类到 另外的簇中，近似为0，表示样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>应该在边界上;所有样本的<span><span class="MathJax_Preview">s(i)</span><script type="math/tex">s(i)</script></span>的均值被成为聚类结果的轮廓系数。 </p>
<p><span><span class="MathJax_Preview">s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\}}</span><script type="math/tex">s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\}}</script></span></p>
<p>(5). <strong>ARI</strong></p>
<p>数据集<span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>共有<span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>个元素，  两个聚类结果分别是：</p>
<p><span><span class="MathJax_Preview">X=\{{{X}_{1}},{{X}_{2}},...,{{X}_{r}}\},Y=\{{{Y}_{1}},{{Y}_{2}},...,{{Y}_{s}}\}</span><script type="math/tex">X=\{{{X}_{1}},{{X}_{2}},...,{{X}_{r}}\},Y=\{{{Y}_{1}},{{Y}_{2}},...,{{Y}_{s}}\}</script></span></p>
<p><span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span>和<span><span class="MathJax_Preview">Y</span><script type="math/tex">Y</script></span>的元素个数为：</p>
<p><span><span class="MathJax_Preview">a=\{{{a}_{1}},{{a}_{2}},...,{{a}_{r}}\},b=\{{{b}_{1}},{{b}_{2}},...,{{b}_{s}}\}</span><script type="math/tex">a=\{{{a}_{1}},{{a}_{2}},...,{{a}_{r}}\},b=\{{{b}_{1}},{{b}_{2}},...,{{b}_{s}}\}</script></span></p>
<p><img alt="ri1" src="/Ari11.png" /></p>
<p>记：<span><span class="MathJax_Preview">{{n}_{ij}}=\left| {{X}_{i}}\cap {{Y}_{i}} \right|</span><script type="math/tex">{{n}_{ij}}=\left| {{X}_{i}}\cap {{Y}_{i}} \right|</script></span></p>
<p><span><span class="MathJax_Preview">ARI=\frac{\sum\limits_{i,j}{C_{{{n}_{ij}}}^{2}}-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)+\left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}</span><script type="math/tex">ARI=\frac{\sum\limits_{i,j}{C_{{{n}_{ij}}}^{2}}-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)+\left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}</script></span></p>
<h2 id="dimensionality-reduction">十四、降维(Dimensionality Reduction)<a class="headerlink" href="#dimensionality-reduction" title="Permanent link">&para;</a></h2>
<h3 id="141">14.1 动机一：数据压缩<a class="headerlink" href="#141" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 1 - Motivation I_ Data Compression (10 min).mkv</p>
<p>这个视频，我想开始谈论第二种类型的无监督学习问题，称为降维。有几个不同的的原因使你可能想要做降维。一是数据压缩，后面我们会看了一些视频后，数据压缩不仅允许我们压缩数据，因而使用较少的计算机内存或磁盘空间，但它也让我们加快我们的学习算法。</p>
<p>但首先，让我们谈论降维是什么。作为一种生动的例子，我们收集的数据集，有许多，许多特征，我绘制两个在这里。</p>
<p><img alt="" src="../../images/2373072a74d97a9f606981ffaf1dd53b.png" /></p>
<p>假设我们未知两个的特征：<span><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>:长度：用厘米表示；<span><span class="MathJax_Preview">x_2</span><script type="math/tex">x_2</script></span>：是用英寸表示同一物体的长度。</p>
<p>所以，这给了我们高度冗余表示，也许不是两个分开的特征<span><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>和<span><span class="MathJax_Preview">x_2</span><script type="math/tex">x_2</script></span>，这两个基本的长度度量，也许我们想要做的是减少数据到一维，只有一个数测量这个长度。这个例子似乎有点做作，这里厘米英寸的例子实际上不是那么不切实际的，两者并没有什么不同。</p>
<p>将数据从二维降至一维：
假使我们要采用两种不同的仪器来测量一些东西的尺寸，其中一个仪器测量结果的单位是英寸，另一个仪器测量的结果是厘米，我们希望将测量的结果作为我们机器学习的特征。现在的问题的是，两种仪器对同一个东西测量的结果不完全相等（由于误差、精度等），而将两者都作为特征有些重复，因而，我们希望将这个二维的数据降至一维。</p>
<p>从这件事情我看到的东西发生在工业上的事。如果你有几百个或成千上万的特征，它是它这往往容易失去你需要的特征。有时可能有几个不同的工程团队，也许一个工程队给你二百个特征，第二工程队给你另外三百个的特征，第三工程队给你五百个特征，一千多个特征都在一起，它实际上会变得非常困难，去跟踪你知道的那些特征，你从那些工程队得到的。其实不想有高度冗余的特征一样。</p>
<p><img alt="" src="../../images/2c95b316a3c61cf076ef132d3d50b51c.png" /></p>
<p>多年我一直在研究直升飞机自动驾驶。诸如此类。如果你想测量——如果你想做，你知道，做一个调查或做这些不同飞行员的测试——你可能有一个特征：<span><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>，这也许是他们的技能（直升机飞行员），也许<span><span class="MathJax_Preview">x_2</span><script type="math/tex">x_2</script></span>可能是飞行员的爱好。这是表示他们是否喜欢飞行，也许这两个特征将高度相关。你真正关心的可能是这条红线的方向，不同的特征，决定飞行员的能力。</p>
<p><img alt="" src="../../images/8274f0c29314742e9b4f15071ea7624a.png" /></p>
<p>将数据从三维降至二维：
这个例子中我们要将一个三维的特征向量降至一个二维的特征向量。过程是与上面类似的，我们将三维向量投射到一个二维的平面上，强迫使得所有的数据都在同一个平面上，降至二维的特征向量。</p>
<p><img alt="" src="../../images/67e2a9d760300d33ac5e12ad2bd5523c.jpg" /></p>
<p>这样的处理过程可以被用于把任何维度的数据降到任何想要的维度，例如将1000维的特征降至100维。</p>
<p>正如我们所看到的，最后，这将使我们能够使我们的一些学习算法运行也较晚，但我们会在以后的视频提到它。</p>
<h3 id="142">14.2 动机二：数据可视化<a class="headerlink" href="#142" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 2 - Motivation II_ Visualization (6 min).mkv</p>
<p>在许多及其学习问题中，如果我们能将数据可视化，我们便能寻找到一个更好的解决方案，降维可以帮助我们。</p>
<p><img alt="" src="../../images/789d90327121d3391735087b9276db2a.png" /></p>
<p>假使我们有有关于许多不同国家的数据，每一个特征向量都有50个特征（如<strong>GDP</strong>，人均<strong>GDP</strong>，平均寿命等）。如果要将这个50维的数据可视化是不可能的。使用降维的方法将其降至2维，我们便可以将其可视化了。</p>
<p><img alt="" src="../../images/ec85b79482c868eddc06ba075465fbcf.png" /></p>
<p>这样做的问题在于，降维的算法只负责减少维数，新产生的特征的意义就必须由我们自己去发现了。</p>
<h3 id="143">14.3 主成分分析问题<a class="headerlink" href="#143" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 3 - Principal Component Analysis Problem Formulation (9 min). mkv</p>
<p>主成分分析(<strong>PCA</strong>)是最常见的降维算法。</p>
<p>在<strong>PCA</strong>中，我们要做的是找到一个方向向量（<strong>Vector direction</strong>），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。</p>
<p><img alt="" src="../../images/a93213474b35ce393320428996aeecd9.jpg" /></p>
<p>下面给出主成分分析问题的描述：</p>
<p>问题是要将<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>维数据降至<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>维，目标是找到向量<span><span class="MathJax_Preview">u^{(1)}</span><script type="math/tex">u^{(1)}</script></span>,<span><span class="MathJax_Preview">u^{(2)}</span><script type="math/tex">u^{(2)}</script></span>,...,<span><span class="MathJax_Preview">u^{(k)}</span><script type="math/tex">u^{(k)}</script></span>使得总的投射误差最小。主成分分析与线性回顾的比较：</p>
<p>主成分分析与线性回归是两种不同的算法。主成分分析最小化的是投射误差（<strong>Projected Error</strong>），而线性回归尝试的是最小化预测误差。线性回归的目的是预测结果，而主成分分析不作任何预测。</p>
<p><img alt="" src="../../images/7e1389918ab9358d1432d20ed20f8142.png" /></p>
<p>上图中，左边的是线性回归的误差（垂直于横轴投影），右边则是主要成分分析的误差（垂直于红线投影）。</p>
<p><strong>PCA</strong>将<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>个特征降维到<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个，可以用来进行数据压缩，如果100维的向量最后可以用10维来表示，那么压缩率为90%。同样图像处理领域的<strong>KL变换</strong>使用<strong>PCA</strong>做图像压缩。但<strong>PCA</strong> 要保证降维后，还要保证数据的特性损失最小。</p>
<p><strong>PCA</strong>技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。</p>
<p><strong>PCA</strong>技术的一个很大的优点是，它是完全无参数限制的。在<strong>PCA</strong>的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。</p>
<p>但是，这一点同时也可以看作是缺点。如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。</p>
<h3 id="144">14.4 主成分分析算法<a class="headerlink" href="#144" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 4 - Principal Component Analysis Algorithm (15 min).mkv</p>
<p><strong>PCA</strong> 减少<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>维到<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>维：</p>
<p>第一步是均值归一化。我们需要计算出所有特征的均值，然后令 <span><span class="MathJax_Preview">x_j= x_j-μ_j</span><script type="math/tex">x_j= x_j-μ_j</script></span>。如果特征是在不同的数量级上，我们还需要将其除以标准差 <span><span class="MathJax_Preview">σ^2</span><script type="math/tex">σ^2</script></span>。</p>
<p>第二步是计算<strong>协方差矩阵</strong>（<strong>covariance matrix</strong>）<span><span class="MathJax_Preview">Σ</span><script type="math/tex">Σ</script></span>：
<span><span class="MathJax_Preview">\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</span><script type="math/tex">\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</script></span></p>
<p>第三步是计算协方差矩阵<span><span class="MathJax_Preview">Σ</span><script type="math/tex">Σ</script></span>的<strong>特征向量</strong>（<strong>eigenvectors</strong>）:</p>
<p>在 <strong>Octave</strong> 里我们可以利用<strong>奇异值分解</strong>（<strong>singular value decomposition</strong>）来求解，<code>[U, S, V]= svd(sigma)</code>。</p>
<p><img alt="" src="../../images/0918b38594709705723ed34bb74928ba.png" />
<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</span><script type="math/tex">Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</span><script type="math/tex">Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</script></span></script></span></p>
<p><img alt="" src="../../images/01e1c4a2f29a626b5980a27fc7d6a693.png" /></p>
<p>对于一个 <span><span class="MathJax_Preview">n×n</span><script type="math/tex">n×n</script></span>维度的矩阵，上式中的<span><span class="MathJax_Preview">U</span><script type="math/tex">U</script></span>是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>维降至<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>维，我们只需要从<span><span class="MathJax_Preview">U</span><script type="math/tex">U</script></span>中选取前<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个向量，获得一个<span><span class="MathJax_Preview">n×k</span><script type="math/tex">n×k</script></span>维度的矩阵，我们用<span><span class="MathJax_Preview">U_{reduce}</span><script type="math/tex">U_{reduce}</script></span>表示，然后通过如下计算获得要求的新特征向量<span><span class="MathJax_Preview">z^{(i)}</span><script type="math/tex">z^{(i)}</script></span>:
<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">z^{(i)}=U^{T}_{reduce}*x^{(i)}</span><script type="math/tex">z^{(i)}=U^{T}_{reduce}*x^{(i)}</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">z^{(i)}=U^{T}_{reduce}*x^{(i)}</span><script type="math/tex">z^{(i)}=U^{T}_{reduce}*x^{(i)}</script></span></script></span></p>
<p>其中<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>是<span><span class="MathJax_Preview">n×1</span><script type="math/tex">n×1</script></span>维的，因此结果为<span><span class="MathJax_Preview">k×1</span><script type="math/tex">k×1</script></span>维度。注，我们不对方差特征进行处理。</p>
<h3 id="145">14.5 选择主成分的数量<a class="headerlink" href="#145" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 5 - Choosing The Number Of Principal Components (13 min).mkv</p>
<p>主要成分分析是减少投射的平均均方误差：</p>
<p>训练集的方差为：<span><span class="MathJax_Preview">\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }\right\| ^{2}</span><script type="math/tex">\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }\right\| ^{2}</script></span></p>
<p>我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>值。</p>
<p>如果我们希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果我们选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。</p>
<p>我们可以先令<span><span class="MathJax_Preview">k=1</span><script type="math/tex">k=1</script></span>，然后进行主要成分分析，获得<span><span class="MathJax_Preview">U_{reduce}</span><script type="math/tex">U_{reduce}</script></span>和<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>，然后计算比例是否小于1%。如果不是的话再令<span><span class="MathJax_Preview">k=2</span><script type="math/tex">k=2</script></span>，如此类推，直到找到可以使得比例小于1%的最小<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 值（原因是各个特征之间通常情况存在某种相关性）。</p>
<p>还有一些更好的方式来选择<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>，当我们在<strong>Octave</strong>中调用“<strong>svd</strong>”函数的时候，我们获得三个参数：<code>[U, S, V] = svd(sigma)</code>。</p>
<p><img alt="" src="../../images/a4477d787f876ae4e72cb416a2cb0b8a.jpg" /></p>
<p>其中的<span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>是一个<span><span class="MathJax_Preview">n×n</span><script type="math/tex">n×n</script></span>的矩阵，只有对角线上有值，而其它单元都是0，我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例：
<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%</span><script type="math/tex">\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%</span><script type="math/tex">\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%</script></span></script></span></p>
<p>也就是：<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">\frac {\Sigma^{k}_{i=1}s_{ii}}{\Sigma^{n}_{i=1}s_{ii}}\geq0.99</span><script type="math/tex">\frac {\Sigma^{k}_{i=1}s_{ii}}{\Sigma^{n}_{i=1}s_{ii}}\geq0.99</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">\frac {\Sigma^{k}_{i=1}s_{ii}}{\Sigma^{n}_{i=1}s_{ii}}\geq0.99</span><script type="math/tex">\frac {\Sigma^{k}_{i=1}s_{ii}}{\Sigma^{n}_{i=1}s_{ii}}\geq0.99</script></span></script></span></p>
<p>在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}</span><script type="math/tex">x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}</span><script type="math/tex">x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}</script></span></script></span></p>
<h3 id="146">14.6 重建的压缩表示<a class="headerlink" href="#146" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 6 - Reconstruction from Compressed Representation (4 min).mkv</p>
<p>在以前的视频中，我谈论<strong>PCA</strong>作为压缩算法。在那里你可能需要把1000维的数据压缩100维特征，或具有三维数据压缩到一二维表示。所以，如果这是一个压缩算法，应该能回到这个压缩表示，回到你原有的高维数据的一种近似。</p>
<p>所以，给定的<span><span class="MathJax_Preview">z^{(i)}</span><script type="math/tex">z^{(i)}</script></span>，这可能100维，怎么回到你原来的表示<span><span class="MathJax_Preview">x^{(i)}</span><script type="math/tex">x^{(i)}</script></span>，这可能是1000维的数组？</p>
<p><img alt="" src="../../images/0a4edcb9c0d0a3812a50b3e95ef3912a.png" /></p>
<p><strong>PCA</strong>算法，我们可能有一个这样的样本。如图中样本<span><span class="MathJax_Preview">x^{(1)}</span><script type="math/tex">x^{(1)}</script></span>,<span><span class="MathJax_Preview">x^{(2)}</span><script type="math/tex">x^{(2)}</script></span>。我们做的是，我们把这些样本投射到图中这个一维平面。然后现在我们需要只使用一个实数，比如<span><span class="MathJax_Preview">z^{(1)}</span><script type="math/tex">z^{(1)}</script></span>，指定这些点的位置后他们被投射到这一个三维曲面。给定一个点<span><span class="MathJax_Preview">z^{(1)}</span><script type="math/tex">z^{(1)}</script></span>，我们怎么能回去这个原始的二维空间呢？<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>为2维，<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>为1维，<span><span class="MathJax_Preview">z=U^{T}_{reduce}x</span><script type="math/tex">z=U^{T}_{reduce}x</script></span>，相反的方程为：<span><span class="MathJax_Preview">x_{appox}=U_{reduce}\cdot z</span><script type="math/tex">x_{appox}=U_{reduce}\cdot z</script></span>,<span><span class="MathJax_Preview">x_{appox}\approx x</span><script type="math/tex">x_{appox}\approx x</script></span>。如图：</p>
<p><img alt="" src="../../images/66544d8fa1c1639d80948006f7f4a8ff.png" /></p>
<p>如你所知，这是一个漂亮的与原始数据相当相似。所以，这就是你从低维表示<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>回到未压缩的表示。我们得到的数据的一个之间你的原始数据 <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>，我们也把这个过程称为重建原始数据。</p>
<p>当我们认为试图重建从压缩表示 <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> 的初始值。所以，给定未标记的数据集，您现在知道如何应用<strong>PCA</strong>，你的带高维特征<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>和映射到这的低维表示<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>。这个视频，希望你现在也知道如何采取这些低维表示<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>，映射到备份到一个近似你原有的高维数据。</p>
<p>现在你知道如何实施应用<strong>PCA</strong>，我们将要做的事是谈论一些技术在实际使用<strong>PCA</strong>很好，特别是，在接下来的视频中，我想谈一谈关于如何选择<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>。</p>
<h3 id="147">14.7 主成分分析法的应用建议<a class="headerlink" href="#147" title="Permanent link">&para;</a></h3>
<p>参考视频: 14 - 7 - Advice for Applying PCA (13 min).mkv</p>
<p>假使我们正在针对一张 100×100像素的图片进行某个计算机视觉的机器学习，即总共有10000 个特征。</p>
<ol>
<li>
<p>第一步是运用主要成分分析将数据压缩至1000个特征</p>
</li>
<li>
<p>然后对训练集运行学习算法</p>
<ol>
<li>在预测时，采用之前学习而来的<span><span class="MathJax_Preview">U_{reduce}</span><script type="math/tex">U_{reduce}</script></span>将输入的特征<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>转换成特征向量<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>，然后再进行预测</li>
</ol>
</li>
</ol>
<p>注：如果我们有交叉验证集合测试集，也采用对训练集学习而来的<span><span class="MathJax_Preview">U_{reduce}</span><script type="math/tex">U_{reduce}</script></span>。</p>
<p>错误的主要成分分析情况：一个常见错误使用主要成分分析的情况是，将其用于减少过拟合（减少了特征的数量）。这样做非常不好，不如尝试正则化处理。原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。然而当我们进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。</p>
<p>另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。</p>
                
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://hai5g.cn/aiwiki/Coursera_ML_AndrewNg/markdown/week8/";
      this.page.identifier =
        "/Coursera_ML_AndrewNg/markdown/week8/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//AI-Wiki.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../week7/" title="week7" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                week7
              </span>
            </div>
          </a>
        
        
          <a href="../week9/" title="week9" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                week9
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 AI Wiki Team
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.39abc4af.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdn.jsdelivr.net/gh/ethantw/Han@3.3.0/dist/han.min.js"></script>
      
        <script src="../../../_static/js/extra.js?v=10"></script>
      
        <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>