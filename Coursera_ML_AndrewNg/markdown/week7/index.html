



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="AI Wiki 是一个编程竞赛知识整合站点，提供有趣又实用的编程竞赛知识以及其他有帮助的内容，帮助广大编程竞赛爱好者更快更深入地学习编程竞赛">
      
      
        <link rel="canonical" href="https://hai5g.cn/aiwiki/Coursera_ML_AndrewNg/markdown/week7/">
      
      
        <meta name="author" content="AI Wiki Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>week7 - AI Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,400i,700|Fira+Mono">
        <style>body,input{font-family:"Fira Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Fira Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
      <link rel="manifest" href="../../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/ah@1.5.0/han.min.css">
    
      <link rel="stylesheet" href="../../../_static/css/extra.css?v=11">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#7" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              AI Wiki
            </span>
            <span class="md-header-nav__topic">
              week7
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="简介" class="md-tabs__link">
          简介
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../SUMMARY/" title="Machine Learning" class="md-tabs__link md-tabs__link--active">
          Machine Learning
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../qa500/" title="深度学习500问" class="md-tabs__link">
          深度学习500问
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../dp/" title="经典算法" class="md-tabs__link">
          经典算法
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../string/" title="集成学习算法" class="md-tabs__link">
          集成学习算法
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../math/" title="CNN" class="md-tabs__link">
          CNN
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../ds/" title="RNN" class="md-tabs__link">
          RNN
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../graph/" title="GAN" class="md-tabs__link">
          GAN
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../geometry/" title="计算机视觉" class="md-tabs__link">
          计算机视觉
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../misc/" title="NLP" class="md-tabs__link">
          NLP
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../misc/" title="推荐系统" class="md-tabs__link">
          推荐系统
        </a>
      
    </li>
  

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    AI Wiki
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/AI学习路线/" title="AI学习路线" class="md-nav__link">
      AI学习路线
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/mode/" title="AI 赛事与赛制" class="md-nav__link">
      AI 赛事与赛制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/icpc/" title="ICPC/CCPC 赛事与赛制" class="md-nav__link">
      ICPC/CCPC 赛事与赛制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/resources/" title="学习资源" class="md-nav__link">
      学习资源
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/common-mistakes/" title="常见错误" class="md-nav__link">
      常见错误
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/common-tricks/" title="常见技巧" class="md-nav__link">
      常见技巧
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/non-traditional/" title="非传统题" class="md-nav__link">
      非传统题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-9" type="checkbox" id="nav-1-9">
    
    <label class="md-nav__link" for="nav-1-9">
      工具软件
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-9">
        工具软件
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/judgers/" title="评测工具" class="md-nav__link">
      评测工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/editors/" title="编辑工具" class="md-nav__link">
      编辑工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/wsl/" title="WSL (Windows 10)" class="md-nav__link">
      WSL (Windows 10)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/spj/" title="Special Judge" class="md-nav__link">
      Special Judge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-9-5" type="checkbox" id="nav-1-9-5">
    
    <label class="md-nav__link" for="nav-1-9-5">
      Testlib
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-1-9-5">
        Testlib
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/" title="Testlib 简介" class="md-nav__link">
      Testlib 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/general/" title="通用" class="md-nav__link">
      通用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/generator/" title="Generator" class="md-nav__link">
      Generator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/validator/" title="Validator" class="md-nav__link">
      Validator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/interactor/" title="Interactor" class="md-nav__link">
      Interactor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/testlib/checker/" title="Checker" class="md-nav__link">
      Checker
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/docker-deploy/" title="Docker 部署" class="md-nav__link">
      Docker 部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/about/" title="关于本项目" class="md-nav__link">
      关于本项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../intro/faq/" title="F.A.Q." class="md-nav__link">
      F.A.Q.
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Machine Learning
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Machine Learning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../SUMMARY/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../math/" title="数学基础" class="md-nav__link">
      数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week1/" title="week1" class="md-nav__link">
      week1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week2/" title="week2" class="md-nav__link">
      week2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week3/" title="week3" class="md-nav__link">
      week3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week4/" title="week4" class="md-nav__link">
      week4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week5/" title="week5" class="md-nav__link">
      week5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week6/" title="week6" class="md-nav__link">
      week6
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        week7
      </label>
    
    <a href="./" title="week7" class="md-nav__link md-nav__link--active">
      week7
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#121" title="12.1 优化目标" class="md-nav__link">
    12.1 优化目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#122" title="12.2 大边界的直观理解" class="md-nav__link">
    12.2 大边界的直观理解
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#123" title="12.3 大边界分类背后的数学（选修）" class="md-nav__link">
    12.3 大边界分类背后的数学（选修）
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#124-1" title="12.4 核函数1" class="md-nav__link">
    12.4 核函数1
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#125-2" title="12.5 核函数2" class="md-nav__link">
    12.5 核函数2
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#126" title="12.6 使用支持向量机" class="md-nav__link">
    12.6 使用支持向量机
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week8/" title="week8" class="md-nav__link">
      week8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week9/" title="week9" class="md-nav__link">
      week9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week10/" title="week10" class="md-nav__link">
      week10
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度学习500问
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        深度学习500问
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/content/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch01_math/ch01_math/" title="第一章_数学基础" class="md-nav__link">
      第一章_数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch02_机器学习基础/第二章_机器学习基础/" title="第二章_机器学习基础" class="md-nav__link">
      第二章_机器学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch03_深度学习基础/第三章_深度学习基础/" title="第三章_深度学习基础" class="md-nav__link">
      第三章_深度学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch04_经典网络/第四章_经典网络/" title="第四章_经典网络" class="md-nav__link">
      第四章_经典网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch05_卷积神经网络(CNN)/第五章 卷积神经网络（CNN）/" title="第五章 卷积神经网络（CNN）" class="md-nav__link">
      第五章 卷积神经网络（CNN）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch06_循环神经网络(RNN)/第六章_循环神经网络(RNN)/" title="第六章_循环神经网络(RNN)" class="md-nav__link">
      第六章_循环神经网络(RNN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch07_生成对抗网络(GAN)/ch7/" title="第七章_生成对抗网络(GAN)" class="md-nav__link">
      第七章_生成对抗网络(GAN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch08_目标检测/第八章_目标检测/" title="第八章_目标检测" class="md-nav__link">
      第八章_目标检测
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch09_图像分割/第九章_图像分割/" title="第九章_图像分割" class="md-nav__link">
      第九章_图像分割
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch10_强化学习/第十章_强化学习/" title="第十章_强化学习" class="md-nav__link">
      第十章_强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch11_迁移学习/第十一章_迁移学习/" title="第十一章_迁移学习" class="md-nav__link">
      第十一章_迁移学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch12_网络搭建及训练/第十二章_网络搭建及训练/" title="第十二章_网络搭建及训练" class="md-nav__link">
      第十二章_网络搭建及训练
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch13_优化算法/第十三章_优化算法/" title="第十三章_优化算法" class="md-nav__link">
      第十三章_优化算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch14_超参数调整/第十四章_超参数调整/" title="第十四章_超参数调整" class="md-nav__link">
      第十四章_超参数调整
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch15_GPU和框架选型/第十五章_异构运算、GPU及框架选型/" title="第十五章_异构运算、GPU及框架选型" class="md-nav__link">
      第十五章_异构运算、GPU及框架选型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch16_自然语言处理(NLP)/第十六章_NLP/" title="第十六章_NLP" class="md-nav__link">
      第十六章_NLP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch17_模型压缩、加速及移动端部署/第十七章_模型压缩、加速及移动端部署/" title="第十七章_模型压缩、加速及移动端部署" class="md-nav__link">
      第十七章_模型压缩、加速及移动端部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型、离线及实时计算/第十八章_后端架构选型、离线及实时计算/" title="第十八章_后端架构选型、离线及实时计算" class="md-nav__link">
      第十八章_后端架构选型、离线及实时计算
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../qa500/ch18_后端架构选型及应用场景/第十八章_后端架构选型及应用场景/" title="第十八章_后端架构选型及应用场景" class="md-nav__link">
      第十八章_后端架构选型及应用场景
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      经典算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        经典算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/" title="动态规划部分简介" class="md-nav__link">
      动态规划部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/memo/" title="记忆化搜索" class="md-nav__link">
      记忆化搜索
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/knapsack/" title="背包 DP" class="md-nav__link">
      背包 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/interval/" title="区间 DP" class="md-nav__link">
      区间 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/dag/" title="DAG 上的 DP" class="md-nav__link">
      DAG 上的 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/tree/" title="树形 DP" class="md-nav__link">
      树形 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/state/" title="状压 DP" class="md-nav__link">
      状压 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/number/" title="数位 DP" class="md-nav__link">
      数位 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/plug/" title="插头 DP" class="md-nav__link">
      插头 DP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-10" type="checkbox" id="nav-4-10">
    
    <label class="md-nav__link" for="nav-4-10">
      DP 优化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-10">
        DP 优化
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/optimizations/binary-knapsack/" title="二进制分组解多重背包" class="md-nav__link">
      二进制分组解多重背包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/optimizations/monotonous-queue-stack/" title="单调队列/单调栈优化" class="md-nav__link">
      单调队列/单调栈优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/optimizations/convex-hull-optimization/" title="斜率优化" class="md-nav__link">
      斜率优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/optimizations/knuth-yao-quadrangle-inequality/" title="四边形不等式优化" class="md-nav__link">
      四边形不等式优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/optimizations/state-optimization/" title="状态设计优化" class="md-nav__link">
      状态设计优化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../dp/misc/" title="其它 DP 方法" class="md-nav__link">
      其它 DP 方法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      集成学习算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        集成学习算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/" title="字符串部分简介" class="md-nav__link">
      字符串部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/lib-func/" title="标准库" class="md-nav__link">
      标准库
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/match/" title="字符串匹配" class="md-nav__link">
      字符串匹配
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/hash/" title="哈希" class="md-nav__link">
      哈希
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/prefix-function/" title="前缀函数与 KMP 算法" class="md-nav__link">
      前缀函数与 KMP 算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/trie/" title="字典树 (Trie)" class="md-nav__link">
      字典树 (Trie)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/pam/" title="回文自动机" class="md-nav__link">
      回文自动机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/sa/" title="后缀数组 (SA)" class="md-nav__link">
      后缀数组 (SA)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/ac-automaton/" title="AC 自动机" class="md-nav__link">
      AC 自动机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/sam/" title="后缀自动机 (SAM)" class="md-nav__link">
      后缀自动机 (SAM)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/suffix-tree/" title="后缀树" class="md-nav__link">
      后缀树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/manacher/" title="Manacher" class="md-nav__link">
      Manacher
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/minimal-string/" title="最小表示法" class="md-nav__link">
      最小表示法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../string/z-function/" title="Z 函数（扩展 KMP）" class="md-nav__link">
      Z 函数（扩展 KMP）
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      CNN
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        CNN
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/" title="数学部分简介" class="md-nav__link">
      数学部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/base/" title="进制" class="md-nav__link">
      进制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/bit/" title="位运算" class="md-nav__link">
      位运算
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/bignum/" title="高精度" class="md-nav__link">
      高精度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/quick-pow/" title="快速幂" class="md-nav__link">
      快速幂
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-6" type="checkbox" id="nav-6-6">
    
    <label class="md-nav__link" for="nav-6-6">
      整除及其性质
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-6">
        整除及其性质
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/prime/" title="素数" class="md-nav__link">
      素数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/gcd/" title="最大公约数" class="md-nav__link">
      最大公约数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/euler/" title="欧拉函数" class="md-nav__link">
      欧拉函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/sieve/" title="筛法" class="md-nav__link">
      筛法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/fermat/" title="费马小定理" class="md-nav__link">
      费马小定理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-7" type="checkbox" id="nav-6-7">
    
    <label class="md-nav__link" for="nav-6-7">
      同余方程相关
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-7">
        同余方程相关
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/bezouts/" title="裴蜀定理" class="md-nav__link">
      裴蜀定理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/inverse/" title="乘法逆元" class="md-nav__link">
      乘法逆元
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/linear-equation/" title="线性同余方程" class="md-nav__link">
      线性同余方程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/crt/" title="中国剩余定理" class="md-nav__link">
      中国剩余定理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/bsgs/" title="BSGS" class="md-nav__link">
      BSGS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/primitive-root/" title="原根" class="md-nav__link">
      原根
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-8" type="checkbox" id="nav-6-8">
    
    <label class="md-nav__link" for="nav-6-8">
      线性代数
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-8">
        线性代数
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/matrix/" title="矩阵" class="md-nav__link">
      矩阵
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/gauss/" title="高斯消元" class="md-nav__link">
      高斯消元
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/basis/" title="线性基" class="md-nav__link">
      线性基
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/complex/" title="复数" class="md-nav__link">
      复数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/dictionary/" title="分段打表" class="md-nav__link">
      分段打表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-11" type="checkbox" id="nav-6-11">
    
    <label class="md-nav__link" for="nav-6-11">
      数论函数相关
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-11">
        数论函数相关
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/mobius/" title="莫比乌斯反演" class="md-nav__link">
      莫比乌斯反演
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/du-sieves/" title="杜教筛" class="md-nav__link">
      杜教筛
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-12" type="checkbox" id="nav-6-12">
    
    <label class="md-nav__link" for="nav-6-12">
      多项式
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-12">
        多项式
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/intro/" title="多项式部分简介" class="md-nav__link">
      多项式部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/lagrange-poly/" title="拉格朗日插值" class="md-nav__link">
      拉格朗日插值
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/fft/" title="快速傅里叶变换" class="md-nav__link">
      快速傅里叶变换
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/ntt/" title="快速数论变换" class="md-nav__link">
      快速数论变换
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/fwt/" title="快速沃尔什变换" class="md-nav__link">
      快速沃尔什变换
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/inv/" title="多项式求逆" class="md-nav__link">
      多项式求逆
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/sqrt/" title="多项式开方" class="md-nav__link">
      多项式开方
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/div-mod/" title="多项式除法|取模" class="md-nav__link">
      多项式除法|取模
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/ln-exp/" title="多项式对数函数|指数函数" class="md-nav__link">
      多项式对数函数|指数函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/newton/" title="多项式牛顿迭代" class="md-nav__link">
      多项式牛顿迭代
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/multipoint-eval-interpolation/" title="多项式多点求值|快速插值" class="md-nav__link">
      多项式多点求值|快速插值
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/tri-func/" title="多项式三角函数" class="md-nav__link">
      多项式三角函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/poly/inv-tri-func/" title="多项式反三角函数" class="md-nav__link">
      多项式反三角函数
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-13" type="checkbox" id="nav-6-13">
    
    <label class="md-nav__link" for="nav-6-13">
      组合数学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-13">
        组合数学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/combination/" title="排列组合" class="md-nav__link">
      排列组合
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/catalan/" title="卡特兰数" class="md-nav__link">
      卡特兰数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/stirling/" title="斯特林数" class="md-nav__link">
      斯特林数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/cantor/" title="康托展开" class="md-nav__link">
      康托展开
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/inclusion-exclusion-principle/" title="容斥原理" class="md-nav__link">
      容斥原理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/drawer-principle/" title="抽屉原理" class="md-nav__link">
      抽屉原理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/expectation/" title="概率 & 期望" class="md-nav__link">
      概率 & 期望
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/permutation-group/" title="置换群" class="md-nav__link">
      置换群
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/integral/" title="数值积分" class="md-nav__link">
      数值积分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/linear-programming/" title="线性规划" class="md-nav__link">
      线性规划
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/game-theory/" title="博弈论" class="md-nav__link">
      博弈论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../math/misc/" title="杂项" class="md-nav__link">
      杂项
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      RNN
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        RNN
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/" title="数据结构部分简介" class="md-nav__link">
      数据结构部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-2" type="checkbox" id="nav-7-2">
    
    <label class="md-nav__link" for="nav-7-2">
      STL
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-2">
        STL
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stl/" title="STL 简介" class="md-nav__link">
      STL 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stl/vector/" title="vector" class="md-nav__link">
      vector
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stl/priority_queue/" title="priority_queue" class="md-nav__link">
      priority_queue
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stl/map/" title="map" class="md-nav__link">
      map
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stl/bitset/" title="bitset" class="md-nav__link">
      bitset
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-3" type="checkbox" id="nav-7-3">
    
    <label class="md-nav__link" for="nav-7-3">
      pb_ds
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-3">
        pb_ds
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/pb-ds/" title="pb_ds 简介" class="md-nav__link">
      pb_ds 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/pb-ds/priority-queue/" title="__gnu_pbds::priority_queue" class="md-nav__link">
      __gnu_pbds::priority_queue
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/stack/" title="栈" class="md-nav__link">
      栈
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/queue/" title="队列" class="md-nav__link">
      队列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/linked-list/" title="链表" class="md-nav__link">
      链表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/hash/" title="哈希表" class="md-nav__link">
      哈希表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/dsu/" title="并查集" class="md-nav__link">
      并查集
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-9" type="checkbox" id="nav-7-9">
    
    <label class="md-nav__link" for="nav-7-9">
      堆
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-9">
        堆
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/heap/" title="堆简介" class="md-nav__link">
      堆简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/binary-heap/" title="二叉堆" class="md-nav__link">
      二叉堆
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/pairing-heap/" title="配对堆" class="md-nav__link">
      配对堆
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-10" type="checkbox" id="nav-7-10">
    
    <label class="md-nav__link" for="nav-7-10">
      块状数据结构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-10">
        块状数据结构
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/square-root-decomposition/" title="分块思想" class="md-nav__link">
      分块思想
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/block-list/" title="块状链表" class="md-nav__link">
      块状链表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/block-array/" title="块状数组" class="md-nav__link">
      块状数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/tree-decompose/" title="树分块" class="md-nav__link">
      树分块
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/monotonous-stack/" title="单调栈" class="md-nav__link">
      单调栈
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/monotonous-queue/" title="单调队列" class="md-nav__link">
      单调队列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/sparse-table/" title="倍增" class="md-nav__link">
      倍增
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/bit/" title="树状数组" class="md-nav__link">
      树状数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/segment/" title="线段树" class="md-nav__link">
      线段树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/dividing/" title="划分树" class="md-nav__link">
      划分树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-17" type="checkbox" id="nav-7-17">
    
    <label class="md-nav__link" for="nav-7-17">
      平衡树
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-17">
        平衡树
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/bst/" title="二叉搜索树简介" class="md-nav__link">
      二叉搜索树简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/treap/" title="Treap" class="md-nav__link">
      Treap
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/splay/" title="Splay" class="md-nav__link">
      Splay
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/wblt/" title="WBLT" class="md-nav__link">
      WBLT
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/sbt/" title="Size Balanced Tree" class="md-nav__link">
      Size Balanced Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/avl/" title="AVL 树" class="md-nav__link">
      AVL 树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/scapegoat/" title="替罪羊树" class="md-nav__link">
      替罪羊树
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-18" type="checkbox" id="nav-7-18">
    
    <label class="md-nav__link" for="nav-7-18">
      树套树
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-18">
        树套树
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/seg-in-seg/" title="线段树套线段树" class="md-nav__link">
      线段树套线段树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/seg-in-balanced/" title="平衡树套线段树" class="md-nav__link">
      平衡树套线段树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/balanced-in-seg/" title="线段树套平衡树" class="md-nav__link">
      线段树套平衡树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent-in-bit/" title="树状数组套主席树" class="md-nav__link">
      树状数组套主席树
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/k-dtree/" title="K-Dtree" class="md-nav__link">
      K-Dtree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-20" type="checkbox" id="nav-7-20">
    
    <label class="md-nav__link" for="nav-7-20">
      可持久化数据结构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-20">
        可持久化数据结构
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent/" title="可持久化数据结构简介" class="md-nav__link">
      可持久化数据结构简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent-seg/" title="可持久化线段树" class="md-nav__link">
      可持久化线段树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent-block-array/" title="可持久化块状数组" class="md-nav__link">
      可持久化块状数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent-balanced/" title="可持久化平衡树" class="md-nav__link">
      可持久化平衡树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/persistent-trie/" title="可持久化字典树" class="md-nav__link">
      可持久化字典树
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/odt/" title="珂朵莉树" class="md-nav__link">
      珂朵莉树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/lct/" title="Link Cut Tree" class="md-nav__link">
      Link Cut Tree
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../ds/ett/" title="Euler Tour Tree" class="md-nav__link">
      Euler Tour Tree
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      GAN
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        GAN
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/" title="图论部分简介" class="md-nav__link">
      图论部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/basic/" title="图论基础" class="md-nav__link">
      图论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/traverse/" title="图的遍历" class="md-nav__link">
      图的遍历
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8-4" type="checkbox" id="nav-8-4">
    
    <label class="md-nav__link" for="nav-8-4">
      树上问题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-8-4">
        树上问题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/tree-basic/" title="树基础" class="md-nav__link">
      树基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/lca/" title="最近公共祖先" class="md-nav__link">
      最近公共祖先
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/dfs-order/" title="DFS 序" class="md-nav__link">
      DFS 序
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/tree-misc/" title="树的其他问题" class="md-nav__link">
      树的其他问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/tree-hash/" title="树哈希" class="md-nav__link">
      树哈希
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/heavy-light-decomposition/" title="树链剖分" class="md-nav__link">
      树链剖分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/tree-divide/" title="树分治" class="md-nav__link">
      树分治
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/dynamic-tree-divide/" title="动态树分治" class="md-nav__link">
      动态树分治
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/virtual-tree/" title="虚树" class="md-nav__link">
      虚树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/dsu-on-tree/" title="树上启发式合并" class="md-nav__link">
      树上启发式合并
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/matrix-tree/" title="矩阵树定理" class="md-nav__link">
      矩阵树定理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/dag/" title="有向无环图" class="md-nav__link">
      有向无环图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/topo/" title="拓扑排序" class="md-nav__link">
      拓扑排序
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/mst/" title="最小生成树" class="md-nav__link">
      最小生成树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/mdst/" title="最小树形图" class="md-nav__link">
      最小树形图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/shortest-path/" title="最短路" class="md-nav__link">
      最短路
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/differential-constraints/" title="差分约束" class="md-nav__link">
      差分约束
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/kth-path/" title="k 短路" class="md-nav__link">
      k 短路
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8-13" type="checkbox" id="nav-8-13">
    
    <label class="md-nav__link" for="nav-8-13">
      连通性相关
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-8-13">
        连通性相关
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/scc/" title="强连通分量" class="md-nav__link">
      强连通分量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/bcc/" title="双连通分量" class="md-nav__link">
      双连通分量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/bridge/" title="割点和桥" class="md-nav__link">
      割点和桥
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/2-sat/" title="2-SAT" class="md-nav__link">
      2-SAT
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/euler/" title="欧拉图" class="md-nav__link">
      欧拉图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/hamilton/" title="哈密顿图" class="md-nav__link">
      哈密顿图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/bi-graph/" title="二分图" class="md-nav__link">
      二分图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/min-circle/" title="最小环" class="md-nav__link">
      最小环
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/planar/" title="平面图" class="md-nav__link">
      平面图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/color/" title="图的着色" class="md-nav__link">
      图的着色
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8-20" type="checkbox" id="nav-8-20">
    
    <label class="md-nav__link" for="nav-8-20">
      网络流
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-8-20">
        网络流
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/" title="网络流简介" class="md-nav__link">
      网络流简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/node/" title="拆点" class="md-nav__link">
      拆点
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/max-flow/" title="最大流" class="md-nav__link">
      最大流
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/min-cut/" title="最小割" class="md-nav__link">
      最小割
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/min-cost/" title="费用流" class="md-nav__link">
      费用流
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/flow/bound/" title="上下界网络流" class="md-nav__link">
      上下界网络流
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../graph/misc/" title="图论杂项" class="md-nav__link">
      图论杂项
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9">
    
    <label class="md-nav__link" for="nav-9">
      计算机视觉
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        计算机视觉
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/" title="计算几何部分简介" class="md-nav__link">
      计算几何部分简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/2d/" title="二维计算几何基础" class="md-nav__link">
      二维计算几何基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/3d/" title="三维计算几何基础" class="md-nav__link">
      三维计算几何基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/distance/" title="距离" class="md-nav__link">
      距离
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/pick/" title="Pick 定理" class="md-nav__link">
      Pick 定理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/triangulation/" title="三角剖分" class="md-nav__link">
      三角剖分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/convex-hull/" title="凸包" class="md-nav__link">
      凸包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/scanning/" title="扫描线" class="md-nav__link">
      扫描线
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/rotating-calipers/" title="旋转卡壳" class="md-nav__link">
      旋转卡壳
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/half-plane-intersection/" title="半平面交" class="md-nav__link">
      半平面交
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/nearest-points/" title="平面最近点对" class="md-nav__link">
      平面最近点对
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../geometry/magic/" title="计算几何杂项" class="md-nav__link">
      计算几何杂项
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-10" type="checkbox" id="nav-10">
    
    <label class="md-nav__link" for="nav-10">
      NLP
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-10">
        NLP
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/" title="杂项简介" class="md-nav__link">
      杂项简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/io/" title="读入、输出优化" class="md-nav__link">
      读入、输出优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/complexity/" title="复杂度" class="md-nav__link">
      复杂度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/discrete/" title="离散化" class="md-nav__link">
      离散化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-10-5" type="checkbox" id="nav-10-5">
    
    <label class="md-nav__link" for="nav-10-5">
      离线算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-10-5">
        离线算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/offline/" title="离线算法简介" class="md-nav__link">
      离线算法简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/cdq-divide/" title="CDQ 分治" class="md-nav__link">
      CDQ 分治
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/mo-algo/" title="莫队算法" class="md-nav__link">
      莫队算法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/fractional-programming/" title="分数规划" class="md-nav__link">
      分数规划
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-10-7" type="checkbox" id="nav-10-7">
    
    <label class="md-nav__link" for="nav-10-7">
      随机化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-10-7">
        随机化
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/random/" title="随机函数" class="md-nav__link">
      随机函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/hill-climbing/" title="爬山算法" class="md-nav__link">
      爬山算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/simulated-annealing/" title="模拟退火" class="md-nav__link">
      模拟退火
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/random-incremental/" title="随机增量法" class="md-nav__link">
      随机增量法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/largest-matrix/" title="悬线法" class="md-nav__link">
      悬线法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/cc-basic/" title="计算理论基础" class="md-nav__link">
      计算理论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/endianness/" title="字节顺序" class="md-nav__link">
      字节顺序
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-11" type="checkbox" id="nav-11">
    
    <label class="md-nav__link" for="nav-11">
      推荐系统
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-11">
        推荐系统
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/" title="杂项简介" class="md-nav__link">
      杂项简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/io/" title="读入、输出优化" class="md-nav__link">
      读入、输出优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/complexity/" title="复杂度" class="md-nav__link">
      复杂度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/discrete/" title="离散化" class="md-nav__link">
      离散化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-11-5" type="checkbox" id="nav-11-5">
    
    <label class="md-nav__link" for="nav-11-5">
      离线算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-11-5">
        离线算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/offline/" title="离线算法简介" class="md-nav__link">
      离线算法简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/cdq-divide/" title="CDQ 分治" class="md-nav__link">
      CDQ 分治
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/mo-algo/" title="莫队算法" class="md-nav__link">
      莫队算法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/fractional-programming/" title="分数规划" class="md-nav__link">
      分数规划
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-11-7" type="checkbox" id="nav-11-7">
    
    <label class="md-nav__link" for="nav-11-7">
      随机化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-11-7">
        随机化
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/random/" title="随机函数" class="md-nav__link">
      随机函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/hill-climbing/" title="爬山算法" class="md-nav__link">
      爬山算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/simulated-annealing/" title="模拟退火" class="md-nav__link">
      模拟退火
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/random-incremental/" title="随机增量法" class="md-nav__link">
      随机增量法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/largest-matrix/" title="悬线法" class="md-nav__link">
      悬线法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/cc-basic/" title="计算理论基础" class="md-nav__link">
      计算理论基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../misc/endianness/" title="字节顺序" class="md-nav__link">
      字节顺序
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../about/" title="关于" class="md-nav__link">
      关于
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#121" title="12.1 优化目标" class="md-nav__link">
    12.1 优化目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#122" title="12.2 大边界的直观理解" class="md-nav__link">
    12.2 大边界的直观理解
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#123" title="12.3 大边界分类背后的数学（选修）" class="md-nav__link">
    12.3 大边界分类背后的数学（选修）
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#124-1" title="12.4 核函数1" class="md-nav__link">
    12.4 核函数1
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#125-2" title="12.5 核函数2" class="md-nav__link">
    12.5 核函数2
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#126" title="12.6 使用支持向量机" class="md-nav__link">
    12.6 使用支持向量机
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/myourdream/aiwiki/blob/master/docs/Coursera_ML_AndrewNg/markdown/week7.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="7">第7周<a class="headerlink" href="#7" title="Permanent link">&para;</a></h1>
<p>[TOC]
十二、支持向量机(Support Vector Machines)</p>
<hr />
<h3 id="121">12.1 优化目标<a class="headerlink" href="#121" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 1 - Optimization Objective (15 min).mkv</p>
<p>到目前为止,你已经见过一系列不同的学习算法。在监督学习中，许多学习算法的性能都非常类似，因此，重要的不是你该选择使用学习算法<strong>A</strong>还是学习算法<strong>B</strong>，而更重要的是，应用这些算法时，所创建的大量数据在应用这些算法时，表现情况通常依赖于你的水平。比如：你为学习算法所设计的特征量的选择，以及如何选择正则化参数，诸如此类的事。还有一个更加强大的算法广泛的应用于工业界和学术界，它被称为支持向量机(<strong>Support Vector Machine</strong>)。与逻辑回归和神经网络相比，支持向量机，或者简称<strong>SVM</strong>，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。因此，在接下来的视频中，我会探讨这一算法。在稍后的课程中，我也会对监督学习算法进行简要的总结。当然，仅仅是作简要描述。但对于支持向量机，鉴于该算法的强大和受欢迎度，在本课中，我会花许多时间来讲解它。它也是我们所介绍的最后一个监督学习算法。</p>
<p>正如我们之前开发的学习算法，我们从优化目标开始。那么，我们开始学习这个算法。为了描述支持向量机，事实上，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。</p>
<p><img alt="" src="../../images/3d12b07f13a976e916d0c707fd03153c.png" /></p>
<p>那么，在逻辑回归中我们已经熟悉了这里的假设函数形式，和右边的S型激励函数。然而，为了解释一些数学知识.我将用<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 表示<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>。</p>
<p>现在考虑下我们想要逻辑回归做什么：如果有一个 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>的样本，我的意思是不管是在训练集中或是在测试集中，又或者在交叉验证集中，总之是 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，现在我们希望<span><span class="MathJax_Preview">{{h}_{\theta }}\left( x \right)</span><script type="math/tex">{{h}_{\theta }}\left( x \right)</script></span> 趋近1。因为我们想要正确地将此样本分类，这就意味着当 <span><span class="MathJax_Preview">{{h}_{\theta }}\left( x \right)</span><script type="math/tex">{{h}_{\theta }}\left( x \right)</script></span>趋近于1时，<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span> 应当远大于0，这里的<span><span class="MathJax_Preview">&gt;&gt;</span><script type="math/tex">>></script></span>意思是远远大于0。这是因为由于 <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 表示 <span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>，当 <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>远大于0时，即到了该图的右边，你不难发现此时逻辑回归的输出将趋近于1。相反地，如果我们有另一个样本，即<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>。我们希望假设函数的输出值将趋近于0，这对应于<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>，或者就是 <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 会远小于0，因为对应的假设函数的输出值趋近0。</p>
<p><img alt="" src="../../images/66facb7fa8eddc3a860e420588c981d5.png" /></p>
<p>如果你进一步观察逻辑回归的代价函数，你会发现每个样本 <span><span class="MathJax_Preview">(x,y)</span><script type="math/tex">(x,y)</script></span>都会为总代价函数，增加这里的一项，因此，对于总代价函数通常会有对所有的训练样本求和，并且这里还有一个<span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span>项，但是，在逻辑回归中，这里的这一项就是表示一个训练样本所对应的表达式。现在，如果我将完整定义的假设函数代入这里。那么，我们就会得到每一个训练样本都影响这一项。</p>
<p>现在，先忽略 <span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span> 这一项，但是这一项是影响整个总代价函数中的这一项的。</p>
<p>现在，一起来考虑两种情况：</p>
<p>一种是<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>等于1的情况；另一种是 <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> 等于0的情况。</p>
<p>在第一种情况中，假设 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span> ，此时在目标函数中只需有第一项起作用，因为<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>时，<span><span class="MathJax_Preview">(1-y)</span><script type="math/tex">(1-y)</script></span>项将等于0。因此，当在 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span> 的样本中时，即在 $(x, y) $中 ，我们得到 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span> <span><span class="MathJax_Preview">-\log(1-\frac{1}{1+e^{-z}})​</span><script type="math/tex">-\log(1-\frac{1}{1+e^{-z}})​</script></span>这样一项，这里同上一张幻灯片一致。</p>
<p>我用 <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 表示<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>，即： <span><span class="MathJax_Preview">z= \theta^Tx</span><script type="math/tex">z= \theta^Tx</script></span>。当然，在代价函数中，<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> 前面有负号。我们只是这样表示，如果 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span> 代价函数中，这一项也等于1。这样做是为了简化此处的表达式。如果画出关于<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 的函数，你会看到左下角的这条曲线，我们同样可以看到，当<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 增大时，也就是相当于<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>增大时，<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span> 对应的值会变的非常小。对整个代价函数而言，影响也非常小。这也就解释了，为什么逻辑回归在观察到正样本<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>时，试图将<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>设置得非常大。因为，在代价函数中的这一项会变的非常小。</p>
<p>现在开始建立支持向量机，我们从这里开始：</p>
<p>我们会从这个代价函数开始，也就是<span><span class="MathJax_Preview">-\log(1-\frac{1}{1+e^{-z}})</span><script type="math/tex">-\log(1-\frac{1}{1+e^{-z}})</script></span>一点一点修改，让我取这里的<span><span class="MathJax_Preview">z=1</span><script type="math/tex">z=1</script></span> 点，我先画出将要用的代价函数。</p>
<p><img alt="" src="../../images/b4b43ee98bff9f5e73d841af1fa316bf.png" /></p>
<p>新的代价函数将会水平的从这里到右边(图外)，然后我再画一条同逻辑回归非常相似的直线，但是，在这里是一条直线，也就是我用紫红色画的曲线，就是这条紫红色的曲线。那么，到了这里已经非常接近逻辑回归中使用的代价函数了。只是这里是由两条线段组成，即位于右边的水平部分和位于左边的直线部分，先别过多的考虑左边直线部分的斜率，这并不是很重要。但是，这里我们将使用的新的代价函数，是在<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>的前提下的。你也许能想到，这应该能做同逻辑回归中类似的事情，但事实上，在之后的优化问题中，这会变得更坚定，并且为支持向量机，带来计算上的优势。例如，更容易计算股票交易的问题等等。</p>
<p>目前，我们只是讨论了<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>的情况，另外一种情况是当<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>时，此时如果你仔细观察代价函数只留下了第二项，因为第一项被消除了。如果当<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>时，那么这一项也就是0了。所以上述表达式只留下了第二项。因此，这个样本的代价或是代价函数的贡献。将会由这一项表示。并且，如果你将这一项作为<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>的函数，那么，这里就会得到横轴<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>。现在，你完成了支持向量机中的部分内容，同样地，我们要替代这一条蓝色的线，用相似的方法。</p>
<p><img alt="" src="../../images/ab372c9161375a4f7b6f0bd4a69560e9.png" /></p>
<p>如果我们用一个新的代价函数来代替，即这条从0点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为<span><span class="MathJax_Preview">{\cos}t_1{(z)}</span><script type="math/tex">{\cos}t_1{(z)}</script></span>，同时，右边函数我称它为<span><span class="MathJax_Preview">{\cos}t_0{(z)}</span><script type="math/tex">{\cos}t_0{(z)}</script></span>。这里的下标是指在代价函数中，对应的 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span> 和 <span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span> 的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。</p>
<p><img alt="" src="../../images/59541ab1fda4f92d6f1b508c8e29ab1c.png" /></p>
<p>这是我们在逻辑回归中使用代价函数<span><span class="MathJax_Preview">J(\theta)</span><script type="math/tex">J(\theta)</script></span>。也许这个方程看起来不是非常熟悉。这是因为之前有个负号在方程外面，但是，这里我所做的是，将负号移到了表达式的里面，这样做使得方程看起来有些不同。对于支持向量机而言，实质上我们要将这替换为<span><span class="MathJax_Preview">{\cos}t_1{(z)}</span><script type="math/tex">{\cos}t_1{(z)}</script></span>，也就是<span><span class="MathJax_Preview">{\cos}t_1{(\theta^Tx)}</span><script type="math/tex">{\cos}t_1{(\theta^Tx)}</script></span>，同样地，我也将这一项替换为<span><span class="MathJax_Preview">{\cos}t_0{(z)}</span><script type="math/tex">{\cos}t_0{(z)}</script></span>，也就是代价<span><span class="MathJax_Preview">{\cos}t_0{(\theta^Tx)}</span><script type="math/tex">{\cos}t_0{(\theta^Tx)}</script></span>。这里的代价函数<span><span class="MathJax_Preview">{\cos}t_1</span><script type="math/tex">{\cos}t_1</script></span>，就是之前所提到的那条线。此外，代价函数<span><span class="MathJax_Preview">{\cos}t_0</span><script type="math/tex">{\cos}t_0</script></span>，也是上面所介绍过的那条线。因此，对于支持向量机，我们得到了这里的最小化问题，即:</p>
<p><img alt="" src="../../images/4ac1ca54cb0f2c465ab81339baaf9186.png" /></p>
<p>然后，再加上正则化参数。现在，按照支持向量机的惯例，事实上，我们的书写会稍微有些不同，代价函数的参数表示也会稍微有些不同。</p>
<p>首先，我们要除去<span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span>这一项，当然，这仅仅是由于人们使用支持向量机时，对比于逻辑回归而言，不同的习惯所致，但这里我所说的意思是：你知道，我将要做的是仅仅除去<span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span>这一项，但是，这也会得出同样的 <span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span> 最优值，好的，因为<span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span> 仅是个常量，因此，你知道在这个最小化问题中，无论前面是否有<span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span> 这一项，最终我所得到的最优值<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>都是一样的。这里我的意思是，先给你举一个样本，假定有一最小化问题：即要求当<span><span class="MathJax_Preview">(u-5)^2+1</span><script type="math/tex">(u-5)^2+1</script></span>取得最小值时的<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>值，这时最小值为：当<span><span class="MathJax_Preview">u=5</span><script type="math/tex">u=5</script></span>时取得最小值。</p>
<p>现在，如果我们想要将这个目标函数乘上常数10，这里我的最小化问题就变成了：求使得<span><span class="MathJax_Preview">10×(u-5)^2+10</span><script type="math/tex">10×(u-5)^2+10</script></span>最小的值<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>，然而，使得这里最小的<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>值仍为5。因此将一些常数乘以你的最小化项，这并不会改变最小化该方程时得到<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>值。因此，这里我所做的是删去常量<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>。也相同的，我将目标函数乘上一个常量<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>，并不会改变取得最小值时的<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>值。</p>
<p>第二点概念上的变化，我们只是指在使用支持向量机时，一些如下的标准惯例，而不是逻辑回归。因此，对于逻辑回归，在目标函数中，我们有两项：第一个是训练样本的代价，第二个是我们的正则化项，我们不得不去用这一项来平衡。这就相当于我们想要最小化<span><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>加上正则化参数<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>，然后乘以其他项<span><span class="MathJax_Preview">B</span><script type="math/tex">B</script></span>对吧？这里的<span><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>表示这里的第一项，同时我用<strong>B</strong>表示第二项，但不包括<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>，我们不是优化这里的<span><span class="MathJax_Preview">A+\lambda\times B</span><script type="math/tex">A+\lambda\times B</script></span>。我们所做的是通过设置不同正则参数<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>达到优化目的。这样，我们就能够权衡对应的项，是使得训练样本拟合的更好。即最小化<span><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>。还是保证正则参数足够小，也即是对于<strong>B</strong>项而言，但对于支持向量机，按照惯例，我们将使用一个不同的参数替换这里使用的<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>来权衡这两项。你知道，就是第一项和第二项我们依照惯例使用一个不同的参数称为<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>，同时改为优化目标，<span><span class="MathJax_Preview">C×A+B</span><script type="math/tex">C×A+B</script></span>。
因此，在逻辑回归中，如果给定<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>，一个非常大的值，意味着给予<span><span class="MathJax_Preview">B</span><script type="math/tex">B</script></span>更大的权重。而这里，就对应于将<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 设定为非常小的值，那么，相应的将会给<span><span class="MathJax_Preview">B</span><script type="math/tex">B</script></span>比给<span><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>更大的权重。因此，这只是一种不同的方式来控制这种权衡或者一种不同的方法，即用参数来决定是更关心第一项的优化，还是更关心第二项的优化。当然你也可以把这里的参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 考虑成<span><span class="MathJax_Preview">1/\lambda</span><script type="math/tex">1/\lambda</script></span>，同 <span><span class="MathJax_Preview">1/\lambda</span><script type="math/tex">1/\lambda</script></span>所扮演的角色相同，并且这两个方程或这两个表达式并不相同，因为<span><span class="MathJax_Preview">C=1/\lambda</span><script type="math/tex">C=1/\lambda</script></span>，但是也并不全是这样，如果当<span><span class="MathJax_Preview">C=1/\lambda</span><script type="math/tex">C=1/\lambda</script></span>时，这两个优化目标应当得到相同的值，相同的最优值 <span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>。因此，就用它们来代替。那么，我现在删掉这里的<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>，并且用常数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>来代替。因此，这就得到了在支持向量机中我们的整个优化目标函数。然后最小化这个目标函数，得到<strong>SVM</strong> 学习到的参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>。</p>
<p><img alt="" src="../../images/5a63e35db410fdb57c76de97ea888278.png" /></p>
<p>最后有别于逻辑回归输出的概率。在这里，我们的代价函数，当最小化代价函数，获得参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>时，支持向量机所做的是它来直接预测<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>的值等于1，还是等于0。因此，这个假设函数会预测1。当<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>大于或者等于0时，或者等于0时，所以学习参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>就是支持向量机假设函数的形式。那么，这就是支持向量机数学上的定义。</p>
<p>在接下来的视频中，让我们再回去从直观的角度看看优化目标，实际上是在做什么，以及SVM的假设函数将会学习什么，同时也会谈谈如何做些许修改，学习更加复杂、非线性的函数。</p>
<h3 id="122">12.2 大边界的直观理解<a class="headerlink" href="#122" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 2 - Large Margin Intuition (11 min).mkv</p>
<p>人们有时将支持向量机看作是大间距分类器。在这一部分，我将介绍其中的含义，这有助于我们直观理解<strong>SVM</strong>模型的假设是什么样的。</p>
<p><img alt="" src="../../images/cc66af7cbd88183efc07c8ddf09cbc73.png" /></p>
<p>这是我的支持向量机模型的代价函数，在左边这里我画出了关于<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>的代价函数<span><span class="MathJax_Preview">{\cos}t_1{(z)}</span><script type="math/tex">{\cos}t_1{(z)}</script></span>，此函数用于正样本，而在右边这里我画出了关于<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>的代价函数<span><span class="MathJax_Preview">{\cos}t_0{(z)}</span><script type="math/tex">{\cos}t_0{(z)}</script></span>，横轴表示<span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>，现在让我们考虑一下，最小化这些代价函数的必要条件是什么。如果你有一个正样本，<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，则只有在<span><span class="MathJax_Preview">z&gt;=1</span><script type="math/tex">z>=1</script></span>时，代价函数<span><span class="MathJax_Preview">{\cos}t_1{(z)}</span><script type="math/tex">{\cos}t_1{(z)}</script></span>才等于0。</p>
<p>换句话说，如果你有一个正样本，我们会希望<span><span class="MathJax_Preview">\theta^Tx&gt;=1</span><script type="math/tex">\theta^Tx>=1</script></span>，反之，如果<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>，我们观察一下，函数<span><span class="MathJax_Preview">{\cos}t_0{(z)}</span><script type="math/tex">{\cos}t_0{(z)}</script></span>，它只有在<span><span class="MathJax_Preview">z&lt;=-1</span><script type="math/tex">z<=-1</script></span>的区间里函数值为0。这是支持向量机的一个有趣性质。事实上，如果你有一个正样本<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，则其实我们仅仅要求<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>大于等于0，就能将该样本恰当分出，这是因为如果<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>>0大的话，我们的模型代价函数值为0，类似地，如果你有一个负样本，则仅需要<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>\&lt;=0就会将负例正确分离，但是，支持向量机的要求更高，不仅仅要能正确分开输入的样本，即不仅仅要求<span><span class="MathJax_Preview">\theta^Tx</span><script type="math/tex">\theta^Tx</script></span>>0，我们需要的是比0值大很多，比如大于等于1，我也想这个比0小很多，比如我希望它小于等于-1，这就相当于在支持向量机中嵌入了一个额外的安全因子，或者说安全的间距因子。</p>
<p>当然，逻辑回归做了类似的事情。但是让我们看一下，在支持向量机中，这个因子会导致什么结果。具体而言，我接下来会考虑一个特例。我们将这个常数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>设置成一个非常大的值。比如我们假设<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>的值为100000或者其它非常大的数，然后来观察支持向量机会给出什么结果？</p>
<p><img alt="" src="../../images/12ebd5973230e8fdf279ae09e187f437.png" /></p>
<p>如果 <span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>非常大，则最小化代价函数的时候，我们将会很希望找到一个使第一项为0的最优解。因此，让我们尝试在代价项的第一项为0的情形下理解该优化问题。比如我们可以把<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>设置成了非常大的常数，这将给我们一些关于支持向量机模型的直观感受。</p>
<p><span><span class="MathJax_Preview">\min_\limits{\theta}C\sum_\limits{i=1}^{m}\left[y^{(i)}{\cos}t_{1}\left(\theta^{T}x^{(i)}\right)+\left(1-y^{(i)}\right){\cos}t\left(\theta^{T}x^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{i=1}^{n}\theta^{2}_{j}</span><script type="math/tex">\min_\limits{\theta}C\sum_\limits{i=1}^{m}\left[y^{(i)}{\cos}t_{1}\left(\theta^{T}x^{(i)}\right)+\left(1-y^{(i)}\right){\cos}t\left(\theta^{T}x^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{i=1}^{n}\theta^{2}_{j}</script></span></p>
<p>我们已经看到输入一个训练样本标签为<span><span class="MathJax_Preview">y=1​</span><script type="math/tex">y=1​</script></span>，你想令第一项为0，你需要做的是找到一个<span><span class="MathJax_Preview">{{\theta }}​</span><script type="math/tex">{{\theta }}​</script></span>，使得<span><span class="MathJax_Preview">\theta^Tx&gt;=1​</span><script type="math/tex">\theta^Tx>=1​</script></span>，类似地，对于一个训练样本，标签为<span><span class="MathJax_Preview">y=0​</span><script type="math/tex">y=0​</script></span>，为了使<span><span class="MathJax_Preview">{\cos}t_0{(z)}​</span><script type="math/tex">{\cos}t_0{(z)}​</script></span> 函数的值为0，我们需要<span><span class="MathJax_Preview">\theta^Tx&lt;=-1​</span><script type="math/tex">\theta^Tx<=-1​</script></span>。因此，现在考虑我们的优化问题。选择参数，使得第一项等于0，就会导致下面的优化问题，因为我们将选择参数使第一项为0，因此这个函数的第一项为0，因此是<span><span class="MathJax_Preview">C​</span><script type="math/tex">C​</script></span>乘以0加上二分之一乘以第二项。这里第一项是<span><span class="MathJax_Preview">C​</span><script type="math/tex">C​</script></span>乘以0，因此可以将其删去，因为我知道它是0。</p>
<p>这将遵从以下的约束：<span><span class="MathJax_Preview">\theta^Tx^{(i)}&gt;=1</span><script type="math/tex">\theta^Tx^{(i)}>=1</script></span>，如果 <span><span class="MathJax_Preview">y^{(i)}</span><script type="math/tex">y^{(i)}</script></span>是等于1 的，<span><span class="MathJax_Preview">\theta^Tx^{(i)}&lt;=-1</span><script type="math/tex">\theta^Tx^{(i)}<=-1</script></span>，如果样本<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>是一个负样本，这样当你求解这个优化问题的时候，当你最小化这个关于变量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的函数的时候，你会得到一个非常有趣的决策边界。</p>
<p><img alt="" src="../../images/b1f670fddd9529727aa16a559d49d151.png" /></p>
<p>具体而言，如果你考察这样一个数据集，其中有正样本，也有负样本，可以看到这个数据集是线性可分的。我的意思是，存在一条直线把正负样本分开。当然有多条不同的直线，可以把正样本和负样本完全分开。</p>
<p><img alt="" src="../../images/01105c3afd1315acf0577f8493137dcc.png" /></p>
<p>比如，这就是一个决策边界可以把正样本和负样本分开。但是多多少少这个看起来并不是非常自然是么?</p>
<p>或者我们可以画一条更差的决策界，这是另一条决策边界，可以将正样本和负样本分开，但仅仅是勉强分开，这些决策边界看起来都不是特别好的选择，支持向量机将会选择这个黑色的决策边界，相较于之前我用粉色或者绿色画的决策界。这条黑色的看起来好得多，黑线看起来是更稳健的决策界。在分离正样本和负样本上它显得的更好。数学上来讲，这是什么意思呢？这条黑线有更大的距离，这个距离叫做间距(<strong>margin</strong>)。</p>
<p><img alt="" src="../../images/e68e6ca3275f433330a7981971eb4f16.png" /></p>
<p>当画出这两条额外的蓝线，我们看到黑色的决策界和训练样本之间有更大的最短距离。然而粉线和蓝线离训练样本就非常近，在分离样本的时候就会比黑线表现差。因此，这个距离叫做支持向量机的间距，而这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。因此支持向量机有时被称为<strong>大间距分类器</strong>，而这其实是求解上一页幻灯片上优化问题的结果。</p>
<p>我知道你也许想知道求解上一页幻灯片中的优化问题为什么会产生这个结果？它是如何产生这个大间距分类器的呢？我知道我还没有解释这一点。</p>
<p>我将会从直观上略述为什么这个优化问题会产生大间距分类器。总之这个图示有助于你理解支持向量机模型的做法，即努力将正样本和负样本用最大的间距分开。</p>
<p><img alt="" src="../../images/dd6239efad3d3ee7a89a28574d7795b3.png" /></p>
<p>在本节课中关于大间距分类器，我想讲最后一点：我们将这个大间距分类器中的正则化因子常数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>设置的非常大，我记得我将其设置为了100000，因此对这样的一个数据集，也许我们将选择这样的决策界，从而最大间距地分离开正样本和负样本。那么在让代价函数最小化的过程中，我们希望找出在<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>和<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>两种情况下都使得代价函数中左边的这一项尽量为零的参数。如果我们找到了这样的参数，则我们的最小化问题便转变成：</p>
<p><img alt="" src="../../images/f4b6dee99cfb4352b3cac5287002e8de.png" /></p>
<p>事实上，支持向量机现在要比这个大间距分类器所体现得更成熟，尤其是当你使用大间距分类器的时候，你的学习算法会受异常点(outlier) 的影响。比如我们加入一个额外的正样本。</p>
<p><img alt="" src="../../images/b8fbe2f6ac48897cf40497a2d034c691.png" /></p>
<p>在这里，如果你加了这个样本，为了将样本用最大间距分开，也许我最终会得到一条类似这样的决策界，对么？就是这条粉色的线，仅仅基于一个异常值，仅仅基于一个样本，就将我的决策界从这条黑线变到这条粉线，这实在是不明智的。而如果正则化参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>，设置的非常大，这事实上正是支持向量机将会做的。它将决策界，从黑线变到了粉线，但是如果<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 设置的小一点，<strong>如果你将C设置的不要太大，则你最终会得到这条黑线，</strong>当然数据如果不是线性可分的，如果你在这里有一些正样本或者你在这里有一些负样本，则支持向量机也会将它们恰当分开。因此，大间距分类器的描述，仅仅是从直观上给出了正则化参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>非常大的情形，同时，要提醒你<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>的作用类似于<span><span class="MathJax_Preview">1/\lambda</span><script type="math/tex">1/\lambda</script></span>，<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>是我们之前使用过的正则化参数。这只是<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>非常大的情形，或者等价地 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> 非常小的情形。你最终会得到类似粉线这样的决策界，但是实际上应用支持向量机的时候，<strong>当<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>不是非常非常大的时候，它可以忽略掉一些异常点的影响，得到更好的决策界。</strong>甚至当你的数据不是线性可分的时候，支持向量机也可以给出好的结果。</p>
<p>回顾 <span><span class="MathJax_Preview">C=1/\lambda</span><script type="math/tex">C=1/\lambda</script></span>，因此：</p>
<p><span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 较大时，相当于 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> 较小，可能会导致过拟合，高方差。</p>
<p><span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 较小时，相当于<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>较大，可能会导致低拟合，高偏差。</p>
<p>我们稍后会介绍支持向量机的偏差和方差，希望在那时候关于如何处理参数的这种平衡会变得更加清晰。我希望，这节课给出了一些关于为什么支持向量机被看做大间距分类器的直观理解。它用最大间距将样本区分开，尽管从技术上讲，这只有当参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>是非常大的时候是真的，但是它对于理解支持向量机是有益的。</p>
<p>本节课中我们略去了一步，那就是我们在幻灯片中给出的优化问题。为什么会是这样的？它是如何得出大间距分类器的？我在本节中没有讲解，在下一节课中，我将略述这些问题背后的数学原理，来解释这个优化问题是如何得到一个大间距分类器的。</p>
<h3 id="123">12.3 大边界分类背后的数学（选修）<a class="headerlink" href="#123" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 3 - Mathematics Behind Large Margin Classification (Optional) (20 min).mkv</p>
<p>在本节课中，我将介绍一些大间隔分类背后的数学原理。本节为选修部分，你完全可以跳过它，但是听听这节课可能让你对支持向量机中的优化问题，以及如何得到大间距分类器，产生更好的直观理解。</p>
<p><img alt="" src="../../images/55e05845c636c8c99c03e6e29337d8c4.png" /></p>
<p>首先，让我来给大家复习一下关于向量内积的知识。假设我有两个向量，<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>，我将它们写在这里。两个都是二维向量，我们看一下，<span><span class="MathJax_Preview">u^T v</span><script type="math/tex">u^T v</script></span>的结果。<span><span class="MathJax_Preview">u^T v</span><script type="math/tex">u^T v</script></span>也叫做向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>之间的内积。由于是二维向量，我可以将它们画在这个图上。我们说，这就是向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>即在横轴上，取值为某个<span><span class="MathJax_Preview">{{u}_{1}}</span><script type="math/tex">{{u}_{1}}</script></span>，而在纵轴上，高度是某个<span><span class="MathJax_Preview">{{u}_{2}}</span><script type="math/tex">{{u}_{2}}</script></span>作为<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的第二个分量。现在，很容易计算的一个量就是向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的范数。<span><span class="MathJax_Preview">\left\| u \right\|</span><script type="math/tex">\left\| u \right\|</script></span>表示<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的范数，即<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的长度，即向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的欧几里得长度。根据毕达哥拉斯定理，<span><span class="MathJax_Preview">\left\| u \right\|=\sqrt{u_{1}^{2}+u_{2}^{2}}</span><script type="math/tex">\left\| u \right\|=\sqrt{u_{1}^{2}+u_{2}^{2}}</script></span>，这是向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的长度，它是一个实数。现在你知道了这个的长度是多少了。我刚刚画的这个向量的长度就知道了。</p>
<p>现在让我们回头来看向量<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span> ，因为我们想计算内积。<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>是另一个向量，它的两个分量<span><span class="MathJax_Preview">{{v}_{1}}</span><script type="math/tex">{{v}_{1}}</script></span>和<span><span class="MathJax_Preview">{{v}_{2}}</span><script type="math/tex">{{v}_{2}}</script></span>是已知的。向量<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>可以画在这里，现在让我们来看看如何计算<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>之间的内积。这就是具体做法，我们将向量<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>投影到向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上，我们做一个直角投影，或者说一个90度投影将其投影到<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上，接下来我度量这条红线的长度。我称这条红线的长度为<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>，因此<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>就是长度，或者说是向量<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>投影到向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上的量，我将它写下来，<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>是<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>投影到向量<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上的长度，因此可以将<span><span class="MathJax_Preview">{{u}^{T}}v=p\centerdot \left\| u \right\|</span><script type="math/tex">{{u}^{T}}v=p\centerdot \left\| u \right\|</script></span>，或者说<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的长度。这是计算内积的一种方法。如果你从几何上画出<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>的值，同时画出<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的范数，你也会同样地计算出内积，答案是一样的。另一个计算公式是：<span><span class="MathJax_Preview">u^T v</span><script type="math/tex">u^T v</script></span>就是<span><span class="MathJax_Preview">\left[ {{u}_{1}}\text{ }{{u}_{2}} \right]</span><script type="math/tex">\left[ {{u}_{1}}\text{ }{{u}_{2}} \right]</script></span> 这个一行两列的矩阵乘以<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>。因此可以得到<span><span class="MathJax_Preview">{{u}_{1}}\times {{v}_{1}}+{{u}_{2}}\times {{v}_{2}}</span><script type="math/tex">{{u}_{1}}\times {{v}_{1}}+{{u}_{2}}\times {{v}_{2}}</script></span>。根据线性代数的知识，这两个公式会给出同样的结果。顺便说一句，<span><span class="MathJax_Preview">u^Tv=v^Tu</span><script type="math/tex">u^Tv=v^Tu</script></span>。因此如果你将<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>交换位置，将<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>投影到<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>上，而不是将<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>投影到<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上，然后做同样地计算，只是把<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>的位置交换一下，你事实上可以得到同样的结果。申明一点，在这个等式中<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的范数是一个实数，<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>也是一个实数，因此<span><span class="MathJax_Preview">u^T v</span><script type="math/tex">u^T v</script></span>就是两个实数正常相乘。</p>
<p><img alt="" src="../../images/44ad37bce4b7e03835095dccbd2a7b7a.png" /></p>
<p>最后一点，需要注意的就是<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>值，<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>事实上是有符号的，即它可能是正值，也可能是负值。我的意思是说，如果<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>是一个类似这样的向量，<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>是一个类似这样的向量，<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>之间的夹角大于90度，则如果将<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>投影到<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>上，会得到这样的一个投影，这是<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>的长度，在这个情形下我们仍然有<span><span class="MathJax_Preview">{{u}^{T}}v</span><script type="math/tex">{{u}^{T}}v</script></span>是等于<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>乘以<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>的范数。唯一一点不同的是<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>在这里是负的。在内积计算中，如果<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>之间的夹角小于90度，那么那条红线的长度<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>是正值。然而如果这个夹角大于90度，则<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>将会是负的。就是这个小线段的长度是负的。如果它们之间的夹角大于90度，两个向量之间的内积也是负的。这就是关于向量内积的知识。我们接下来将会使用这些关于向量内积的性质试图来理解支持向量机中的目标函数。</p>
<p><img alt="" src="../../images/03bd4b3ff69e327f7949c3d2a73eed8a.png" /></p>
<p>这就是我们先前给出的支持向量机模型中的目标函数。为了讲解方便，我做一点简化，仅仅是为了让目标函数更容易被分析。</p>
<p><img alt="" src="../../images/3cc61c6e5fe85c2a7bf8170f5bbfd8c3.png" /></p>
<p>我接下来忽略掉截距，令<span><span class="MathJax_Preview">{{\theta }_{0}}=0</span><script type="math/tex">{{\theta }_{0}}=0</script></span>，这样更容易画示意图。我将特征数<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>置为2，因此我们仅有两个特征<span><span class="MathJax_Preview">{{x}_{1}},{{x}_{2}}</span><script type="math/tex">{{x}_{1}},{{x}_{2}}</script></span>，现在我们来看一下目标函数，支持向量机的优化目标函数。当我们仅有两个特征，即<span><span class="MathJax_Preview">n=2</span><script type="math/tex">n=2</script></span>时，这个式子可以写作：<span><span class="MathJax_Preview">\frac{1}{2}\left({\theta_1^2+\theta_2^2}\right)=\frac{1}{2}\left(\sqrt{\theta_1^2+\theta_2^2}\right)^2</span><script type="math/tex">\frac{1}{2}\left({\theta_1^2+\theta_2^2}\right)=\frac{1}{2}\left(\sqrt{\theta_1^2+\theta_2^2}\right)^2</script></span>，我们只有两个参数<span><span class="MathJax_Preview">{{\theta }_{1}},{{\theta }_{2}}</span><script type="math/tex">{{\theta }_{1}},{{\theta }_{2}}</script></span>。你可能注意到括号里面的这一项是向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数，或者说是向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的长度。我的意思是如果我们将向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>写出来，那么我刚刚画红线的这一项就是向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的长度或范数。这里我们用的是之前学过的向量范数的定义，事实上这就等于向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的长度。</p>
<p>当然你可以将其写作<span><span class="MathJax_Preview">{{\theta }_{0}}\text{,}{{\theta }_{1}},{{\theta }_{2}}</span><script type="math/tex">{{\theta }_{0}}\text{,}{{\theta }_{1}},{{\theta }_{2}}</script></span>，如果<span><span class="MathJax_Preview">{{\theta }_{0}}=0</span><script type="math/tex">{{\theta }_{0}}=0</script></span>，那就是<span><span class="MathJax_Preview">{{\theta }_{1}},{{\theta }_{2}}</span><script type="math/tex">{{\theta }_{1}},{{\theta }_{2}}</script></span>的长度。在这里我将忽略<span><span class="MathJax_Preview">{{\theta }_{0}}</span><script type="math/tex">{{\theta }_{0}}</script></span>，这样来写<span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>的范数，它仅仅和<span><span class="MathJax_Preview">{{\theta }_{1}},{{\theta }_{2}}</span><script type="math/tex">{{\theta }_{1}},{{\theta }_{2}}</script></span>有关。但是，数学上不管你是否包含，其实并没有差别，因此在我们接下来的推导中去掉<span><span class="MathJax_Preview">{{\theta }_{0}}</span><script type="math/tex">{{\theta }_{0}}</script></span>不会有影响这意味着我们的目标函数是等于<span><span class="MathJax_Preview">\frac{1}{2}\left\| \theta \right\|^2</span><script type="math/tex">\frac{1}{2}\left\| \theta \right\|^2</script></span>。因此支持向量机做的全部事情，就是<strong>极小化参数向量</strong><span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span><strong>范数的平方，或者说长度的平方</strong>。</p>
<p>现在我将要看看这些项：<span><span class="MathJax_Preview">\theta^{T}x</span><script type="math/tex">\theta^{T}x</script></span>更深入地理解它们的含义。给定参数向量<span><span class="MathJax_Preview">\theta <span><span class="MathJax_Preview">给定一个样本</span><script type="math/tex">给定一个样本</script></span>xx</span><script type="math/tex">\theta <span><span class="MathJax_Preview">给定一个样本</span><script type="math/tex">给定一个样本</script></span>xx</script></span>，这等于什么呢?在前一页幻灯片上，我们画出了在不同情形下，<span><span class="MathJax_Preview">u^Tv</span><script type="math/tex">u^Tv</script></span>的示意图，我们将会使用这些概念，<span><span class="MathJax_Preview">\theta <span><span class="MathJax_Preview">和</span><script type="math/tex">和</script></span>x</span><script type="math/tex">\theta <span><span class="MathJax_Preview">和</span><script type="math/tex">和</script></span>x<sup>{(i)}x</sup>{(i)}</script></span>就类似于<span><span class="MathJax_Preview">u</span><script type="math/tex">u</script></span>和<span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span> 。</p>
<p><img alt="" src="../../images/4510b8fbc90ba2b233bb6996529f2df1.png" /></p>
<p>让我们看一下示意图：我们考察一个单一的训练样本，我有一个正样本在这里，用一个叉来表示这个样本<span><span class="MathJax_Preview">x^{(i)}​</span><script type="math/tex">x^{(i)}​</script></span>，意思是在水平轴上取值为<span><span class="MathJax_Preview">x_1^{(i)}​</span><script type="math/tex">x_1^{(i)}​</script></span>，在竖直轴上取值为<span><span class="MathJax_Preview">x_2^{(i)}​</span><script type="math/tex">x_2^{(i)}​</script></span>。这就是我画出的训练样本。尽管我没有将其真的看做向量。它事实上就是一个始于原点，终点位置在这个训练样本点的向量。现在，我们有一个参数向量我会将它也画成向量。我将<span><span class="MathJax_Preview">θ_1​</span><script type="math/tex">θ_1​</script></span>画在横轴这里，将<span><span class="MathJax_Preview">θ_2​</span><script type="math/tex">θ_2​</script></span> 画在纵轴这里，那么内积<span><span class="MathJax_Preview">θ^T x^{(i)}</span><script type="math/tex">θ^T x^{(i)}</script></span> 将会是什么呢？</p>
<p>使用我们之前的方法，我们计算的方式就是我将训练样本投影到参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>，然后我来看一看这个线段的长度，我将它画成红色。我将它称为<span><span class="MathJax_Preview">p^{(i)}</span><script type="math/tex">p^{(i)}</script></span>用来表示这是第 <span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>个训练样本在参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>上的投影。根据我们之前幻灯片的内容，我们知道的是<span><span class="MathJax_Preview">θ^Tx^{(i)}</span><script type="math/tex">θ^Tx^{(i)}</script></span>将会等于<span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span> 乘以向量 <span><span class="MathJax_Preview">θ</span><script type="math/tex">θ</script></span> 的长度或范数。这就等于<span><span class="MathJax_Preview">\theta_1\cdot{x_1^{(i)}}+\theta_2\cdot{x_2^{(i)}}</span><script type="math/tex">\theta_1\cdot{x_1^{(i)}}+\theta_2\cdot{x_2^{(i)}}</script></span>。这两种方式是等价的，都可以用来计算<span><span class="MathJax_Preview">θ</span><script type="math/tex">θ</script></span>和<span><span class="MathJax_Preview">x^{(i)}</span><script type="math/tex">x^{(i)}</script></span>之间的内积。</p>
<p>这告诉了我们什么呢？这里表达的意思是：这个<span><span class="MathJax_Preview">θ^Tx^{(i)}&gt;=1</span><script type="math/tex">θ^Tx^{(i)}>=1</script></span>  或者<span><span class="MathJax_Preview">θ^Tx^{(i)}&lt;-1</span><script type="math/tex">θ^Tx^{(i)}<-1</script></span>的,约束是可以被<span><span class="MathJax_Preview">p^{(i)}\cdot{x}&gt;=1</span><script type="math/tex">p^{(i)}\cdot{x}>=1</script></span>这个约束所代替的。因为<span><span class="MathJax_Preview">θ^Tx^{(i)}=p^{(i)}\cdot{\left\| \theta \right\|}</span><script type="math/tex">θ^Tx^{(i)}=p^{(i)}\cdot{\left\| \theta \right\|}</script></span> ，将其写入我们的优化目标。我们将会得到没有了约束，<span><span class="MathJax_Preview">θ^Tx^{(i)}</span><script type="math/tex">θ^Tx^{(i)}</script></span>而变成了<span><span class="MathJax_Preview">p^{(i)}\cdot{\left\| \theta \right\|}</span><script type="math/tex">p^{(i)}\cdot{\left\| \theta \right\|}</script></span>。</p>
<p><img alt="" src="../../images/912cb43058cee46ddf51598b7538968c.png" /></p>
<p>需要提醒一点，我们之前曾讲过这个优化目标函数可以被写成等于<span><span class="MathJax_Preview">\frac{1}{2}\left\| \theta \right\|^2</span><script type="math/tex">\frac{1}{2}\left\| \theta \right\|^2</script></span>。</p>
<p>现在让我们考虑下面这里的训练样本。现在，继续使用之前的简化，即<span><span class="MathJax_Preview">{{\theta }_{0}}=0</span><script type="math/tex">{{\theta }_{0}}=0</script></span>，我们来看一下支持向量机会选择什么样的决策界。这是一种选择，我们假设支持向量机会选择这个决策边界。这不是一个非常好的选择，因为它的间距很小。这个决策界离训练样本的距离很近。我们来看一下为什么支持向量机不会选择它。</p>
<p>对于这样选择的参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>，可以看到参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>事实上是和决策界是90度正交的，因此这个绿色的决策界对应着一个参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>这个方向,顺便提一句<span><span class="MathJax_Preview">{{\theta }_{0}}=0</span><script type="math/tex">{{\theta }_{0}}=0</script></span>的简化仅仅意味着决策界必须通过原点<span><span class="MathJax_Preview">(0,0)</span><script type="math/tex">(0,0)</script></span>。现在让我们看一下这对于优化目标函数意味着什么。</p>
<p><img alt="" src="../../images/20725ba601c1c90d1024e50fc24c579b.png" /></p>
<p>比如这个样本，我们假设它是我的第一个样本<span><span class="MathJax_Preview">x^{(1)}</span><script type="math/tex">x^{(1)}</script></span>，如果我考察这个样本到参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的投影，投影是这个短的红线段，就等于<span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span>，它非常短。类似地，这个样本如果它恰好是<span><span class="MathJax_Preview">x^{(2)}</span><script type="math/tex">x^{(2)}</script></span>，我的第二个训练样本，则它到<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的投影在这里。我将它画成粉色，这个短的粉色线段是<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>，即第二个样本到我的参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的投影。因此，这个投影非常短。<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>事实上是一个负值，<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>是在相反的方向，这个向量和参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的夹角大于90度，<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>的值小于0。</p>
<p>我们会发现这些<span><span class="MathJax_Preview">p^{(i)}</span><script type="math/tex">p^{(i)}</script></span>将会是非常小的数，因此当我们考察优化目标函数的时候，对于正样本而言，我们需要<span><span class="MathJax_Preview">p^{(i)}\cdot{\left\| \theta \right\|}&gt;=1</span><script type="math/tex">p^{(i)}\cdot{\left\| \theta \right\|}>=1</script></span>,但是如果 <span><span class="MathJax_Preview">p^{(i)}</span><script type="math/tex">p^{(i)}</script></span>在这里非常小,那就意味着我们需要<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数非常大.因为如果 <span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span> 很小,而我们希望<span><span class="MathJax_Preview">p^{(1)}\cdot{\left\| \theta \right\|}&gt;=1</span><script type="math/tex">p^{(1)}\cdot{\left\| \theta \right\|}>=1</script></span>,令其实现的唯一的办法就是这两个数较大。如果 <span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span> 小，我们就希望<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数大。类似地，对于负样本而言我们需要<span><span class="MathJax_Preview">p^{(2)}\cdot{\left\|\theta \right\|}&lt;=-1</span><script type="math/tex">p^{(2)}\cdot{\left\|\theta \right\|}<=-1</script></span>。我们已经在这个样本中看到<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>会是一个非常小的数，因此唯一的办法就是<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数变大。但是我们的目标函数是希望找到一个参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>，它的范数是小的。因此，这看起来不像是一个好的参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的选择。</p>
<p><img alt="" src="../../images/5eab58ad9cb54b3b6fda8f6c96efff24.png" /></p>
<p>相反的，来看一个不同的决策边界。比如说，支持向量机选择了这个决策界，现在状况会有很大不同。如果这是决策界，这就是相对应的参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的方向，因此，在这个决策界之下，垂直线是决策界。使用线性代数的知识，可以说明，这个绿色的决策界有一个垂直于它的向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>。现在如果你考察你的数据在横轴<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>上的投影，比如这个我之前提到的样本，我的样本<span><span class="MathJax_Preview">x^{(1)}</span><script type="math/tex">x^{(1)}</script></span>，当我将它投影到横轴<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>上，或说投影到<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>上，就会得到这样<span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span>。它的长度是<span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span>，另一个样本，那个样本是<span><span class="MathJax_Preview">x^{(2)}</span><script type="math/tex">x^{(2)}</script></span>。我做同样的投影，我会发现，<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>的长度是负值。你会注意到现在<span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span> 和<span><span class="MathJax_Preview">p^{(2)}</span><script type="math/tex">p^{(2)}</script></span>这些投影长度是长多了。如果我们仍然要满足这些约束，<span><span class="MathJax_Preview">P^{(i)}\cdot{\left\| \theta \right\|}</span><script type="math/tex">P^{(i)}\cdot{\left\| \theta \right\|}</script></span>>1，则因为<span><span class="MathJax_Preview">p^{(1)}</span><script type="math/tex">p^{(1)}</script></span>变大了，<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数就可以变小了。因此这意味着通过选择右边的决策界，而不是左边的那个，支持向量机可以使参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数变小很多。因此，如果我们想令<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>的范数变小，从而令<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>范数的平方变小，就能让支持向量机选择右边的决策界。这就是支持向量机如何能有效地产生大间距分类的原因。</p>
<p>看这条绿线，这个绿色的决策界。我们希望正样本和负样本投影到<span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>的值大。要做到这一点的唯一方式就是选择这条绿线做决策界。这是大间距决策界来区分开正样本和负样本这个间距的值。这个间距的值就是<span><span class="MathJax_Preview">p^{(1)},p^{(2)},p^{(3)}</span><script type="math/tex">p^{(1)},p^{(2)},p^{(3)}</script></span>等等的值。通过让间距变大，即通过这些<span><span class="MathJax_Preview">p^{(1)},p^{(2)},p^{(3)}</span><script type="math/tex">p^{(1)},p^{(2)},p^{(3)}</script></span>等等的值，支持向量机最终可以找到一个较小的<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>范数。这正是支持向量机中最小化目标函数的目的。</p>
<p>以上就是为什么支持向量机最终会找到大间距分类器的原因。因为它试图极大化这些<span><span class="MathJax_Preview">p^{(i)}</span><script type="math/tex">p^{(i)}</script></span>的范数，它们是训练样本到决策边界的距离。最后一点，我们的推导自始至终使用了这个简化假设，就是参数<span><span class="MathJax_Preview">θ_0=0</span><script type="math/tex">θ_0=0</script></span>。</p>
<p><img alt="" src="../../images/65198a1748fdbe16da34afab9f33d801.png" /></p>
<p>就像我之前提到的。这个的作用是：<span><span class="MathJax_Preview">θ_0=0</span><script type="math/tex">θ_0=0</script></span>的意思是我们让决策界通过原点。如果你令<span><span class="MathJax_Preview">θ_0</span><script type="math/tex">θ_0</script></span>不是0的话，含义就是你希望决策界不通过原点。我将不会做全部的推导。实际上，支持向量机产生大间距分类器的结论，会被证明同样成立，证明方式是非常类似的，是我们刚刚做的证明的推广。</p>
<p>之前视频中说过，即便<span><span class="MathJax_Preview">θ_0</span><script type="math/tex">θ_0</script></span>不等于0，支持向量机要做的事情都是优化这个目标函数对应着<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>值非常大的情况，但是可以说明的是，即便<span><span class="MathJax_Preview">θ_0</span><script type="math/tex">θ_0</script></span>不等于0，支持向量机仍然会找到正样本和负样本之间的大间距分隔。</p>
<p>总之，我们解释了为什么支持向量机是一个大间距分类器。在下一节我们，将开始讨论如何利用支持向量机的原理，应用它们建立一个复杂的非线性分类器。</p>
<h3 id="124-1">12.4 核函数1<a class="headerlink" href="#124-1" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 4 - Kernels I (16 min).mkv</p>
<p>回顾我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题：</p>
<p><img alt="" src="../../images/529b6dbc07c9f39f5266bd0b3f628545.png" /></p>
<p>为了获得上图所示的判定边界，我们的模型可能是${{\theta }<em>{0}}+{{\theta }</em>{1}}{{x}<em>{1}}+{{\theta }</em>{2}}{{x}<em>{2}}+{{\theta }</em>{3}}{{x}<em>{1}}{{x}</em>{2}}+{{\theta }<em>{4}}x</em>{1}^{2}+{{\theta }<em>{5}}x</em>{2}^{2}+\cdots $的形式。</p>
<p>我们可以用一系列的新的特征<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>来替换模型中的每一项。例如令：
<span><span class="MathJax_Preview">{{f}_{1}}={{x}_{1}},{{f}_{2}}={{x}_{2}},{{f}_{3}}={{x}_{1}}{{x}_{2}},{{f}_{4}}=x_{1}^{2},{{f}_{5}}=x_{2}^{2}</span><script type="math/tex">{{f}_{1}}={{x}_{1}},{{f}_{2}}={{x}_{2}},{{f}_{3}}={{x}_{1}}{{x}_{2}},{{f}_{4}}=x_{1}^{2},{{f}_{5}}=x_{2}^{2}</script></span></p>
<p>...得到<span><span class="MathJax_Preview">h_θ(x)={{\theta }_{1}}f_1+{{\theta }_{2}}f_2+...+{{\theta }_{n}}f_n</span><script type="math/tex">h_θ(x)={{\theta }_{1}}f_1+{{\theta }_{2}}f_2+...+{{\theta }_{n}}f_n</script></span>。然而，除了对原有的特征进行组合以外，有没有更好的方法来构造<span><span class="MathJax_Preview">f_1,f_2,f_3</span><script type="math/tex">f_1,f_2,f_3</script></span>？我们可以利用核函数来计算出新的特征。</p>
<p>给定一个训练样本<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>，我们利用<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>的各个特征与我们预先选定的<strong>地标</strong>(<strong>landmarks</strong>)<span><span class="MathJax_Preview">l^{(1)},l^{(2)},l^{(3)}</span><script type="math/tex">l^{(1)},l^{(2)},l^{(3)}</script></span>的近似程度来选取新的特征<span><span class="MathJax_Preview">f_1,f_2,f_3</span><script type="math/tex">f_1,f_2,f_3</script></span>。</p>
<p><img alt="" src="../../images/2516821097bda5dfaf0b94e55de851e0.png" /></p>
<p>例如：<span><span class="MathJax_Preview">{{f}_{1}}=similarity(x,{{l}^{(1)}})=e(-\frac{{{\left\| x-{{l}^{(1)}} \right\|}^{2}}}{2{{\sigma }^{2}}})</span><script type="math/tex">{{f}_{1}}=similarity(x,{{l}^{(1)}})=e(-\frac{{{\left\| x-{{l}^{(1)}} \right\|}^{2}}}{2{{\sigma }^{2}}})</script></span></p>
<p>其中：<span><span class="MathJax_Preview">{{\left\| x-{{l}^{(1)}} \right\|}^{2}}=\sum{_{j=1}^{n}}{{({{x}_{j}}-l_{j}^{(1)})}^{2}}</span><script type="math/tex">{{\left\| x-{{l}^{(1)}} \right\|}^{2}}=\sum{_{j=1}^{n}}{{({{x}_{j}}-l_{j}^{(1)})}^{2}}</script></span>，为实例<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>中所有特征与地标<span><span class="MathJax_Preview">l^{(1)}</span><script type="math/tex">l^{(1)}</script></span>之间的距离的和。上例中的<span><span class="MathJax_Preview">similarity(x,{{l}^{(1)}})</span><script type="math/tex">similarity(x,{{l}^{(1)}})</script></span>就是核函数，具体而言，这里是一个<strong>高斯核函数</strong>(<strong>Gaussian Kernel</strong>)。 <strong>注：这个函数与正态分布没什么实际上的关系，只是看上去像而已。</strong></p>
<p>这些地标的作用是什么？如果一个训练样本<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>与地标<span><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>之间的距离近似于0，则新特征 <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>近似于<span><span class="MathJax_Preview">e^{-0}=1</span><script type="math/tex">e^{-0}=1</script></span>，如果训练样本<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>与地标<span><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>之间距离较远，则<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>近似于<span><span class="MathJax_Preview">e^{-(一个较大的数)}=0</span><script type="math/tex">e^{-(一个较大的数)}=0</script></span>。</p>
<p>假设我们的训练样本含有两个特征[<span><span class="MathJax_Preview">x_{1}</span><script type="math/tex">x_{1}</script></span> <span><span class="MathJax_Preview">x{_2}</span><script type="math/tex">x{_2}</script></span>]，给定地标<span><span class="MathJax_Preview">l^{(1)}</span><script type="math/tex">l^{(1)}</script></span>与不同的<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>值，见下图：</p>
<p><img alt="" src="../../images/b9acfc507a54f5ca13a3d50379972535.jpg" /></p>
<p>图中水平面的坐标为 <span><span class="MathJax_Preview">x_{1}</span><script type="math/tex">x_{1}</script></span>，<span><span class="MathJax_Preview">x_{2}</span><script type="math/tex">x_{2}</script></span>而垂直坐标轴代表<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>。可以看出，只有当<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>与<span><span class="MathJax_Preview">l^{(1)}</span><script type="math/tex">l^{(1)}</script></span>重合时<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>才具有最大值。随着<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>的改变<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>值改变的速率受到<span><span class="MathJax_Preview">\sigma^2</span><script type="math/tex">\sigma^2</script></span>的控制。</p>
<p>在下图中，当样本处于洋红色的点位置处，因为其离<span><span class="MathJax_Preview">l^{(1)}</span><script type="math/tex">l^{(1)}</script></span>更近，但是离<span><span class="MathJax_Preview">l^{(2)}</span><script type="math/tex">l^{(2)}</script></span>和<span><span class="MathJax_Preview">l^{(3)}</span><script type="math/tex">l^{(3)}</script></span>较远，因此<span><span class="MathJax_Preview">f_1</span><script type="math/tex">f_1</script></span>接近1，而<span><span class="MathJax_Preview">f_2</span><script type="math/tex">f_2</script></span>,<span><span class="MathJax_Preview">f_3</span><script type="math/tex">f_3</script></span>接近0。因此<span><span class="MathJax_Preview">h_θ(x)=θ_0+θ_1f_1+θ_2f_2+θ_1f_3&gt;0</span><script type="math/tex">h_θ(x)=θ_0+θ_1f_1+θ_2f_2+θ_1f_3>0</script></span>，因此预测<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>。同理可以求出，对于离<span><span class="MathJax_Preview">l^{(2)}</span><script type="math/tex">l^{(2)}</script></span>较近的绿色点，也预测<span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，但是对于蓝绿色的点，因为其离三个地标都较远，预测<span><span class="MathJax_Preview">y=0</span><script type="math/tex">y=0</script></span>。</p>
<p><img alt="" src="../../images/3d8959d0d12fe9914dc827d5a074b564.jpg" /></p>
<p>这样，图中红色的封闭曲线所表示的范围，便是我们依据一个单一的训练样本和我们选取的地标所得出的判定边界，在预测时，我们采用的特征不是训练样本本身的特征，而是通过核函数计算出的新特征<span><span class="MathJax_Preview">f_1,f_2,f_3</span><script type="math/tex">f_1,f_2,f_3</script></span>。</p>
<h3 id="125-2">12.5 核函数2<a class="headerlink" href="#125-2" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 5 - Kernels II (16 min).mkv</p>
<p>在上一节视频里，我们讨论了核函数这个想法，以及怎样利用它去实现支持向量机的一些新特性。在这一节视频中，我将补充一些缺失的细节，并简单的介绍一下怎么在实际中使用应用这些想法。</p>
<p>如何选择地标？</p>
<p>我们通常是根据训练集的数量选择地标的数量，即如果训练集中有<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>个样本，则我们选取<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>个地标，并且令:<span><span class="MathJax_Preview">l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},.....,l^{(m)}=x^{(m)}</span><script type="math/tex">l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},.....,l^{(m)}=x^{(m)}</script></span>。这样做的好处在于：现在我们得到的新特征是建立在原有特征与训练集中所有其他特征之间距离的基础之上的，即：</p>
<p><img alt="" src="../../images/eca2571849cc36748c26c68708a7a5bd.png" /></p>
<p><img alt="" src="../../images/ea31af620b0a0132fe494ebb4a362465.png" /></p>
<p>下面我们将核函数运用到支持向量机中，修改我们的支持向量机假设为：</p>
<p>• 给定<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>，计算新特征<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>，当<span><span class="MathJax_Preview">θ^Tf&gt;=0</span><script type="math/tex">θ^Tf>=0</script></span> 时，预测 <span><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，否则反之。 </p>
<p>相应地修改代价函数为：$\sum{<em>{j=1}^{n=m}}\theta </em>{j}<sup>{2}={{\theta}</sup>{T}}\theta $，</p>
<p><span><span class="MathJax_Preview">min C\sum\limits_{i=1}^{m}{[{{y}^{(i)}}cos {{t}_{1}}}( {{\theta }^{T}}{{f}^{(i)}})+(1-{{y}^{(i)}})cos {{t}_{0}}( {{\theta }^{T}}{{f}^{(i)}})]+\frac{1}{2}\sum\limits_{j=1}^{n=m}{\theta _{j}^{2}}</span><script type="math/tex">min C\sum\limits_{i=1}^{m}{[{{y}^{(i)}}cos {{t}_{1}}}( {{\theta }^{T}}{{f}^{(i)}})+(1-{{y}^{(i)}})cos {{t}_{0}}( {{\theta }^{T}}{{f}^{(i)}})]+\frac{1}{2}\sum\limits_{j=1}^{n=m}{\theta _{j}^{2}}</script></span>
在具体实施过程中，我们还需要对最后的正则化项进行些微调整，在计算<span><span class="MathJax_Preview">\sum{<em>{j=1}^{n=m}}\theta </em>{j}<sup>{2}={{\theta}</sup>{T}}\theta <span><span class="MathJax_Preview">时，我们用</span><script type="math/tex">时，我们用</script></span>θ</span><script type="math/tex">\sum{<em>{j=1}^{n=m}}\theta </em>{j}<sup>{2}={{\theta}</sup>{T}}\theta <span><span class="MathJax_Preview">时，我们用</span><script type="math/tex">时，我们用</script></span>θ<sup>TMθθ</sup>TMθ</script></span>代替<span><span class="MathJax_Preview">θ^Tθ</span><script type="math/tex">θ^Tθ</script></span>，其中<span><span class="MathJax_Preview">M</span><script type="math/tex">M</script></span>是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。</p>
<p>理论上讲，我们也可以在逻辑回归中使用核函数，但是上面使用 <span><span class="MathJax_Preview">M</span><script type="math/tex">M</script></span>来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。</p>
<p>在此，我们不介绍最小化支持向量机的代价函数的方法，你可以使用现有的软件包（如<strong>liblinear</strong>,<strong>libsvm</strong>等）。在使用这些软件包最小化我们的代价函数之前，我们通常需要编写核函数，并且如果我们使用高斯核函数，那么在使用之前进行特征缩放是非常必要的。</p>
<p>另外，支持向量机也可以不使用核函数，不使用核函数又称为<strong>线性核函数</strong>(<strong>linear kernel</strong>)，当我们不采用非常复杂的函数，或者我们的训练集特征非常多而样本非常少的时候，可以采用这种不带核函数的支持向量机。</p>
<p>下面是支持向量机的两个参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>和<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>的影响：</p>
<p><span><span class="MathJax_Preview">C=1/\lambda</span><script type="math/tex">C=1/\lambda</script></span></p>
<p><span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 较大时，相当于<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>较小，可能会导致过拟合，高方差；</p>
<p><span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span> 较小时，相当于<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>较大，可能会导致低拟合，高偏差；</p>
<p><span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>较大时，可能会导致低方差，高偏差；</p>
<p><span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>较小时，可能会导致低偏差，高方差。</p>
<p>如果你看了本周的编程作业，你就能亲自实现这些想法，并亲眼看到这些效果。这就是利用核函数的支持向量机算法，希望这些关于偏差和方差的讨论，能给你一些对于算法结果预期的直观印象。</p>
<h3 id="126">12.6 使用支持向量机<a class="headerlink" href="#126" title="Permanent link">&para;</a></h3>
<p>参考视频: 12 - 6 - Using An SVM (21 min).mkv</p>
<p>目前为止，我们已经讨论了<strong>SVM</strong>比较抽象的层面，在这个视频中我将要讨论到为了运行或者运用<strong>SVM</strong>。你实际上所需要的一些东西：支持向量机算法，提出了一个特别优化的问题。但是就如在之前的视频中我简单提到的，我真的不建议你自己写软件来求解参数<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>，因此由于今天我们中的很少人，或者其实没有人考虑过自己写代码来转换矩阵，或求一个数的平方根等我们只是知道如何去调用库函数来实现这些功能。同样的，用以解决<strong>SVM</strong>最优化问题的软件很复杂，且已经有研究者做了很多年数值优化了。因此你提出好的软件库和好的软件包来做这样一些事儿。然后强烈建议使用高优化软件库中的一个，而不是尝试自己落实一些数据。有许多好的软件库，我正好用得最多的两个是<strong>liblinear</strong>和<strong>libsvm</strong>，但是真的有很多软件库可以用来做这件事儿。你可以连接许多你可能会用来编写学习算法的主要编程语言。</p>
<p>在高斯核函数之外我们还有其他一些选择，如：</p>
<p>多项式核函数（<strong>Polynomial Kerne</strong>l）</p>
<p>字符串核函数（<strong>String kernel</strong>）</p>
<p>卡方核函数（ <strong>chi-square kernel</strong>）</p>
<p>直方图交集核函数（<strong>histogram intersection kernel</strong>）</p>
<p>等等...</p>
<p>这些核函数的目标也都是根据训练集和地标之间的距离来构建新特征，这些核函数需要满足Mercer's定理，才能被支持向量机的优化软件正确处理。</p>
<p>多类分类问题</p>
<p>假设我们利用之前介绍的一对多方法来解决一个多类分类问题。如果一共有<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个类，则我们需要<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个模型，以及<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个参数向量<span><span class="MathJax_Preview">{{\theta }}</span><script type="math/tex">{{\theta }}</script></span>。我们同样也可以训练<span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个支持向量机来解决多类分类问题。但是大多数支持向量机软件包都有内置的多类分类功能，我们只要直接使用即可。</p>
<p>尽管你不去写你自己的<strong>SVM</strong>的优化软件，但是你也需要做几件事：</p>
<p>1、是提出参数<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>的选择。我们在之前的视频中讨论过误差/方差在这方面的性质。</p>
<p>2、你也需要选择内核参数或你想要使用的相似函数，其中一个选择是：我们选择不需要任何内核参数，没有内核参数的理念，也叫线性核函数。因此，如果有人说他使用了线性核的<strong>SVM</strong>（支持向量机），这就意味这他使用了不带有核函数的<strong>SVM</strong>（支持向量机）。</p>
<p>从逻辑回归模型，我们得到了支持向量机模型，在两者之间，我们应该如何选择呢？</p>
<p><strong>下面是一些普遍使用的准则：</strong></p>
<p><span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>为特征数，<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>为训练样本数。</p>
<p>(1)如果相较于<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>而言，<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</p>
<p>(2)如果<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>较小，而且<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>大小中等，例如<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>在 1-1000 之间，而<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>在10-10000之间，使用高斯核函数的支持向量机。</p>
<p>(3)如果<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>较小，而<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>较大，例如<span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>在1-1000之间，而<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</p>
<p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p>
<p>今天的<strong>SVM</strong>包会工作得很好，但是它们仍然会有一些慢。当你有非常非常大的训练集，且用高斯核函数是在这种情况下，我经常会做的是尝试手动地创建，拥有更多的特征变量，然后用逻辑回归或者不带核函数的支持向量机。如果你看到这个幻灯片，看到了逻辑回归，或者不带核函数的支持向量机。在这个两个地方，我把它们放在一起是有原因的。原因是：逻辑回归和不带核函数的支持向量机它们都是非常相似的算法，不管是逻辑回归还是不带核函数的<strong>SVM</strong>，通常都会做相似的事情，并给出相似的结果。但是根据你实现的情况，其中一个可能会比另一个更加有效。但是在其中一个算法应用的地方，逻辑回归或不带核函数的<strong>SVM</strong>另一个也很有可能很有效。但是随着<strong>SVM</strong>的复杂度增加，当你使用不同的内核函数来学习复杂的非线性函数时，这个体系，你知道的，当你有多达1万（10,000）的样本时，也可能是5万（50,000），你的特征变量的数量这是相当大的。那是一个非常常见的体系，也许在这个体系里，不带核函数的支持向量机就会表现得相当突出。你可以做比这困难得多需要逻辑回归的事情。</p>
<p>最后，神经网络使用于什么时候呢？ 对于所有的这些问题，对于所有的这些不同体系一个设计得很好的神经网络也很有可能会非常有效。有一个缺点是，或者说是有时可能不会使用神经网络的原因是：对于许多这样的问题，神经网络训练起来可能会特别慢，但是如果你有一个非常好的<strong>SVM</strong>实现包，它可能会运行得比较快比神经网络快很多，尽管我们在此之前没有展示，但是事实证明，<strong>SVM</strong>具有的优化问题，是一种凸优化问题。因此，好的<strong>SVM</strong>优化软件包总是会找到全局最小值，或者接近它的值。对于<strong>SVM</strong>你不需要担心局部最优。在实际应用中，局部最优不是神经网络所需要解决的一个重大问题，所以这是你在使用<strong>SVM</strong>的时候不需要太去担心的一个问题。根据你的问题，神经网络可能会比<strong>SVM</strong>慢，尤其是在这样一个体系中，至于这里给出的参考，看上去有些模糊，如果你在考虑一些问题，这些参考会有一些模糊，但是我仍然不能完全确定，我是该用这个算法还是改用那个算法，这个没有太大关系，当我遇到机器学习问题的时候，有时它确实不清楚这是否是最好的算法，但是就如在之前的视频中看到的算法确实很重要。但是通常更加重要的是：你有多少数据，你有多熟练是否擅长做误差分析和排除学习算法，指出如何设定新的特征变量和找出其他能决定你学习算法的变量等方面，通常这些方面会比你使用逻辑回归还是<strong>SVM</strong>这方面更加重要。但是，已经说过了，<strong>SVM</strong>仍然被广泛认为是一种最强大的学习算法，这是一个体系，包含了什么时候一个有效的方法去学习复杂的非线性函数。因此，实际上与逻辑回归、神经网络、<strong>SVM</strong>一起使用这些方法来提高学习算法，我认为你会很好地建立很有技术的状态。（编者注：当时<strong>GPU</strong>计算比较慢，神经网络还不流行。）</p>
<p>机器学习系统对于一个宽泛的应用领域来说，这是另一个在你军械库里非常强大的工具，你可以把它应用到很多地方，如硅谷、在工业、学术等领域建立许多高性能的机器学习系统。</p>
                
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://hai5g.cn/aiwiki/Coursera_ML_AndrewNg/markdown/week7/";
      this.page.identifier =
        "/Coursera_ML_AndrewNg/markdown/week7/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//AI-Wiki.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../week6/" title="week6" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                week6
              </span>
            </div>
          </a>
        
        
          <a href="../week8/" title="week8" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                week8
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 AI Wiki Team
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.39abc4af.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdn.jsdelivr.net/gh/ethantw/Han@3.3.0/dist/han.min.js"></script>
      
        <script src="../../../_static/js/extra.js?v=10"></script>
      
        <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>