



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="AI Wiki 是一个编程竞赛知识整合站点，提供有趣又实用的编程竞赛知识以及其他有帮助的内容，帮助广大编程竞赛爱好者更快更深入地学习编程竞赛">
      
      
        <link rel="canonical" href="https://hai5g.cn/aiwiki/lihang/CH07/">
      
      
        <meta name="author" content="AI Wiki Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>支持向量机 - AI Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,400i,700|Fira+Mono">
        <style>body,input{font-family:"Fira Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Fira Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
      <link rel="manifest" href="../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/ah@1.5.0/han.min.css">
    
      <link rel="stylesheet" href="../../_static/css/extra.css?v=11">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#ch07" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              AI Wiki
            </span>
            <span class="md-header-nav__topic">
              支持向量机
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../.." title="简介" class="md-tabs__link">
          简介
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../Coursera_ML_AndrewNg/" title="机器学习" class="md-tabs__link">
          机器学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../qa500/" title="深度学习500问" class="md-tabs__link">
          深度学习500问
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../" title="统计学习" class="md-tabs__link md-tabs__link--active">
          统计学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../hands-on-ml-zh/README.old/" title="Sklearn与TensorFlow" class="md-tabs__link">
          Sklearn与TensorFlow
        </a>
      
    </li>
  

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://hai5g.cn/aiwiki" title="AI Wiki" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    AI Wiki
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/myourdream/aiwiki/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    aiwiki
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../.." title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/AI学习路线/" title="AI学习路线1" class="md-nav__link">
      AI学习路线1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/ai-roadmap/ai-union-201904/" title="AI学习路线2" class="md-nav__link">
      AI学习路线2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/ai-roadmap/v0.1/" title="AI 路线图v0.1" class="md-nav__link">
      AI 路线图v0.1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/ai-roadmap/v0.2/" title="AI 路线图v0.2" class="md-nav__link">
      AI 路线图v0.2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/ai-roadmap/v1.0/" title="ApacheCN 人工智能知识树" class="md-nav__link">
      ApacheCN 人工智能知识树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7" type="checkbox" id="nav-1-7">
    
    <label class="md-nav__link" for="nav-1-7">
      工具软件
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-7">
        工具软件
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/judgers/" title="评测工具" class="md-nav__link">
      评测工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/editors/" title="编辑工具" class="md-nav__link">
      编辑工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/wsl/" title="WSL (Windows 10)" class="md-nav__link">
      WSL (Windows 10)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/spj/" title="Special Judge" class="md-nav__link">
      Special Judge
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-7-5" type="checkbox" id="nav-1-7-5">
    
    <label class="md-nav__link" for="nav-1-7-5">
      Testlib
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-1-7-5">
        Testlib
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/" title="Testlib 简介" class="md-nav__link">
      Testlib 简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/general/" title="通用" class="md-nav__link">
      通用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/generator/" title="Generator" class="md-nav__link">
      Generator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/validator/" title="Validator" class="md-nav__link">
      Validator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/interactor/" title="Interactor" class="md-nav__link">
      Interactor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/testlib/checker/" title="Checker" class="md-nav__link">
      Checker
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/docker-deploy/" title="Docker 部署" class="md-nav__link">
      Docker 部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/about/" title="关于本项目" class="md-nav__link">
      关于本项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../intro/faq/" title="F.A.Q." class="md-nav__link">
      F.A.Q.
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      机器学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/SUMMARY/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/math/" title="数学基础" class="md-nav__link">
      数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week1/" title="week1" class="md-nav__link">
      week1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week2/" title="week2" class="md-nav__link">
      week2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week3/" title="week3" class="md-nav__link">
      week3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week4/" title="week4" class="md-nav__link">
      week4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week5/" title="week5" class="md-nav__link">
      week5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week6/" title="week6" class="md-nav__link">
      week6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week7/" title="week7" class="md-nav__link">
      week7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week8/" title="week8" class="md-nav__link">
      week8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week9/" title="week9" class="md-nav__link">
      week9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Coursera_ML_AndrewNg/markdown/week10/" title="week10" class="md-nav__link">
      week10
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度学习500问
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        深度学习500问
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/content/" title="目录" class="md-nav__link">
      目录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch01_math/ch01_math/" title="第一章_数学基础" class="md-nav__link">
      第一章_数学基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch02_机器学习基础/第二章_机器学习基础/" title="第二章_机器学习基础" class="md-nav__link">
      第二章_机器学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch03_深度学习基础/第三章_深度学习基础/" title="第三章_深度学习基础" class="md-nav__link">
      第三章_深度学习基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch04_经典网络/第四章_经典网络/" title="第四章_经典网络" class="md-nav__link">
      第四章_经典网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch05_卷积神经网络(CNN)/第五章 卷积神经网络（CNN）/" title="第五章 卷积神经网络（CNN）" class="md-nav__link">
      第五章 卷积神经网络（CNN）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch06_循环神经网络(RNN)/第六章_循环神经网络(RNN)/" title="第六章_循环神经网络(RNN)" class="md-nav__link">
      第六章_循环神经网络(RNN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch07_生成对抗网络(GAN)/ch7/" title="第七章_生成对抗网络(GAN)" class="md-nav__link">
      第七章_生成对抗网络(GAN)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch08_目标检测/第八章_目标检测/" title="第八章_目标检测" class="md-nav__link">
      第八章_目标检测
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch09_图像分割/第九章_图像分割/" title="第九章_图像分割" class="md-nav__link">
      第九章_图像分割
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch10_强化学习/第十章_强化学习/" title="第十章_强化学习" class="md-nav__link">
      第十章_强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch11_迁移学习/第十一章_迁移学习/" title="第十一章_迁移学习" class="md-nav__link">
      第十一章_迁移学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch12_网络搭建及训练/第十二章_网络搭建及训练/" title="第十二章_网络搭建及训练" class="md-nav__link">
      第十二章_网络搭建及训练
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch13_优化算法/第十三章_优化算法/" title="第十三章_优化算法" class="md-nav__link">
      第十三章_优化算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch14_超参数调整/第十四章_超参数调整/" title="第十四章_超参数调整" class="md-nav__link">
      第十四章_超参数调整
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch15_GPU和框架选型/第十五章_异构运算、GPU及框架选型/" title="第十五章_异构运算、GPU及框架选型" class="md-nav__link">
      第十五章_异构运算、GPU及框架选型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch16_自然语言处理(NLP)/第十六章_NLP/" title="第十六章_NLP" class="md-nav__link">
      第十六章_NLP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch17_模型压缩、加速及移动端部署/第十七章_模型压缩、加速及移动端部署/" title="第十七章_模型压缩、加速及移动端部署" class="md-nav__link">
      第十七章_模型压缩、加速及移动端部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch18_后端架构选型、离线及实时计算/第十八章_后端架构选型、离线及实时计算/" title="第十八章_后端架构选型、离线及实时计算" class="md-nav__link">
      第十八章_后端架构选型、离线及实时计算
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../qa500/ch18_后端架构选型及应用场景/第十八章_后端架构选型及应用场景/" title="第十八章_后端架构选型及应用场景" class="md-nav__link">
      第十八章_后端架构选型及应用场景
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      统计学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        统计学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH01/" title="统计学习及监督学习概论" class="md-nav__link">
      统计学习及监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH02/" title="感知机" class="md-nav__link">
      感知机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH03/" title="K近邻法" class="md-nav__link">
      K近邻法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH04/" title="朴素贝叶斯法" class="md-nav__link">
      朴素贝叶斯法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH05/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH06/" title="逻辑斯蒂回归与最大熵模型" class="md-nav__link">
      逻辑斯蒂回归与最大熵模型
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        支持向量机
      </label>
    
    <a href="./" title="支持向量机" class="md-nav__link md-nav__link--active">
      支持向量机
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="前言" class="md-nav__link">
    前言
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="章节目录" class="md-nav__link">
    章节目录
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="导读" class="md-nav__link">
    导读
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" title="[1] 线性可分支持向量机" class="md-nav__link">
    [1] 线性可分支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="算法" class="md-nav__link">
    算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" title="函数间隔" class="md-nav__link">
    函数间隔
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" title="几何间隔" class="md-nav__link">
    几何间隔
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" title="间隔最大化" class="md-nav__link">
    间隔最大化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="支持向量和间隔边界" class="md-nav__link">
    支持向量和间隔边界
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="对偶算法" class="md-nav__link">
    对偶算法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" title="[2] 线性支持向量机" class="md-nav__link">
    [2] 线性支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="对偶问题描述" class="md-nav__link">
    对偶问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="算法" class="md-nav__link">
    算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_14" title="软间隔最大化" class="md-nav__link">
    软间隔最大化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="合页损失" class="md-nav__link">
    合页损失
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" title="[3]非线性支持向量机" class="md-nav__link">
    [3]非线性支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" title="核函数" class="md-nav__link">
    核函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_18" title="学习算法：序列最小最优化" class="md-nav__link">
    学习算法：序列最小最优化
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_19" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kkt" title="KKT 条件" class="md-nav__link">
    KKT 条件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smo" title="SMO算法" class="md-nav__link">
    SMO算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#part-i" title="Part I" class="md-nav__link">
    Part I
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-ii" title="Part II" class="md-nav__link">
    Part II
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" title="算法7.5" class="md-nav__link">
    算法7.5
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_20" title="扩展" class="md-nav__link">
    扩展
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_21" title="对比支持向量机和提升方法" class="md-nav__link">
    对比支持向量机和提升方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smo_1" title="对比二次规划求解工具和SMO" class="md-nav__link">
    对比二次规划求解工具和SMO
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_22" title="习题" class="md-nav__link">
    习题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#73" title="7.3" class="md-nav__link">
    7.3
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" title="参考" class="md-nav__link">
    参考
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH08/" title="提升方法" class="md-nav__link">
      提升方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH09/" title="EM算法及其推广" class="md-nav__link">
      EM算法及其推广
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH10/" title="隐马尔可夫模型" class="md-nav__link">
      隐马尔可夫模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH11/" title="条件随机场" class="md-nav__link">
      条件随机场
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH12/" title="监督学习方法总结" class="md-nav__link">
      监督学习方法总结
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH13/" title="无监督学习概论" class="md-nav__link">
      无监督学习概论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH14/" title="聚类方法" class="md-nav__link">
      聚类方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CH22/" title="无监督学习方法总结" class="md-nav__link">
      无监督学习方法总结
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Sklearn与TensorFlow
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Sklearn与TensorFlow
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/README.old/" title="简介" class="md-nav__link">
      简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/0.前言/" title="前言" class="md-nav__link">
      前言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/1.机器学习概览/" title="机器学习概览" class="md-nav__link">
      机器学习概览
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/2.一个完整的机器学习项目/" title="一个完整的机器学习项目" class="md-nav__link">
      一个完整的机器学习项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/3.分类/" title="分类" class="md-nav__link">
      分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/4.训练模型/" title="训练模型" class="md-nav__link">
      训练模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/5.支持向量机/" title="支持向量机" class="md-nav__link">
      支持向量机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/6.决策树/" title="决策树" class="md-nav__link">
      决策树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/7.集成学习和随机森林/" title="集成学习和随机森林" class="md-nav__link">
      集成学习和随机森林
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/9.启动并运行_TensorFlow/" title="启动并运行_TensorFlow" class="md-nav__link">
      启动并运行_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/10.人工神经网络介绍/" title="人工神经网络介绍" class="md-nav__link">
      人工神经网络介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/11.训练深层神经网络/" title="训练深层神经网络" class="md-nav__link">
      训练深层神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/12.设备和服务器上的分布式_TensorFlow/" title="设备和服务器上的分布式_TensorFlow" class="md-nav__link">
      设备和服务器上的分布式_TensorFlow
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/13.卷积神经网络/" title="卷积神经网络" class="md-nav__link">
      卷积神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/14.循环神经网络/" title="循环神经网络" class="md-nav__link">
      循环神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/15.自编码器/" title="自编码器" class="md-nav__link">
      自编码器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/16.强化学习/" title="强化学习" class="md-nav__link">
      强化学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/B.机器学习项目清单/" title="机器学习项目清单" class="md-nav__link">
      机器学习项目清单
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/C.SVM_对偶问题/" title="SVM_对偶问题" class="md-nav__link">
      SVM_对偶问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hands-on-ml-zh/docs/D.自动微分/" title="自动微分" class="md-nav__link">
      自动微分
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../about/" title="关于" class="md-nav__link">
      关于
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="前言" class="md-nav__link">
    前言
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="章节目录" class="md-nav__link">
    章节目录
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="导读" class="md-nav__link">
    导读
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" title="[1] 线性可分支持向量机" class="md-nav__link">
    [1] 线性可分支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="算法" class="md-nav__link">
    算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" title="函数间隔" class="md-nav__link">
    函数间隔
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" title="几何间隔" class="md-nav__link">
    几何间隔
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" title="间隔最大化" class="md-nav__link">
    间隔最大化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="支持向量和间隔边界" class="md-nav__link">
    支持向量和间隔边界
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="对偶算法" class="md-nav__link">
    对偶算法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" title="[2] 线性支持向量机" class="md-nav__link">
    [2] 线性支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="对偶问题描述" class="md-nav__link">
    对偶问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="算法" class="md-nav__link">
    算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_14" title="软间隔最大化" class="md-nav__link">
    软间隔最大化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="合页损失" class="md-nav__link">
    合页损失
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" title="[3]非线性支持向量机" class="md-nav__link">
    [3]非线性支持向量机
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" title="核函数" class="md-nav__link">
    核函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_18" title="学习算法：序列最小最优化" class="md-nav__link">
    学习算法：序列最小最优化
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_19" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kkt" title="KKT 条件" class="md-nav__link">
    KKT 条件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smo" title="SMO算法" class="md-nav__link">
    SMO算法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#part-i" title="Part I" class="md-nav__link">
    Part I
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-ii" title="Part II" class="md-nav__link">
    Part II
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75" title="算法7.5" class="md-nav__link">
    算法7.5
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_20" title="扩展" class="md-nav__link">
    扩展
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_21" title="对比支持向量机和提升方法" class="md-nav__link">
    对比支持向量机和提升方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smo_1" title="对比二次规划求解工具和SMO" class="md-nav__link">
    对比二次规划求解工具和SMO
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_22" title="习题" class="md-nav__link">
    习题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#73" title="7.3" class="md-nav__link">
    7.3
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" title="参考" class="md-nav__link">
    参考
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/myourdream/aiwiki/blob/master/docs/lihang/CH07/README.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="ch07">CH07 支持向量机<a class="headerlink" href="#ch07" title="Permanent link">&para;</a></h1>
<div class="toc">
<ul>
<li><a href="#ch07">CH07 支持向量机</a><ul>
<li><a href="#_1">前言</a><ul>
<li><a href="#_2">章节目录</a></li>
<li><a href="#_3">导读</a></li>
</ul>
</li>
<li><a href="#1">[1] 线性可分支持向量机</a><ul>
<li><a href="#_4">问题描述</a></li>
<li><a href="#_5">算法</a><ul>
<li><a href="#_6">函数间隔</a></li>
<li><a href="#_7">几何间隔</a></li>
<li><a href="#_8">间隔最大化</a></li>
<li><a href="#_9">支持向量和间隔边界</a></li>
</ul>
</li>
<li><a href="#_10">对偶算法</a></li>
</ul>
</li>
<li><a href="#2">[2] 线性支持向量机</a><ul>
<li><a href="#_11">问题描述</a></li>
<li><a href="#_12">对偶问题描述</a></li>
<li><a href="#_13">算法</a><ul>
<li><a href="#_14">软间隔最大化</a></li>
<li><a href="#_15">合页损失</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3">[3]非线性支持向量机</a><ul>
<li><a href="#_16">核函数</a></li>
<li><a href="#_17">问题描述</a></li>
</ul>
</li>
<li><a href="#_18">学习算法：序列最小最优化</a><ul>
<li><a href="#_19">问题描述</a></li>
<li><a href="#kkt">KKT 条件</a></li>
<li><a href="#smo">SMO算法</a><ul>
<li><a href="#part-i">Part I</a></li>
<li><a href="#part-ii">Part II</a></li>
</ul>
</li>
<li><a href="#75">算法7.5</a></li>
</ul>
</li>
<li><a href="#_20">扩展</a><ul>
<li><a href="#_21">对比支持向量机和提升方法</a></li>
<li><a href="#smo_1">对比二次规划求解工具和SMO</a></li>
</ul>
</li>
<li><a href="#_22">习题</a><ul>
<li><a href="#73">7.3</a></li>
</ul>
</li>
<li><a href="#_23">参考</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="_1">前言<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<h3 id="_2">章节目录<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<ol>
<li>[理论]线性可分支持向量机与硬间隔最大化<ol>
<li>线性可分支持向量机</li>
<li>函数间隔和几何间隔</li>
<li>间隔最大化</li>
<li>学习的对偶算法</li>
</ol>
</li>
<li>[理论]线性支持向量机与软间隔最大化<ol>
<li>线性支持向量机</li>
<li>学习的对偶算法</li>
<li>支持向量</li>
<li>合页损失函数</li>
</ol>
</li>
<li>[理论]非线性支持向量机与核函数<ol>
<li>核技巧</li>
<li>正定核</li>
<li>常用核函数 </li>
<li>非线性支持向量分类机</li>
</ol>
</li>
<li>[实现]序列最小最优化算法<ol>
<li>两个变量二次规划的求解方法</li>
<li>变量的选择方法</li>
<li>SMO算法</li>
</ol>
</li>
</ol>
<h3 id="_3">导读<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>本章概要部分比较精简, 多刷几遍。</p>
<p>支持向量机是一种二类分类模型。</p>
<ul>
<li><strong>基本模型</strong>是定义在特征空间上的间隔最大的<strong>线性分类器</strong></li>
<li>支持向量机还包括<strong>核技巧</strong>， 这使它称为实质上的<strong>非线性分类器</strong>。</li>
<li>支持向量机学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。</li>
<li>支持向量机：线性可分支持向量机，线性支持向量机假设输入空间和特征空间的<strong>元素一一对应</strong>，并将输入空间中的输入映射为特征空间的特征向量；非线性支持向量机利用一个从输入空间到特征空间的<strong>非线性映射</strong>将输入映射为特征向量。</li>
<li>判别模型</li>
<li>符号函数, Sign, 0 对应了超平面(hyper plane), &gt;0与&lt;0对应了半空间(half space)</li>
<li>仿射变换是保凸变换</li>
<li><code>分离超平面将特征空间划分为两部分，一部分是正类，一部分是负类。法向量指向的一侧是正类， 另一侧为负类</code></li>
<li>关于SVM的历史可以参考附录2[^2]，Vapnik的1995年的那个文章名字叫Support-vector networks，主要是提出了soft margin，在这篇文章的附录中给出了线性可分支持向量机与线性支持向量机的推导。同年Vapnik将支持向量机推广到支持向量回归，发表了文章统计学习理论的本质， 这个有中译版本，见书中本章参考文献[4]</li>
<li>Vapnik全名弗拉基米尔·万普尼克， 出生于苏联， VC理论的主要创建人之一，统计学习理论之父。1990年底移居美国，1991-2001年间，他在AT&amp;T工作。2006年成为美国国家工程院院士。2014年加入Facebook人工智能实验室。</li>
<li>1995年SVN的文章结尾有这样的描述：<code>The support-vector network combines 3 ideas: the solution technique from optimal hy- perplanes (that allows for an expansion of the solution vector on support vectors), the idea of convolution of the dot-product (that extends the solution surfaces from linear to non-linear), and the notion of soft margins (to allow for errors on the training set).</code></li>
<li>KKT条件是该最优化问题的充分必要条件。</li>
<li>样本比较多的时候，Boosting和RF往往能得到最好的效果，但是数据集较少的时候，SVM的效果可能会比较好。</li>
</ul>
<hr />
<p>这一章介绍了几个算法</p>
<ol>
<li>算法7.1 最大间隔法，针对线性可分支持向量机，直接求<span><span class="MathJax_Preview">w^*,b^*</span><script type="math/tex">w^*,b^*</script></span></li>
<li>算法7.2 学习的对偶算法，求<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>进一步求<span><span class="MathJax_Preview">w^*,b^*</span><script type="math/tex">w^*,b^*</script></span></li>
<li>算法7.3 线性支持向量机的学习算法， 增加超参<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>，求<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>进一步求<span><span class="MathJax_Preview">w^*,b^*</span><script type="math/tex">w^*,b^*</script></span></li>
<li>算法7.4 非线性支持向量机的学习算法，进一步引入核函数<span><span class="MathJax_Preview">K(x,z)</span><script type="math/tex">K(x,z)</script></span>，求<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>进一步求<span><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span></li>
<li>算法7.5 序列最小最优化</li>
</ol>
<p>注意前四个算法里面，都没有写该怎么去求解<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>，最后一节<strong>序列最小最优化</strong>讨论了具体实现。也就是算法7.5给出了求解<span><span class="MathJax_Preview">\hat\alpha</span><script type="math/tex">\hat\alpha</script></span>的方法。</p>
<p>另外，注意对比算法7.3和算法7.4，关注输出，关注<span><span class="MathJax_Preview">b^*​</span><script type="math/tex">b^*​</script></span>.</p>
<h2 id="1">[1] 线性可分支持向量机<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="_4">问题描述<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\begin{align}
&amp;\min_{w,b}\frac{\hat \gamma}{\left\|w\right\|}\\
&amp;s.t.\ \ \ y_i(w\cdot x_i+b)-1\geqslant0,i=1,2,\dots,N\\
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
&\min_{w,b}\frac{\hat \gamma}{\left\|w\right\|}\\
&s.t.\ \ \ y_i(w\cdot x_i+b)-1\geqslant0,i=1,2,\dots,N\\
\end{align}
</script>
</div>
<p>这是个凸二次规划问题.</p>
<p>如果求出了上述方程的解<span><span class="MathJax_Preview">w^*, b^*</span><script type="math/tex">w^*, b^*</script></span>，就可得到</p>
<p>分离超平面
$$
w^<em>\cdot x+b^</em>=0
$$</p>
<p>相应的分类决策函数
$$
f(x)=sign(w^<em>\cdot x+b^</em>)
$$</p>
<h3 id="_5">算法<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<h4 id="_6">函数间隔<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p>对于给定数据集<span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span>和超平面<span><span class="MathJax_Preview">(w,b)</span><script type="math/tex">(w,b)</script></span>，定义超平面<span><span class="MathJax_Preview">(w,b)</span><script type="math/tex">(w,b)</script></span>关于样本点<span><span class="MathJax_Preview">(x_i,y_i)</span><script type="math/tex">(x_i,y_i)</script></span>的函数间隔为
$$
\hat \gamma_i=y_i(w\cdot x_i+b)
$$
定义超平面<span><span class="MathJax_Preview">(w,b)</span><script type="math/tex">(w,b)</script></span>关于训练数据集<span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span>的函数间隔为超平面<span><span class="MathJax_Preview">(w,b)</span><script type="math/tex">(w,b)</script></span>关于<span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span>中所有样本点<span><span class="MathJax_Preview">(x_i,y_i)</span><script type="math/tex">(x_i,y_i)</script></span>的函数间隔之最小值，即
$$
\hat \gamma=\min_{i=1,\cdots,N}\hat\gamma_i
$$
函数间隔可以表示分类预测的<strong>正确性</strong>及<strong>确信度</strong>。</p>
<h4 id="_7">几何间隔<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<h4 id="_8">间隔最大化<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<h4 id="_9">支持向量和间隔边界<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<p>由于支持向量在确定分离超平面中起着决定作用，所以将这种分类模型称为支持向量机。</p>
<p>支持向量对应
$$
y_i(w\cdot x_i+b)-1 = 0
$$
上式对应两个超平面</p>
<p>分离超平面对应
$$
w\cdot x+b=0
$$
注意，在算法7.1中，并没有说明这个问题如何求得最优解，在7.1.4节中有描述该如何求解。</p>
<p>针对例7.1，可以先用<span><span class="MathJax_Preview">scipy</span><script type="math/tex">scipy</script></span>中的包求解，这个例子我们要清楚：</p>
<ol>
<li>该问题怎么定义的</li>
<li>有哪些约束</li>
<li>支持向量在哪里</li>
<li>三个重要的超平面是怎么得到的</li>
</ol>
<p>可以用如下程序实现</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># data 2.1</span>
<span class="c1"># x_1 = (3, 3), x_2 = (4, 3), x_3 = (1, 1)</span>
<span class="c1"># ref: [example 16.3](http://www.bioinfo.org.cn/~wangchao/maa/Numerical_Optimization.pdf)</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="n">cons</span> <span class="o">=</span> <span class="p">({</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">})</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">cons</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>
</td></tr></table>

<h3 id="_10">对偶算法<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<ol>
<li>对偶问题往往更容易求解</li>
<li>自然引入核函数，进而推广到非线性分类问题</li>
</ol>
<p>针对每个不等式约束，定义拉格朗日乘子<span><span class="MathJax_Preview">\alpha_i\ge0​</span><script type="math/tex">\alpha_i\ge0​</script></span>，定义拉格朗日函数
$$
\begin{align}
L(w,b,\alpha)&amp;=\frac{1}{2}w\cdot w-\left[\sum_{i=1}^N\alpha_i[y_i(w\cdot x_i+b)-1]\right]\
&amp;=\frac{1}{2}\left|w\right|<sup>2-\left[\sum_{i=1}</sup>N\alpha_i[y_i(w\cdot x_i+b)-1]\right]\
&amp;=\frac{1}{2}\left|w\right|<sup>2-\sum_{i=1}</sup>N\alpha_iy_i(w\cdot x_i+b)+\sum_{i=1}^N\alpha_i
\end{align}\
\alpha_i \geqslant0, i=1,2,\dots,N
$$
其中<span><span class="MathJax_Preview">\alpha=(\alpha_1,\alpha_2,\dots,\alpha_N)^T​</span><script type="math/tex">\alpha=(\alpha_1,\alpha_2,\dots,\alpha_N)^T​</script></span>为拉格朗日乘子向量</p>
<p><strong>原始问题是极小极大问题</strong></p>
<p>根据<strong>拉格朗日对偶性</strong>，原始问题的<strong>对偶问题是极大极小问题</strong>:
$$
\max\limits_\alpha\min\limits_{w,b}L(w,b,\alpha)
$$</p>
<p>关于对偶问题，引用Wikipedia中的描述</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Duality_(optimization)">Duality (optimization)</a></p>
<p>In <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">mathematical optimization</a> theory, <strong>duality</strong> or the <strong>duality principle</strong> is the principle that <a href="https://en.wikipedia.org/wiki/Optimization_problem">optimization problems</a> may be viewed from either of two perspectives, the <strong>primal problem</strong> or the <strong>dual problem</strong>. The solution to the dual problem provides a lower bound to the solution of the primal (minimization) problem.[<a href="https://en.wikipedia.org/wiki/Duality_(optimization)#cite_note-Boyd-1">1]</a> However in general the optimal values of the primal and dual problems need not be equal. Their difference is called the <a href="https://en.wikipedia.org/wiki/Duality_gap">duality gap</a>. For <a href="https://en.wikipedia.org/wiki/Convex_optimization">convex optimization</a> problems, the duality gap is zero under a <a href="https://en.wikipedia.org/wiki/Constraint_qualification">constraint qualification</a> condition.</p>
</blockquote>
<p>转换后的对偶问题
$$
\min\limits_\alpha \frac{1}{2}\sum_{i=1}<sup>N\sum_{j=1}</sup>N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j)-\sum_{i=1}^N\alpha_i\
s.t.    \sum_{i=1}^N\alpha_iy_i=0\
\alpha_i\geqslant0, i=1,2,\dots,N
$$</p>
<p>对于任意线性可分的两组点，他们在分类超平面上的投影都是线性不可分的。</p>
<p><span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>不为零的点对应的实例为支持向量，通过支持向量可以求得<span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>值</p>
<p>核心公式两个
$$
\begin{align}
w<sup>*&amp;=\sum_{i=1}</sup>{N}\alpha_i<sup>*y_ix_i\
b</sup><em>&amp;=\color{red}y_j\color{black}-\sum_{i=1}<sup>{N}\alpha_i</sup></em>y_i(x_i\cdot \color{red}x_j\color{black})
\end{align}
$$
这里面比较重要的是<span><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>的公式的理解，通过<span><span class="MathJax_Preview">\arg\max \alpha^*</span><script type="math/tex">\arg\max \alpha^*</script></span>实现，因为支持向量共线，所以通过任意支持向量求解都可以。</p>
<p>介绍学习的对偶算法之后，引入了例7.2解决之前同样的问题，这部分代码整理下</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># data 2.1</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">13</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># cons = ({&#39;type&#39;: &#39;ineq&#39;, &#39;fun&#39;: lambda a: a[0]},</span>
<span class="c1">#         {&#39;type&#39;: &#39;ineq&#39;, &#39;fun&#39;: lambda a: a[1]})</span>
<span class="n">bnds</span> <span class="o">=</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bnds</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">label</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1">#  0和2都OK，因为都为0.5 &gt; 0</span>
<span class="c1"># b = label[0] - np.sum(alpha*label*np.dot(data,data[0,:]),axis=0)</span>
<span class="c1"># b = label[2] - np.sum(alpha*label*np.dot(data,data[2,:]),axis=0)</span>
</pre></div>
</td></tr></table>

<p>至此，两个例子求解的都是线性可分支持向量机。</p>
<h2 id="2">[2] 线性支持向量机<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="_11">问题描述<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\begin{align}
\min_{w,b,\xi} &amp;\frac{1}{2}\left\|w\right\|^2+C\sum_{i=1}^N\xi_i\\
s.t. \ \ \ &amp;y_i(w\cdot x_i+b)\geqslant1-\xi_i, i=1,2,\dots,N\\
&amp;\xi_i\geqslant0,i=1,2,\dots,N
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
\min_{w,b,\xi} &\frac{1}{2}\left\|w\right\|^2+C\sum_{i=1}^N\xi_i\\
s.t. \ \ \ &y_i(w\cdot x_i+b)\geqslant1-\xi_i, i=1,2,\dots,N\\
&\xi_i\geqslant0,i=1,2,\dots,N
\end{align}
</script>
</div>
<h3 id="_12">对偶问题描述<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h3>
<p>原始问题里面有两部分约束，涉及到两个拉格朗日乘子向量
$$
\begin{align}
\min_\alpha &amp;\frac{1}{2}\sum_{i=1}<sup>N\sum_{j=1}</sup>N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j)-\sum_{i=1}<sup>N\alpha_i\
s.t.   &amp;\sum_{i=1}</sup>N\alpha_iy_i=0\
&amp;0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{align}
$$
通过求解对偶问题， 得到<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>，然后求解<span><span class="MathJax_Preview">w,b</span><script type="math/tex">w,b</script></span>的过程和之前一样</p>
<p>注意， 书后总结部分，有这样一句描述：<strong>线性支持向量机的解<span><span class="MathJax_Preview">w^*</span><script type="math/tex">w^*</script></span>唯一但<span><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>不一定唯一</strong></p>
<p>线性支持向量机是线性可分支持向量机的超集。</p>
<h3 id="_13">算法<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h3>
<h4 id="_14">软间隔最大化<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h4>
<blockquote>
<p>对于线性支持向量机学习来说
模型为分离超平面<span><span class="MathJax_Preview">w^*\cdot x+b^*=0</span><script type="math/tex">w^*\cdot x+b^*=0</script></span></p>
<p>决策函数为<span><span class="MathJax_Preview">f(x)=sign(w^*\cdot x+b^*)</span><script type="math/tex">f(x)=sign(w^*\cdot x+b^*)</script></span></p>
<p>学习策略为软间隔最大化</p>
<p>学习算法为凸二次规划</p>
</blockquote>
<h4 id="_15">合页损失<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h4>
<p>另一种解释，最小化目标函数</p>
<div>
<div class="MathJax_Preview">\min\limits_{w,b} \sum\limits_{i=1}^N\left[1-y_i(w\cdot x+b)\right]_++\lambda\left\|w\right\|^2</div>
<script type="math/tex; mode=display">\min\limits_{w,b} \sum\limits_{i=1}^N\left[1-y_i(w\cdot x+b)\right]_++\lambda\left\|w\right\|^2</script>
</div>
<p>其中</p>
<ul>
<li>第一项是经验损失或经验风险，函数<span><span class="MathJax_Preview">L(y(w\cdot x+b))=[1-y(w\cdot x+b)]_+</span><script type="math/tex">L(y(w\cdot x+b))=[1-y(w\cdot x+b)]_+</script></span>称为合页损失，可以表示成<span><span class="MathJax_Preview">L = \max(1-y(w\cdot x+b), 0)</span><script type="math/tex">L = \max(1-y(w\cdot x+b), 0)</script></span></li>
<li>第二项是<strong>系数为<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>的<span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的<span><span class="MathJax_Preview">L_2</span><script type="math/tex">L_2</script></span>范数的平方</strong>，是正则化项</li>
</ul>
<p>书中这里通过定理7.4说明了用合页损失表达的最优化问题和线性支持向量机原始最优化问题的关系。
$$
\begin{align}
\min_{w,b,\xi} &amp;\frac{1}{2}\left|w\right|<sup>2+C\sum_{i=1}</sup>N\xi_i\
s.t.    &amp;y_i(w\cdot x_i+b)\geqslant1-\xi_i, i=1,2,\dots,N\
&amp;\xi_i\geqslant0,i=1,2,\dots,N
\end{align}
$$
等价于
$$
\min\limits_{w,b} \sum\limits_{i=1}^N\left[1-y_i(w\cdot x+b)\right]_++\lambda\left|w\right|^2
$$
证明：</p>
<p>令合页损失<span><span class="MathJax_Preview">\left[1-y_i(w\cdot x+b)\right]_+=\xi_i</span><script type="math/tex">\left[1-y_i(w\cdot x+b)\right]_+=\xi_i</script></span>，合页损失非负，所以有<span><span class="MathJax_Preview">\xi_i\ge0</span><script type="math/tex">\xi_i\ge0</script></span>，这个对应了原始最优化问题中的<strong>一个约束【1】</strong>。</p>
<p>还是根据合页损失非负，当<span><span class="MathJax_Preview">1-y_i(w\cdot x+b)\leq\color{red}0​</span><script type="math/tex">1-y_i(w\cdot x+b)\leq\color{red}0​</script></span>的时候，有<span><span class="MathJax_Preview">\left[1-y_i(w\cdot x+b)\right]_+=\color{red}\xi_i=0​</span><script type="math/tex">\left[1-y_i(w\cdot x+b)\right]_+=\color{red}\xi_i=0​</script></span>，所以有</p>
<p><span><span class="MathJax_Preview">1-y_i(w\cdot x+b)\leq\color{red}0=\xi_i</span><script type="math/tex">1-y_i(w\cdot x+b)\leq\color{red}0=\xi_i</script></span>，这对应了原始最优化问题中的<strong>另一个约束【2】</strong>。</p>
<p>所以，在满足这<strong>两个约束【1】【2】</strong>的情况下，有
$$
\begin{aligned}
\min\limits_{w,b} &amp;\sum\limits_{i=1}^N\left[1-y_i(w\cdot x+b)\right]<em>++\lambda\left|w\right|^2\
\min\limits</em>{w,b} &amp;\sum\limits_{i=1}<sup>N\xi_i+\lambda\left|w\right|</sup>2\
\min\limits_{w,b} &amp;\frac{1}{C}\left(\frac{1}{2}\left|w\right|<sup>2+C\sum\limits_{i=1}</sup>N\xi_i\right), with   \lambda=\frac{1}{2C}\
\end{aligned}
$$
看下下面这个图，其中合页损失和感知机损失函数之间的关系，合页损失要求函数间隔大于1的时候才没有损失（loss=0），而感知机只要函数间隔大于0就认为没有损失，所以说合页损失对学习有更高的要求。</p>
<p>再解释下，对于线性支持向量机大于一的意思是符号为正，且值要大于1；对于感知机大于零的意思是符号为正，就可以了。</p>
<p><img alt="test" src="assets/fig76.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">601</span><span class="p">)</span>
<span class="c1"># perceptron loss</span>
<span class="n">y1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">))</span>
<span class="c1"># hinge loss</span>
<span class="n">y2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">))</span>
<span class="c1"># 0-1 loss</span>
<span class="n">y3</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="c1"># lr loss</span>
<span class="n">y4</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)),</span> <span class="n">x</span><span class="p">))</span>
<span class="c1"># adaboost</span>
<span class="n">y5</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;perceptron loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;hinge loss&#39;</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y3</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;0-1 loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y4</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y5</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;adaboost&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;functional margin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;test.png&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>以上：</p>
<ul>
<li>0-1损失函数不是连续可导</li>
<li>合页损失认为是0-1损失函数的上界，在<a href="../CH08/">AdaBoost</a>中也有说明，指数损失也是0-1损失函数的上界，在<a href="../CH02/">感知机</a>中有提到<code>损失函数的自然选择是误分类点的个数</code>，这句在最开始见到的时候，可能不一定有上面图片的直觉。注意在本书<a href="../CH12/">CH12</a>中也有这个图，可以对比理解下。</li>
<li>感知机误分类驱动， 选择函数间隔作为损失考虑分类的正确性，合页损失不仅要考虑分类正确， 还要考虑确信度足够高时损失才是0.</li>
</ul>
<h2 id="3">[3]非线性支持向量机<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<p>核技巧的想法是在学习和预测中只定义核函数<span><span class="MathJax_Preview">K(x,z)</span><script type="math/tex">K(x,z)</script></span>，而不是显式的定义映射函数<span><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span></p>
<p>通常，直接计算<span><span class="MathJax_Preview">K(x,z)</span><script type="math/tex">K(x,z)</script></span>比较容易， 而通过<span><span class="MathJax_Preview">\phi(x)</span><script type="math/tex">\phi(x)</script></span>和<span><span class="MathJax_Preview">\phi(z)</span><script type="math/tex">\phi(z)</script></span>计算<span><span class="MathJax_Preview">K(x,z)</span><script type="math/tex">K(x,z)</script></span>并不容易。
$$
\begin{align}
W(\alpha)=\frac{1}{2}\sum_{i=1}<sup>N\sum_{j=1}</sup>N\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}<sup>N\alpha_i\
f(x)=sign\left(\sum_{i=1}</sup>{N_s}\alpha_i^<em>y_i\phi(x_i)\cdot \phi(x)+b<sup>*\right)=sign\left(\sum_{i=1}</sup>{N_s}\alpha_i<sup>*y_iK(x_i,x)+b</sup></em>\right) 
\end{align}
$$
学习是隐式地在特征空间进行的，不需要显式的定义特征空间和映射函数。这样的技巧称为核技巧，核技巧不仅引用于支持向量机，而且应用于其他统计学习问题。</p>
<p>TODO：字符串核函数</p>
<h3 id="_16">核函数<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h3>
<p>例7.3 主要是为了说明</p>
<blockquote>
<p>对于给定的核<span><span class="MathJax_Preview">K(x,z)</span><script type="math/tex">K(x,z)</script></span>，特征空间<span><span class="MathJax_Preview">\mathcal H</span><script type="math/tex">\mathcal H</script></span>和映射函数<span><span class="MathJax_Preview">\phi(x)</span><script type="math/tex">\phi(x)</script></span>的取法并不唯一，可以取不同的特征空间，即便是同一特征空间里也可以取不同的映射</p>
</blockquote>
<p>注意这个例子里面<span><span class="MathJax_Preview">\phi(x)</span><script type="math/tex">\phi(x)</script></span>实现了从低维空间到高维空间的映射。
$$
K(x,z)=(x\cdot z)<sup>2\
\cal{X}=\R</sup>2, x=(x<sup>{(1)},x</sup>{(2)})<sup>T\
\cal{H}=\R</sup>3, \phi(x)=((x<sup>{(1)})</sup>2, \sqrt2x<sup>{(1)}x</sup>{(2)}, (x<sup>{(2)})</sup>2)<sup>T\
\cal{H}=\R</sup>4, \phi(x)=((x<sup>{(1)})</sup>2, x<sup>{(1)}x</sup>{(2)}, x<sup>{(1)}x</sup>{(2)}, (x<sup>{(2)})</sup>2)^T\
$$</p>
<p>这里看下：</p>
<ul>
<li>理解下<span><span class="MathJax_Preview">\R^n</span><script type="math/tex">\R^n</script></span></li>
<li>理解下计算<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>要比通过<span><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span>计算<span><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>要容易</li>
<li>核函数的定义相当于给出了<span><span class="MathJax_Preview">\phi(x)\cdot\phi(z)</span><script type="math/tex">\phi(x)\cdot\phi(z)</script></span>的结果，而没有显式的给出<span><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span>的定义，<span><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span>实现了从输入空间到特征空间的变换，所以说，学习是隐式的从特征空间中进行的，不需要显式的定义特征空间和映射函数，这样的技巧称为核技巧，通过线性分类学习方法和核函数解决非线性问题。</li>
</ul>
<p>核具有再生性即满足
$$
K(\cdot,x)\cdot f=f(x)\
K(\cdot,x)\cdot K(\cdot, z)=K(x,z)
$$
称为再生核</p>
<h3 id="_17">问题描述<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h3>
<p><del>和线性支持向量机的问题描述一样</del>，注意，这里是有差异的，将向量内积替换成了核函数，而后续SMO算法求解的问题是该问题。</p>
<p>构建最优化问题：
$$
\begin{align}
\min_\alpha &amp;\frac{1}{2}\sum_{i=1}<sup>N\sum_{j=1}</sup>N\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}<sup>N\alpha_i\
s.t.   &amp;\sum_{i=1}</sup>N\alpha_iy_i=0\
&amp;0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{align}
$$</p>
<p>求解得到<span><span class="MathJax_Preview">\alpha^*=(\alpha_1^*,\alpha_2^*,\cdots,\alpha_N^*)^T</span><script type="math/tex">\alpha^*=(\alpha_1^*,\alpha_2^*,\cdots,\alpha_N^*)^T</script></span></p>
<p>选择<span><span class="MathJax_Preview">\alpha^*</span><script type="math/tex">\alpha^*</script></span>的一个正分量计算
$$
b<sup>*=y_j-\sum_{i=1}</sup>N\alpha_i<sup>*y_iK(x_i,x_j)
$$
构造决策函数
$$
f(x)=sign\left(\sum_{i=1}</sup>N\alpha_i<sup>*y_iK(x,x_i)+b</sup>*\right)
$$</p>
<h2 id="_18">学习算法：序列最小最优化<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h2>
<p>支持向量机的学习问题可以形式化为求解凸二次规划问题，这部分主要参考文献是文献5[^1]</p>
<h3 id="_19">问题描述<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\min_\alpha\ &amp;\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^N\alpha_i\\
s.t.\ \ \ &amp;\sum_{i=1}^N\alpha_iy_i=0\\
&amp;0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\min_\alpha\ &\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^N\alpha_i\\
s.t.\ \ \ &\sum_{i=1}^N\alpha_iy_i=0\\
&0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{aligned}
</script>
</div>
<p>这个问题中，变量是<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>，一个变量<span><span class="MathJax_Preview">\alpha_i</span><script type="math/tex">\alpha_i</script></span>对应一个样本点<span><span class="MathJax_Preview">(x_i,y_i)</span><script type="math/tex">(x_i,y_i)</script></span>，变量总数等于<span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span></p>
<h3 id="kkt">KKT 条件<a class="headerlink" href="#kkt" title="Permanent link">&para;</a></h3>
<p>KKT条件是该最优化问题的充分必要条件。这个参考<a href="../APP/">附录C</a></p>
<h3 id="smo">SMO算法<a class="headerlink" href="#smo" title="Permanent link">&para;</a></h3>
<p>整个SMO算法包括两<sub><sub>步骤</sub></sub><strong>部分</strong>：</p>
<ol>
<li>求解两个变量二次规划的解析方法</li>
<li>选择变量的启发式方法</li>
</ol>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\min_\alpha\ &amp;\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j)-\sum_{i=1}^N\alpha_i\\
s.t.\ \ \ &amp;\sum_{i=1}^N\alpha_iy_i=0\\
&amp;0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\min_\alpha\ &\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j)-\sum_{i=1}^N\alpha_i\\
s.t.\ \ \ &\sum_{i=1}^N\alpha_iy_i=0\\
&0\leqslant \alpha_i \leqslant C,i=1,2,\dots,N
\end{aligned}
</script>
</div>
<p>注意，这里是<strong>两个部分</strong>，而不是先后的两个步骤。</p>
<h4 id="part-i">Part I<a class="headerlink" href="#part-i" title="Permanent link">&para;</a></h4>
<p>两变量二次规划求解</p>
<p>选择两个变量<span><span class="MathJax_Preview">\alpha_1,\alpha_2​</span><script type="math/tex">\alpha_1,\alpha_2​</script></span></p>
<p>由等式约束可以得到</p>
<p><span><span class="MathJax_Preview">\alpha_1=-y_1\sum\limits_{i=2}^N\alpha_iy_i​</span><script type="math/tex">\alpha_1=-y_1\sum\limits_{i=2}^N\alpha_iy_i​</script></span></p>
<p>所以这个问题实质上是单变量优化问题。
$$
\begin{align}
\min_{\alpha_1,\alpha_2} W(\alpha_1,\alpha_2)=&amp;\frac{1}{2}K_{11}\alpha_1<sup>2+\frac{1}{2}K_{22}\alpha_2</sup>2+y_1y_2K_{12}\alpha_1\alpha_2\nonumber\
&amp;-(\alpha_1+\alpha_2)+y_1\alpha_1\sum_{i=3}<sup>Ny_i\alpha_iK_{il}+y_2\alpha_2\sum_{i=3}</sup>Ny_i\alpha_iK_{i2}\
s.t.    &amp;\alpha_1y_1+\alpha_2y_2=-\sum_{i=3}^Ny_i\alpha_i=\varsigma\
&amp;0\leqslant\alpha_i\leqslant C, i=1,2
\end{align}
$$</p>
<p>上面存在两个约束：</p>
<ol>
<li><strong>线性</strong>等式约束</li>
<li>边界约束</li>
</ol>
<p>这里有个<span><span class="MathJax_Preview">\color{red}配图</span><script type="math/tex">\color{red}配图</script></span>，其中这样一段描述<strong>等式约束使得<span><span class="MathJax_Preview">(\alpha_1,\alpha_2)</span><script type="math/tex">(\alpha_1,\alpha_2)</script></span>在平行于盒子<span><span class="MathJax_Preview">[0,C]\times [0,C]</span><script type="math/tex">[0,C]\times [0,C]</script></span>的对角线的直线上</strong></p>
<p>这句怎么理解？</p>
<p><span><span class="MathJax_Preview">y_i\in \mathcal Y=\{+1,-1\}</span><script type="math/tex">y_i\in \mathcal Y=\{+1,-1\}</script></span>所以又等式约束导出的关系式中两个变量的系数相等，所以平行于对角线。</p>
<p>要时刻记得，支持向量机是个二类分类模型。后面有研究者对这个问题做多分类扩展，应该不是简单的OvO或者OvR吧，不然能专门发文章写一下？</p>
<p>书中<strong>剪辑</strong>的概念对应了文献[^1]中的<strong>clipped</strong>，剪辑的操作对应的是clipping，也叫truncation或者shortening。</p>
<h4 id="part-ii">Part II<a class="headerlink" href="#part-ii" title="Permanent link">&para;</a></h4>
<p>变量的选择方法</p>
<ol>
<li>第一个变量<span><span class="MathJax_Preview">\alpha_1</span><script type="math/tex">\alpha_1</script></span>
   外层循环
   违反KKT条件<strong>最严重</strong>的样本点</li>
<li>第二个变量<span><span class="MathJax_Preview">\alpha_2</span><script type="math/tex">\alpha_2</script></span>
   内层循环
   希望能使<span><span class="MathJax_Preview">\alpha_2</span><script type="math/tex">\alpha_2</script></span>有足够大的变化</li>
<li>计算阈值<span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>和差值<span><span class="MathJax_Preview">E_i</span><script type="math/tex">E_i</script></span></li>
</ol>
<h3 id="75">算法7.5<a class="headerlink" href="#75" title="Permanent link">&para;</a></h3>
<blockquote>
<p>输入：训练数据集<span><span class="MathJax_Preview">T={(x_1,y_1),(x_2,y_2),\dots, (x_N,y_N)}</span><script type="math/tex">T={(x_1,y_1),(x_2,y_2),\dots, (x_N,y_N)}</script></span>，其中<span><span class="MathJax_Preview">x_i\in\mathcal X=\bf R^n, y_i\in\mathcal Y=\{-1,+1\}, i=1,2,\dots,N</span><script type="math/tex">x_i\in\mathcal X=\bf R^n, y_i\in\mathcal Y=\{-1,+1\}, i=1,2,\dots,N</script></span>,精度<span><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span></p>
<p>输出：近似解<span><span class="MathJax_Preview">\hat\alpha</span><script type="math/tex">\hat\alpha</script></span></p>
<ol>
<li>
<p>取初值<span><span class="MathJax_Preview">\alpha_0=0</span><script type="math/tex">\alpha_0=0</script></span>，令<span><span class="MathJax_Preview">k=0</span><script type="math/tex">k=0</script></span></p>
</li>
<li>
<p><strong>选取</strong>优化变量<span><span class="MathJax_Preview">\alpha_1^{(k)},\alpha_2^{(k)}</span><script type="math/tex">\alpha_1^{(k)},\alpha_2^{(k)}</script></span>，解析求解两个变量的最优化问题，求得最优解<span><span class="MathJax_Preview">\alpha_1^{(k+1)},\alpha_2^{(k+1)}</span><script type="math/tex">\alpha_1^{(k+1)},\alpha_2^{(k+1)}</script></span>，更新<span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>为<span><span class="MathJax_Preview">\alpha^{k+1}</span><script type="math/tex">\alpha^{k+1}</script></span></p>
</li>
<li>
<p>若在精度<span><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>范围内满足停机条件
   $$
   \sum_{i=1}^{N}\alpha_iy_i=0\
   0\leqslant\alpha_i\leqslant C,i=1,2,\dots,N\
   y_i\cdot g(x_i)=
   \begin{cases}
   \geqslant1,{x_i|\alpha_i=0}\
   =1,{x_i|0&lt;\alpha_i&lt;C}\
   \leqslant1,{x_i|\alpha_i=C}
   \end{cases}\
   g(x_i)=\sum_{j=1}^{N}\alpha_jy_jK(x_j,x_i)+b
   $$
   则转4,否则，<span><span class="MathJax_Preview">k=k+1</span><script type="math/tex">k=k+1</script></span>转2</p>
</li>
<li>
<p>取<span><span class="MathJax_Preview">\hat\alpha=\alpha^{(k+1)}</span><script type="math/tex">\hat\alpha=\alpha^{(k+1)}</script></span></p>
</li>
</ol>
</blockquote>
<p>TODO:</p>
<p>其实这里支持向量机的几个核心的思想是不难理解的，这里涉及到的主要是求解二次规划问题么？</p>
<h2 id="_20">扩展<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h2>
<h3 id="_21">对比支持向量机和提升方法<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h3>
<p>参考下<a href="../CH08/">CH08</a></p>
<h3 id="smo_1">对比二次规划求解工具和SMO<a class="headerlink" href="#smo_1" title="Permanent link">&para;</a></h3>
<h2 id="_22">习题<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h2>
<h3 id="73">7.3<a class="headerlink" href="#73" title="Permanent link">&para;</a></h3>
<p>线性支持向量机还可以定义成以下形式：
$$
\begin{aligned}
\min_{w,b,\xi} &amp;\frac{1}{2}||w||<sup>2+C\sum_{i=1}</sup>{N}\xi_i^2\
s.t. &amp;y_i(w\cdot x_i+b)\ge1-\xi_i, i=1,2,\cdots,N\
&amp;\xi_i\ge 0, i=1,2,\cdots,N
\end{aligned}
$$</p>
<p>求其对偶形式。</p>
<h2 id="_23">参考<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>[^1]: <a href="http://www.cs.utsa.edu/~bylander/cs6243/smo-book.pdf">Fast training of support vector machines using sequential minimal optimization</a></p>
</li>
<li>
<p>[^2]: <a href="http://www.svms.org/history.html">支持向量机历史</a></p>
</li>
</ol>
<p><strong><a href="#导读">⬆ top</a></strong></p>
                
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://hai5g.cn/aiwiki/lihang/CH07/";
      this.page.identifier =
        "/lihang/CH07/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//AI-Wiki.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../CH06/" title="逻辑斯蒂回归与最大熵模型" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                逻辑斯蒂回归与最大熵模型
              </span>
            </div>
          </a>
        
        
          <a href="../CH08/" title="提升方法" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                提升方法
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 AI Wiki Team
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.39abc4af.js"></script>
      
        
        
          
          <script src="../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="https://cdn.jsdelivr.net/gh/ethantw/Han@3.3.0/dist/han.min.js"></script>
      
        <script src="../../_static/js/extra.js?v=10"></script>
      
        <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>