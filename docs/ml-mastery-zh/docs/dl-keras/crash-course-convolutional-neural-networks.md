# 机器学习卷积神经网络的速成课程

> 原文： [https://machinelearningmastery.com/crash-course-convolutional-neural-networks/](https://machinelearningmastery.com/crash-course-convolutional-neural-networks/)

卷积神经网络是一种强大的人工神经网络技术。

这些网络保留了问题的空间结构，并且是为诸如手写数字识别之类的对象识别任务而开发的。它们很受欢迎，因为人们在困难的计算机视觉和自然语言处理任务上取得了最先进的成果。

在这篇文章中，您将发现用于深度学习的卷积神经网络，也称为 ConvNets 或 CNN。完成本速成课程后，您将了解：

*   CNN 中使用的构建块，例如卷积层和池层。
*   如何将构建块与一个简短的工作示例结合在一起。
*   在您自己的对象识别任务上配置 CNN 的最佳实践。
*   适用于复杂机器学习问题的最新网络参考。

让我们开始吧。

![Crash Course in Convolutional Neural Networks for Machine Learning](img/28a944c830ffc6a1fd896c1df6c953e5.png)

用于机器学习的卷积神经网络的崩溃课程
照片由 [Bryan Ledgard](https://www.flickr.com/photos/ledgard/7772964384/) ，保留一些权利。

## 卷积神经网络的案例

给定灰度图像的数据集，其标准化尺寸各为 32×32 像素，传统的前馈神经网络将需要 1024 个输入权重（加上一个偏差）。

这是公平的，但是像素的图像矩阵平坦化为像素值的长向量会丢失图像中的所有空间结构。除非所有图像都完美地调整大小，否则神经网络将很难解决问题。

卷积神经网络通过使用小方块输入数据学习内部特征表示来期望并保持像素之间的空间关系。在整个图像中学习和使用特征，允许图像中的对象在场景中被移位或平移，并且仍然可以被网络检测到。

这就是为什么网络对于照片中的对象识别，选择具有不同方向的数字，面部，对象等非常有用的原因。

总之，以下是使用卷积神经网络的一些好处：

*   与完全连接的网络相比，它们使用更少的参数（权重）来学习。
*   它们被设计为对场景中的物体位置和失真不变。
*   它们会自动学习并概括输入域中的功能。

## 卷积神经网络的构建模块

卷积神经网络中有三种类型的层：

1.  卷积层。
2.  汇集层。
3.  完全连接的层。

### 1.卷积层

卷积层由滤波器和特征映射组成。

#### 过滤器

过滤器是层的“神经元”。有输入权重并输出一个值。输入大小是一个固定的方块，称为补丁或感知字段。

如果卷积层是输入层，则输入补丁将是像素值。如果网络架构中的更深层，则卷积层将从前一层的特征映射中获取输入。

#### 功能图

要素图是应用于上一层的一个过滤器的输出。

在整个前一层上绘制给定的滤镜，一次移动一个像素。每个位置导致神经元的激活，并且输出被收集在特征图中。您可以看到，如果将感知字段从激活移动到激活一个像素，则该字段将与之前激活的（字段宽度 - 1）输入值重叠。

#### 零填充

过滤器在每次激活时从前一层的输入移动的距离称为步幅。

如果前一层的大小不能被过滤器接收场的大小和步幅的大小完全整除，那么接收场可能会尝试读取输入特征图的边缘。在这种情况下，可以使用诸如零填充之类的技术来发明用于读取的感知字段的模拟输入。

### 2.合并层

池化层对先前的层要素图进行下采样。

池化层遵循一个或多个卷积层的序列，旨在合并在先前层的特征映射中学习和表达的特征。因此，池化可以被认为是压缩或概括特征表示的技术，并且通常减少模型对训练数据的过度拟合。

它们也有一个感受野，通常比卷积层小得多。此外，为每次激活移动感受野的输入的步幅或数量通常等于感受野的大小以避免任何重叠。

池化层通常非常简单，取输入值的平均值或最大值以创建自己的特征映射。

### 3.完全连接的层

完全连接的层是正常的平坦前馈神经网络层。

这些层可以具有非线性激活函数或 softmax 激活，以便输出类预测的概率。

在卷积和池化层执行特征提取和合并之后，在网络末端使用完全连接的层。它们用于创建最终的非线性特征组合，并用于通过网络进行预测。

## 卷积神经网络的工作实例

您现在知道卷积，池和完全连接的层。让我们通过研究如何将这三个层连接在一起来使这个更具体。

### 1.图像输入数据

假设我们有一个灰度图像的数据集。每个图像具有 32 像素宽和 32 像素高的相同尺寸，并且像素值在 0 到 255 之间，例如。一个 32x32x1 或 1024 像素值的矩阵。

图像输入数据表示为宽度*高度*通道的三维矩阵。如果我们在我们的示例中使用彩色图像，我们将有 3 个通道用于红色，绿色和蓝色像素值，例如 32x32x3。

### 2.卷积层

我们定义了一个卷积层，其中包含 10 个滤波器和一个 5 像素宽，5 像素高，步长为 1 的感知域。

因为每个滤波器一次只能从（即“看”）5×5（25）像素输入，我们可以计算每个滤波器需要 25 + 1 个输入权重（偏置输入加 1）。

在步幅宽度为 1 的情况下在输入图像数据上拖动 5×5 感受野将导致每个图像具有 28×28 个输出值或 784 个不同激活的特征图。

我们有 10 个滤镜，因此将为一个图像创建 10 个不同的 28×28 特征映射或 7,840 个输出。

最后，我们知道每个滤波器有 26 个输入，10 个滤波器和 28×28 输出值来计算每个滤波器，因此我们的卷积层总共有 26x10x28x28 或 203,840 个“连接”，我们想用传统的神经元来表达它网络命名法。

卷积层还利用非线性传递函数作为激活的一部分，整流器激活函数是常用的默认值。

### 3.池层

我们定义了一个具有感知字段的池层，其宽度为 2 个输入，高度为 2 个输入。我们还使用 2 的步幅来确保没有重叠。

这导致特征映射的大小是输入要素映射的一半。从 10 个不同的 28×28 特征映射作为输入到 10 个不同的 14×14 特征映射作为输出。

我们将对每个感知字段使用 max（）操作，以便激活是最大输入值。

### 4.完全连接的层

最后，我们可以将方形特征映射平坦化为传统的平坦完全连接层。

我们可以用 200 个隐藏的神经元定义完全连接的层，每个神经元具有 10x14x14 输入连接，或者每个神经元具有 1960 + 1 个权重。这一层共有 392,200 个连接和权重。

我们可以使用 sigmoid 或 softmax 传递函数直接输出类值的概率。

## 卷积神经网络最佳实践

现在我们已经了解了卷积神经网络的构建块以及这些层如何挂在一起，我们可以回顾一下应用它们时要考虑的一些最佳实践。

*   **输入感受野维度**：图像的默认值为 2D，但可以是 1D，例如句子中的单词或添加时间维度的视频的 3D。
*   **接收字段大小**：补丁应尽可能小，但大到足以“看到”输入数据中的功能。通常在小图像上使用 3×3，在较大图像尺寸上使用 5×5 或 7×7 或更多。
*   **步幅宽度**：使用默认步幅 1.这很容易理解，并且您不需要填充来处理从图像边缘掉落的感受野。对于较大的图像，这可以增加到 2 或更大。
*   **滤波器数量**：滤波器是特征检测器。通常在输入层使用较少的滤波器，并且在较深层使用的滤波器越来越多。
*   **填充**：设置为零并在读取非输入数据时调用零填充。当您不能或不想标准化输入图像大小或想要使用不能整齐划分输入图像大小的感知字段和步幅大小时，这非常有用。
*   **汇集**：汇集是一种破坏性或泛化过程，以减少过度拟合。接收场几乎总是设置为 2×2，步幅为 2，以丢弃前一层输出的 75％激活。
*   **数据准备**：考虑标准化输入数据，包括图像尺寸和像素值。
*   **模式体系结构**：通常在网络体系结构中对层进行模式化。这可能是一个，两个或一些卷积层，后面是池化层。然后可以重复该结构一次或多次。最后，完全连接的层通常仅在输出端使用，并且可以堆叠一个，两个或更多个深度。
*   **dropout**：CNN 有一种过度拟合的习惯，即使是汇集层也是如此。应该使用 Dropout，例如在完全连接的层之间，也可以在池化之后。

您是否了解使用 CNN 的更多最佳做法？

请在评论中告诉我。

## 进一步阅读卷积神经网络

你只能在卷积神经网络上划伤表面。该领域正在快速发展，并且一直在讨论和使用新的有趣的架构和技术。

如果您正在寻找对该技术的更深入理解，请查看 LeCun 等。 al 的开创性论文题为“[基于梯度的学习应用于文档识别](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)”[PDF]。他们将 [LeNet](http://yann.lecun.com/exdb/lenet/) 应用于手写数字识别，并仔细解释各层以及网络连接方式。

网络上有很多关于 CNN 的教程和讨论。下面列出了一些选择示例。就个人而言，我发现帖子中的解释性图片只有在理解了网络如何挂起之后才有用，许多解释令人困惑，如果有疑问，请将您推迟到 LeCun 的论文中。

*   [DeepLearning4J 中的卷积网络](http://deeplearning4j.org/convolutionalnets.html)
*   [斯坦福 CS231n 课程中的卷积网络模型](https://cs231n.github.io/convolutional-networks/ https://cs231n.github.io/)
*   [卷积网络与视觉应用](http://yann.lecun.com/exdb/publis/pdf/lecun-iscas-10.pdf) [PDF]
*   [Michael Nielsen 开放式深度学习书](http://neuralnetworksanddeeplearning.com/chap6.html)第 6 章
*   [VGG 卷云神经网络实用于牛津](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/)
*   [了解 Denny Britz](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/) 对 NLP 的卷积神经网络的理解

## 摘要

在这篇文章中，您发现了卷积神经网络。你了解到：

*   为什么需要 CNN 来保留输入数据中的空间结构及其提供的好处。
*   CNN 的构建块包括卷积，池化和完全连接的层。
*   CNN 中的层如何挂在一起。
*   将 CNN 应用于您自己的问题时的最佳做法。

你对卷积神经网络或这篇文章有任何疑问吗？在评论中提出您的问题，我会尽力回答。